{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[2021.02.22] VGG16 - 1",
      "provenance": [],
      "mount_file_id": "1AkQjO9boiGL2_pcMSxD4oGnzA0Jo8sts",
      "authorship_tag": "ABX9TyPJO5xgMVM/lemlfyAkIxur",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seunghyeon2776/98/blob/master/%5B2021_02_22%5DVGG16-1\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBddqM_z-QDp"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "import seaborn as sns\r\n",
        "\r\n",
        "import keras\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout \r\n",
        "from keras.preprocessing.image import ImageDataGenerator\r\n",
        "from keras.optimizers import Adam\r\n",
        "\r\n",
        "from sklearn.metrics import classification_report,confusion_matrix\r\n",
        "\r\n",
        "import tensorflow as tf\r\n",
        "\r\n",
        "import cv2\r\n",
        "import os\r\n",
        "\r\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I29S4vP-_5D4"
      },
      "source": [
        "labels = ['1.Cancer', '2.Precancer', '3.Inflammatory', '4.Normal']\r\n",
        "img_size = 224\r\n",
        "def get_data(data_dir):\r\n",
        "    data = [] \r\n",
        "    for label in labels: \r\n",
        "        path = os.path.join(data_dir, label)\r\n",
        "        class_num = labels.index(label)\r\n",
        "        for img in os.listdir(path):\r\n",
        "            try:\r\n",
        "                img_arr = cv2.imread(os.path.join(path, img))[...,::-1]\r\n",
        "                resized_arr = cv2.resize(img_arr, (img_size, img_size))\r\n",
        "                data.append([resized_arr, class_num])\r\n",
        "            except Exception as e:\r\n",
        "                print(e)\r\n",
        "    return np.array(data)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PT7Z1LTwANiM",
        "outputId": "75e8c975-0060-427e-9c02-e1df86dbfb67"
      },
      "source": [
        "train = get_data('/content/drive/Shareddrives/CTRC-OralDetect-Project/HM_Color/train')\r\n",
        "val = get_data('/content/drive/Shareddrives/CTRC-OralDetect-Project/HM_Color/validation')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  from ipykernel import kernelapp as app\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "SPd60tBpAdUT",
        "outputId": "f45c400e-a19e-4f3f-bee1-30a6b8edfd2b"
      },
      "source": [
        "l = []\r\n",
        "for i in train:\r\n",
        "    if i[1] == 0:\r\n",
        "        l.append(\"1.Cancer\")\r\n",
        "    elif i[1] == 1:\r\n",
        "        l.append(\"2.Precancer\")\r\n",
        "    elif i[1] == 2:\r\n",
        "        l.append(\"3.Inflammatory\")\r\n",
        "    else:\r\n",
        "        l.append(\"4.Normal\")\r\n",
        "sns.set_style('darkgrid')\r\n",
        "sns.countplot(l)\r\n",
        "\r\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f055633d320>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2J2v6y-AwH8"
      },
      "source": [
        "x_train = []\r\n",
        "y_train = []\r\n",
        "x_val = []\r\n",
        "y_val = []\r\n",
        "\r\n",
        "for feature, label in train:\r\n",
        "  x_train.append(feature)\r\n",
        "  y_train.append(label)\r\n",
        "\r\n",
        "for feature, label in val:\r\n",
        "  x_val.append(feature)\r\n",
        "  y_val.append(label)\r\n",
        "\r\n",
        "# Normalize the data\r\n",
        "x_train = np.array(x_train) / 255\r\n",
        "x_val = np.array(x_val) / 255\r\n",
        "\r\n",
        "x_train.reshape(-1, img_size, img_size, 1)\r\n",
        "y_train = np.array(y_train)\r\n",
        "\r\n",
        "x_val.reshape(-1, img_size, img_size, 1)\r\n",
        "y_val = np.array(y_val)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAes10iCAwSP"
      },
      "source": [
        "datagen = ImageDataGenerator(\r\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\r\n",
        "        samplewise_center=False,  # set each sample mean to 0\r\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\r\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\r\n",
        "        zca_whitening=False,  # apply ZCA whitening\r\n",
        "        rotation_range = 30,  # randomly rotate images in the range (degrees, 0 to 180)\r\n",
        "        zoom_range = 0.2, # Randomly zoom image \r\n",
        "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\r\n",
        "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\r\n",
        "        horizontal_flip = True,  # randomly flip images\r\n",
        "        vertical_flip=False)  # randomly flip images\r\n",
        "\r\n",
        "\r\n",
        "datagen.fit(x_train)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ByFOsWWBSHoJ",
        "outputId": "bacc3c3a-5115-4d76-8ace-1b75f3322d15"
      },
      "source": [
        "base_model = tf.keras.applications.VGG16(input_shape = (224, 224, 3), include_top = False, weights = \"imagenet\", classifier_activation='softmax', classes=1000)\r\n",
        "base_model.trainable = False\r\n",
        "\r\n",
        "model = tf.keras.Sequential([base_model,\r\n",
        "                                 tf.keras.layers.GlobalAveragePooling2D(),\r\n",
        "                                 tf.keras.layers.Dropout(0.3),\r\n",
        "                                 tf.keras.layers.Dense(4, activation=\"softmax\")                                     \r\n",
        "                                ])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOg-wf-OSQ8Z",
        "outputId": "c365c56f-3a79-4632-bb59-33bb85d27269"
      },
      "source": [
        "base_learning_rate = 0.001\r\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(lr=base_learning_rate),\r\n",
        "              loss= tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\r\n",
        "              metrics=['accuracy'])\r\n",
        "\r\n",
        "history = model.fit(x_train,y_train,epochs = 100 , validation_data = (x_val, y_val))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "74/74 [==============================] - 18s 218ms/step - loss: 1.5743 - accuracy: 0.3116 - val_loss: 1.1199 - val_accuracy: 0.5421\n",
            "Epoch 2/100\n",
            "74/74 [==============================] - 13s 178ms/step - loss: 1.0634 - accuracy: 0.5997 - val_loss: 1.0233 - val_accuracy: 0.5723\n",
            "Epoch 3/100\n",
            "74/74 [==============================] - 13s 179ms/step - loss: 0.9789 - accuracy: 0.6420 - val_loss: 0.9799 - val_accuracy: 0.5866\n",
            "Epoch 4/100\n",
            "74/74 [==============================] - 13s 180ms/step - loss: 0.9169 - accuracy: 0.6788 - val_loss: 0.9486 - val_accuracy: 0.5898\n",
            "Epoch 5/100\n",
            "74/74 [==============================] - 13s 181ms/step - loss: 0.8779 - accuracy: 0.6888 - val_loss: 0.9458 - val_accuracy: 0.5946\n",
            "Epoch 6/100\n",
            "74/74 [==============================] - 13s 180ms/step - loss: 0.8166 - accuracy: 0.6960 - val_loss: 0.9048 - val_accuracy: 0.6169\n",
            "Epoch 7/100\n",
            "74/74 [==============================] - 13s 181ms/step - loss: 0.8093 - accuracy: 0.7087 - val_loss: 0.9034 - val_accuracy: 0.6169\n",
            "Epoch 8/100\n",
            "74/74 [==============================] - 13s 183ms/step - loss: 0.7991 - accuracy: 0.7186 - val_loss: 0.8804 - val_accuracy: 0.6169\n",
            "Epoch 9/100\n",
            "74/74 [==============================] - 13s 183ms/step - loss: 0.8145 - accuracy: 0.7067 - val_loss: 0.8563 - val_accuracy: 0.6407\n",
            "Epoch 10/100\n",
            "74/74 [==============================] - 14s 183ms/step - loss: 0.7736 - accuracy: 0.7211 - val_loss: 0.8940 - val_accuracy: 0.6169\n",
            "Epoch 11/100\n",
            "74/74 [==============================] - 14s 183ms/step - loss: 0.7375 - accuracy: 0.7298 - val_loss: 0.8900 - val_accuracy: 0.6153\n",
            "Epoch 12/100\n",
            "74/74 [==============================] - 13s 183ms/step - loss: 0.7429 - accuracy: 0.7149 - val_loss: 0.9081 - val_accuracy: 0.6248\n",
            "Epoch 13/100\n",
            "74/74 [==============================] - 13s 183ms/step - loss: 0.7472 - accuracy: 0.7235 - val_loss: 0.8629 - val_accuracy: 0.6391\n",
            "Epoch 14/100\n",
            "74/74 [==============================] - 14s 183ms/step - loss: 0.7372 - accuracy: 0.7191 - val_loss: 0.8822 - val_accuracy: 0.6232\n",
            "Epoch 15/100\n",
            "74/74 [==============================] - 14s 183ms/step - loss: 0.7281 - accuracy: 0.7279 - val_loss: 0.8347 - val_accuracy: 0.6471\n",
            "Epoch 16/100\n",
            "74/74 [==============================] - 13s 183ms/step - loss: 0.7135 - accuracy: 0.7418 - val_loss: 0.8413 - val_accuracy: 0.6439\n",
            "Epoch 17/100\n",
            "74/74 [==============================] - 14s 183ms/step - loss: 0.7108 - accuracy: 0.7296 - val_loss: 0.8295 - val_accuracy: 0.6486\n",
            "Epoch 18/100\n",
            "74/74 [==============================] - 14s 184ms/step - loss: 0.7125 - accuracy: 0.7368 - val_loss: 0.8572 - val_accuracy: 0.6423\n",
            "Epoch 19/100\n",
            "74/74 [==============================] - 13s 183ms/step - loss: 0.7345 - accuracy: 0.7209 - val_loss: 0.8628 - val_accuracy: 0.6486\n",
            "Epoch 20/100\n",
            "74/74 [==============================] - 13s 182ms/step - loss: 0.7209 - accuracy: 0.7258 - val_loss: 0.8515 - val_accuracy: 0.6407\n",
            "Epoch 21/100\n",
            "74/74 [==============================] - 14s 183ms/step - loss: 0.6869 - accuracy: 0.7432 - val_loss: 0.8585 - val_accuracy: 0.6486\n",
            "Epoch 22/100\n",
            "74/74 [==============================] - 14s 183ms/step - loss: 0.6800 - accuracy: 0.7373 - val_loss: 0.8429 - val_accuracy: 0.6502\n",
            "Epoch 23/100\n",
            "74/74 [==============================] - 13s 182ms/step - loss: 0.6770 - accuracy: 0.7473 - val_loss: 0.8422 - val_accuracy: 0.6502\n",
            "Epoch 24/100\n",
            "74/74 [==============================] - 14s 184ms/step - loss: 0.7008 - accuracy: 0.7364 - val_loss: 0.8739 - val_accuracy: 0.6486\n",
            "Epoch 25/100\n",
            "74/74 [==============================] - 14s 184ms/step - loss: 0.6895 - accuracy: 0.7437 - val_loss: 0.8831 - val_accuracy: 0.6375\n",
            "Epoch 26/100\n",
            "74/74 [==============================] - 14s 184ms/step - loss: 0.6742 - accuracy: 0.7518 - val_loss: 0.8609 - val_accuracy: 0.6502\n",
            "Epoch 27/100\n",
            "74/74 [==============================] - 14s 185ms/step - loss: 0.7054 - accuracy: 0.7343 - val_loss: 0.8491 - val_accuracy: 0.6550\n",
            "Epoch 28/100\n",
            "74/74 [==============================] - 14s 184ms/step - loss: 0.6979 - accuracy: 0.7422 - val_loss: 0.8928 - val_accuracy: 0.6359\n",
            "Epoch 29/100\n",
            "74/74 [==============================] - 14s 185ms/step - loss: 0.6787 - accuracy: 0.7550 - val_loss: 0.8559 - val_accuracy: 0.6407\n",
            "Epoch 30/100\n",
            "74/74 [==============================] - 14s 184ms/step - loss: 0.6923 - accuracy: 0.7388 - val_loss: 0.8616 - val_accuracy: 0.6550\n",
            "Epoch 31/100\n",
            "74/74 [==============================] - 14s 184ms/step - loss: 0.6605 - accuracy: 0.7504 - val_loss: 0.8281 - val_accuracy: 0.6677\n",
            "Epoch 32/100\n",
            "74/74 [==============================] - 13s 183ms/step - loss: 0.6652 - accuracy: 0.7595 - val_loss: 0.8348 - val_accuracy: 0.6582\n",
            "Epoch 33/100\n",
            "74/74 [==============================] - 14s 184ms/step - loss: 0.6652 - accuracy: 0.7569 - val_loss: 0.8607 - val_accuracy: 0.6518\n",
            "Epoch 34/100\n",
            "74/74 [==============================] - 14s 183ms/step - loss: 0.6567 - accuracy: 0.7523 - val_loss: 0.8653 - val_accuracy: 0.6534\n",
            "Epoch 35/100\n",
            "74/74 [==============================] - 14s 184ms/step - loss: 0.6445 - accuracy: 0.7560 - val_loss: 0.8795 - val_accuracy: 0.6534\n",
            "Epoch 36/100\n",
            "74/74 [==============================] - 13s 183ms/step - loss: 0.6490 - accuracy: 0.7409 - val_loss: 0.8675 - val_accuracy: 0.6614\n",
            "Epoch 37/100\n",
            "74/74 [==============================] - 14s 184ms/step - loss: 0.6452 - accuracy: 0.7607 - val_loss: 0.8435 - val_accuracy: 0.6614\n",
            "Epoch 38/100\n",
            "74/74 [==============================] - 14s 183ms/step - loss: 0.6407 - accuracy: 0.7567 - val_loss: 0.8823 - val_accuracy: 0.6423\n",
            "Epoch 39/100\n",
            "74/74 [==============================] - 14s 184ms/step - loss: 0.6586 - accuracy: 0.7520 - val_loss: 0.8508 - val_accuracy: 0.6661\n",
            "Epoch 40/100\n",
            "74/74 [==============================] - 14s 184ms/step - loss: 0.6421 - accuracy: 0.7669 - val_loss: 0.8498 - val_accuracy: 0.6614\n",
            "Epoch 41/100\n",
            "74/74 [==============================] - 14s 183ms/step - loss: 0.6494 - accuracy: 0.7585 - val_loss: 0.8222 - val_accuracy: 0.6693\n",
            "Epoch 42/100\n",
            "74/74 [==============================] - 14s 184ms/step - loss: 0.6419 - accuracy: 0.7725 - val_loss: 0.8043 - val_accuracy: 0.6725\n",
            "Epoch 43/100\n",
            "74/74 [==============================] - 14s 184ms/step - loss: 0.6366 - accuracy: 0.7662 - val_loss: 0.8307 - val_accuracy: 0.6693\n",
            "Epoch 44/100\n",
            "74/74 [==============================] - 14s 184ms/step - loss: 0.6415 - accuracy: 0.7614 - val_loss: 0.8763 - val_accuracy: 0.6550\n",
            "Epoch 45/100\n",
            "74/74 [==============================] - 14s 184ms/step - loss: 0.6427 - accuracy: 0.7559 - val_loss: 0.8090 - val_accuracy: 0.6741\n",
            "Epoch 46/100\n",
            "74/74 [==============================] - 14s 183ms/step - loss: 0.6501 - accuracy: 0.7578 - val_loss: 0.8222 - val_accuracy: 0.6709\n",
            "Epoch 47/100\n",
            "74/74 [==============================] - 14s 184ms/step - loss: 0.6722 - accuracy: 0.7542 - val_loss: 0.8226 - val_accuracy: 0.6741\n",
            "Epoch 48/100\n",
            "74/74 [==============================] - 13s 183ms/step - loss: 0.6355 - accuracy: 0.7497 - val_loss: 0.8205 - val_accuracy: 0.6693\n",
            "Epoch 49/100\n",
            "74/74 [==============================] - 14s 184ms/step - loss: 0.6461 - accuracy: 0.7658 - val_loss: 0.7931 - val_accuracy: 0.6804\n",
            "Epoch 50/100\n",
            "74/74 [==============================] - 14s 183ms/step - loss: 0.6286 - accuracy: 0.7535 - val_loss: 0.8238 - val_accuracy: 0.6709\n",
            "Epoch 51/100\n",
            "74/74 [==============================] - 14s 184ms/step - loss: 0.6430 - accuracy: 0.7644 - val_loss: 0.8607 - val_accuracy: 0.6614\n",
            "Epoch 52/100\n",
            "74/74 [==============================] - 14s 184ms/step - loss: 0.6179 - accuracy: 0.7596 - val_loss: 0.8039 - val_accuracy: 0.6741\n",
            "Epoch 53/100\n",
            "74/74 [==============================] - 14s 184ms/step - loss: 0.6420 - accuracy: 0.7530 - val_loss: 0.8595 - val_accuracy: 0.6677\n",
            "Epoch 54/100\n",
            "74/74 [==============================] - 14s 184ms/step - loss: 0.6098 - accuracy: 0.7704 - val_loss: 0.8574 - val_accuracy: 0.6693\n",
            "Epoch 55/100\n",
            "74/74 [==============================] - 14s 184ms/step - loss: 0.6168 - accuracy: 0.7761 - val_loss: 0.8286 - val_accuracy: 0.6709\n",
            "Epoch 56/100\n",
            "74/74 [==============================] - 14s 184ms/step - loss: 0.6416 - accuracy: 0.7594 - val_loss: 0.8767 - val_accuracy: 0.6598\n",
            "Epoch 57/100\n",
            "74/74 [==============================] - 14s 183ms/step - loss: 0.6210 - accuracy: 0.7657 - val_loss: 0.8364 - val_accuracy: 0.6677\n",
            "Epoch 58/100\n",
            "74/74 [==============================] - 14s 184ms/step - loss: 0.6066 - accuracy: 0.7689 - val_loss: 0.8360 - val_accuracy: 0.6709\n",
            "Epoch 59/100\n",
            "74/74 [==============================] - 14s 184ms/step - loss: 0.5878 - accuracy: 0.7814 - val_loss: 0.8295 - val_accuracy: 0.6709\n",
            "Epoch 60/100\n",
            "74/74 [==============================] - 14s 183ms/step - loss: 0.6059 - accuracy: 0.7707 - val_loss: 0.8402 - val_accuracy: 0.6725\n",
            "Epoch 61/100\n",
            "74/74 [==============================] - 14s 184ms/step - loss: 0.6464 - accuracy: 0.7614 - val_loss: 0.8169 - val_accuracy: 0.6773\n",
            "Epoch 62/100\n",
            "74/74 [==============================] - 14s 184ms/step - loss: 0.6099 - accuracy: 0.7657 - val_loss: 0.8161 - val_accuracy: 0.6741\n",
            "Epoch 63/100\n",
            "74/74 [==============================] - 14s 183ms/step - loss: 0.6430 - accuracy: 0.7645 - val_loss: 0.8315 - val_accuracy: 0.6693\n",
            "Epoch 64/100\n",
            "74/74 [==============================] - 14s 184ms/step - loss: 0.6104 - accuracy: 0.7630 - val_loss: 0.8316 - val_accuracy: 0.6693\n",
            "Epoch 65/100\n",
            "74/74 [==============================] - 14s 184ms/step - loss: 0.5961 - accuracy: 0.7813 - val_loss: 0.8213 - val_accuracy: 0.6741\n",
            "Epoch 66/100\n",
            "74/74 [==============================] - 14s 184ms/step - loss: 0.6000 - accuracy: 0.7790 - val_loss: 0.8054 - val_accuracy: 0.6804\n",
            "Epoch 67/100\n",
            "74/74 [==============================] - 14s 184ms/step - loss: 0.6003 - accuracy: 0.7770 - val_loss: 0.8393 - val_accuracy: 0.6693\n",
            "Epoch 68/100\n",
            "74/74 [==============================] - 14s 183ms/step - loss: 0.5922 - accuracy: 0.7754 - val_loss: 0.8533 - val_accuracy: 0.6630\n",
            "Epoch 69/100\n",
            "74/74 [==============================] - 14s 183ms/step - loss: 0.6395 - accuracy: 0.7552 - val_loss: 0.8359 - val_accuracy: 0.6709\n",
            "Epoch 70/100\n",
            "74/74 [==============================] - 14s 184ms/step - loss: 0.6019 - accuracy: 0.7865 - val_loss: 0.8005 - val_accuracy: 0.6773\n",
            "Epoch 71/100\n",
            "74/74 [==============================] - 14s 183ms/step - loss: 0.5619 - accuracy: 0.8086 - val_loss: 0.8235 - val_accuracy: 0.6725\n",
            "Epoch 72/100\n",
            "74/74 [==============================] - 14s 183ms/step - loss: 0.5959 - accuracy: 0.7828 - val_loss: 0.8985 - val_accuracy: 0.6534\n",
            "Epoch 73/100\n",
            "74/74 [==============================] - 13s 183ms/step - loss: 0.5944 - accuracy: 0.7791 - val_loss: 0.8445 - val_accuracy: 0.6725\n",
            "Epoch 74/100\n",
            "74/74 [==============================] - 14s 183ms/step - loss: 0.5813 - accuracy: 0.7792 - val_loss: 0.8221 - val_accuracy: 0.6741\n",
            "Epoch 75/100\n",
            "74/74 [==============================] - 14s 184ms/step - loss: 0.6067 - accuracy: 0.7734 - val_loss: 0.7925 - val_accuracy: 0.6820\n",
            "Epoch 76/100\n",
            "74/74 [==============================] - 14s 183ms/step - loss: 0.6094 - accuracy: 0.7797 - val_loss: 0.8712 - val_accuracy: 0.6598\n",
            "Epoch 77/100\n",
            "74/74 [==============================] - 13s 183ms/step - loss: 0.6152 - accuracy: 0.7530 - val_loss: 0.8306 - val_accuracy: 0.6741\n",
            "Epoch 78/100\n",
            "74/74 [==============================] - 14s 183ms/step - loss: 0.6056 - accuracy: 0.7699 - val_loss: 0.8116 - val_accuracy: 0.6804\n",
            "Epoch 79/100\n",
            "74/74 [==============================] - 14s 184ms/step - loss: 0.6143 - accuracy: 0.7680 - val_loss: 0.8784 - val_accuracy: 0.6598\n",
            "Epoch 80/100\n",
            "74/74 [==============================] - 14s 185ms/step - loss: 0.5965 - accuracy: 0.7837 - val_loss: 0.8702 - val_accuracy: 0.6677\n",
            "Epoch 81/100\n",
            "74/74 [==============================] - 14s 184ms/step - loss: 0.5909 - accuracy: 0.7684 - val_loss: 0.7865 - val_accuracy: 0.6820\n",
            "Epoch 82/100\n",
            "74/74 [==============================] - 13s 183ms/step - loss: 0.6229 - accuracy: 0.7745 - val_loss: 0.8230 - val_accuracy: 0.6709\n",
            "Epoch 83/100\n",
            "74/74 [==============================] - 13s 183ms/step - loss: 0.6046 - accuracy: 0.7633 - val_loss: 0.8184 - val_accuracy: 0.6757\n",
            "Epoch 84/100\n",
            "74/74 [==============================] - 14s 183ms/step - loss: 0.5973 - accuracy: 0.7818 - val_loss: 0.8342 - val_accuracy: 0.6725\n",
            "Epoch 85/100\n",
            "74/74 [==============================] - 13s 183ms/step - loss: 0.5863 - accuracy: 0.7851 - val_loss: 0.8001 - val_accuracy: 0.6773\n",
            "Epoch 86/100\n",
            "74/74 [==============================] - 14s 184ms/step - loss: 0.5709 - accuracy: 0.7855 - val_loss: 0.8893 - val_accuracy: 0.6550\n",
            "Epoch 87/100\n",
            "74/74 [==============================] - 14s 184ms/step - loss: 0.5818 - accuracy: 0.7884 - val_loss: 0.7850 - val_accuracy: 0.6836\n",
            "Epoch 88/100\n",
            "74/74 [==============================] - 14s 184ms/step - loss: 0.5968 - accuracy: 0.7781 - val_loss: 0.8410 - val_accuracy: 0.6725\n",
            "Epoch 89/100\n",
            "74/74 [==============================] - 14s 183ms/step - loss: 0.5798 - accuracy: 0.7820 - val_loss: 0.8343 - val_accuracy: 0.6741\n",
            "Epoch 90/100\n",
            "74/74 [==============================] - 13s 183ms/step - loss: 0.5518 - accuracy: 0.8048 - val_loss: 0.8088 - val_accuracy: 0.6804\n",
            "Epoch 91/100\n",
            "74/74 [==============================] - 13s 182ms/step - loss: 0.6031 - accuracy: 0.7708 - val_loss: 0.8597 - val_accuracy: 0.6661\n",
            "Epoch 92/100\n",
            "74/74 [==============================] - 13s 183ms/step - loss: 0.6310 - accuracy: 0.7634 - val_loss: 0.8887 - val_accuracy: 0.6566\n",
            "Epoch 93/100\n",
            "74/74 [==============================] - 14s 183ms/step - loss: 0.5962 - accuracy: 0.7820 - val_loss: 0.8526 - val_accuracy: 0.6645\n",
            "Epoch 94/100\n",
            "74/74 [==============================] - 14s 183ms/step - loss: 0.5736 - accuracy: 0.7936 - val_loss: 0.8398 - val_accuracy: 0.6693\n",
            "Epoch 95/100\n",
            "74/74 [==============================] - 14s 183ms/step - loss: 0.5863 - accuracy: 0.7864 - val_loss: 0.8241 - val_accuracy: 0.6757\n",
            "Epoch 96/100\n",
            "74/74 [==============================] - 14s 183ms/step - loss: 0.5785 - accuracy: 0.7868 - val_loss: 0.8439 - val_accuracy: 0.6709\n",
            "Epoch 97/100\n",
            "74/74 [==============================] - 14s 184ms/step - loss: 0.5816 - accuracy: 0.7799 - val_loss: 0.8739 - val_accuracy: 0.6645\n",
            "Epoch 98/100\n",
            "74/74 [==============================] - 13s 183ms/step - loss: 0.5831 - accuracy: 0.7852 - val_loss: 0.8175 - val_accuracy: 0.6757\n",
            "Epoch 99/100\n",
            "74/74 [==============================] - 14s 183ms/step - loss: 0.6027 - accuracy: 0.7805 - val_loss: 0.8182 - val_accuracy: 0.6789\n",
            "Epoch 100/100\n",
            "74/74 [==============================] - 14s 184ms/step - loss: 0.5794 - accuracy: 0.7906 - val_loss: 0.7984 - val_accuracy: 0.6804\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49jpStyaTB4U"
      },
      "source": [
        "ㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWgpskUmTA5E"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1B8uuKoeAwb-",
        "outputId": "f1ea745b-b77f-401d-f553-4cc60581ebc4"
      },
      "source": [
        "model = Sequential()\r\n",
        "\r\n",
        "model.add(Conv2D(64,3,padding=\"same\", activation=\"relu\", input_shape=(224,224,3)))\r\n",
        "model.add(Conv2D(64,3,padding=\"same\", activation=\"relu\", input_shape=(224,224,3)))\r\n",
        "model.add(MaxPool2D())\r\n",
        "\r\n",
        "\r\n",
        "model.add(Conv2D(128,3,padding=\"same\", activation=\"relu\", input_shape=(224,224,3)))\r\n",
        "model.add(Conv2D(128,3,padding=\"same\", activation=\"relu\", input_shape=(224,224,3)))\r\n",
        "model.add(MaxPool2D())\r\n",
        "\r\n",
        "\r\n",
        "model.add(Conv2D(256,3,padding=\"same\", activation=\"relu\", input_shape=(224,224,3)))\r\n",
        "model.add(Conv2D(256,3,padding=\"same\", activation=\"relu\", input_shape=(224,224,3)))\r\n",
        "model.add(Conv2D(256,3,padding=\"same\", activation=\"relu\", input_shape=(224,224,3)))\r\n",
        "model.add(MaxPool2D())\r\n",
        "\r\n",
        "\r\n",
        "model.add(Conv2D(512,3,padding=\"same\", activation=\"relu\", input_shape=(224,224,3)))\r\n",
        "model.add(Conv2D(512,3,padding=\"same\", activation=\"relu\", input_shape=(224,224,3)))\r\n",
        "model.add(Conv2D(512,3,padding=\"same\", activation=\"relu\", input_shape=(224,224,3)))\r\n",
        "model.add(MaxPool2D())\r\n",
        "\r\n",
        "\r\n",
        "model.add(Conv2D(512,3,padding=\"same\", activation=\"relu\", input_shape=(224,224,3)))\r\n",
        "model.add(Conv2D(512,3,padding=\"same\", activation=\"relu\", input_shape=(224,224,3)))\r\n",
        "model.add(Conv2D(512,3,padding=\"same\", activation=\"relu\", input_shape=(224,224,3)))\r\n",
        "model.add(MaxPool2D())\r\n",
        "\r\n",
        "model.add(Flatten()) \r\n",
        "model.add(Dense(128,activation=\"relu\"))\r\n",
        "model.add(Dense(64,activation=\"relu\"))\r\n",
        "model.add(Dense(4,activation=\"softmax\"))\r\n",
        "\r\n",
        "model.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_17 (Conv2D)           (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "conv2d_18 (Conv2D)           (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_19 (Conv2D)           (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "conv2d_20 (Conv2D)           (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_21 (Conv2D)           (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "conv2d_22 (Conv2D)           (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "conv2d_23 (Conv2D)           (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_24 (Conv2D)           (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "conv2d_25 (Conv2D)           (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "conv2d_26 (Conv2D)           (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_27 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "conv2d_28 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "conv2d_29 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               3211392   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 4)                 260       \n",
            "=================================================================\n",
            "Total params: 17,934,596\n",
            "Trainable params: 17,934,596\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ut2HqGjkCCak"
      },
      "source": [
        "opt = Adam(lr=0.001)\r\n",
        "model.compile(optimizer = opt , loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True) , metrics = ['accuracy'])"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "LT3JQiiZCFKZ",
        "outputId": "ff2bfcae-3181-4ed7-e59d-79560345585e"
      },
      "source": [
        "history = model.fit(x_train,y_train,epochs = 100 , validation_data = (x_val, y_val))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "74/74 [==============================] - 33s 438ms/step - loss: 1.2263 - accuracy: 0.5687 - val_loss: 1.1656 - val_accuracy: 0.5421\n",
            "Epoch 2/100\n",
            "74/74 [==============================] - 32s 428ms/step - loss: 1.1277 - accuracy: 0.5692 - val_loss: 1.1620 - val_accuracy: 0.5421\n",
            "Epoch 3/100\n",
            "74/74 [==============================] - 31s 422ms/step - loss: 1.0996 - accuracy: 0.5885 - val_loss: 1.1624 - val_accuracy: 0.5421\n",
            "Epoch 4/100\n",
            "74/74 [==============================] - 32s 438ms/step - loss: 1.1392 - accuracy: 0.5576 - val_loss: 1.1588 - val_accuracy: 0.5421\n",
            "Epoch 5/100\n",
            "74/74 [==============================] - 31s 425ms/step - loss: 1.1058 - accuracy: 0.5913 - val_loss: 1.1594 - val_accuracy: 0.5421\n",
            "Epoch 6/100\n",
            "74/74 [==============================] - 31s 424ms/step - loss: 1.1137 - accuracy: 0.5791 - val_loss: 1.1605 - val_accuracy: 0.5421\n",
            "Epoch 7/100\n",
            "74/74 [==============================] - 31s 424ms/step - loss: 1.1252 - accuracy: 0.5710 - val_loss: 1.1608 - val_accuracy: 0.5421\n",
            "Epoch 8/100\n",
            "74/74 [==============================] - 31s 425ms/step - loss: 1.1144 - accuracy: 0.5818 - val_loss: 1.1605 - val_accuracy: 0.5421\n",
            "Epoch 9/100\n",
            "74/74 [==============================] - 31s 425ms/step - loss: 1.1217 - accuracy: 0.5793 - val_loss: 1.1593 - val_accuracy: 0.5421\n",
            "Epoch 10/100\n",
            "74/74 [==============================] - 31s 426ms/step - loss: 1.0891 - accuracy: 0.5993 - val_loss: 1.1643 - val_accuracy: 0.5421\n",
            "Epoch 11/100\n",
            "74/74 [==============================] - 31s 425ms/step - loss: 1.1446 - accuracy: 0.5589 - val_loss: 1.1600 - val_accuracy: 0.5421\n",
            "Epoch 12/100\n",
            "74/74 [==============================] - 31s 423ms/step - loss: 1.1284 - accuracy: 0.5766 - val_loss: 1.1624 - val_accuracy: 0.5421\n",
            "Epoch 13/100\n",
            "74/74 [==============================] - 31s 424ms/step - loss: 1.1217 - accuracy: 0.5661 - val_loss: 1.1671 - val_accuracy: 0.5421\n",
            "Epoch 14/100\n",
            "74/74 [==============================] - 31s 423ms/step - loss: 1.1052 - accuracy: 0.5851 - val_loss: 1.1576 - val_accuracy: 0.5421\n",
            "Epoch 15/100\n",
            "74/74 [==============================] - 31s 424ms/step - loss: 1.1292 - accuracy: 0.5619 - val_loss: 1.1629 - val_accuracy: 0.5421\n",
            "Epoch 16/100\n",
            "74/74 [==============================] - 31s 423ms/step - loss: 1.1039 - accuracy: 0.5901 - val_loss: 1.1620 - val_accuracy: 0.5421\n",
            "Epoch 17/100\n",
            "74/74 [==============================] - 31s 423ms/step - loss: 1.0996 - accuracy: 0.5930 - val_loss: 1.1575 - val_accuracy: 0.5421\n",
            "Epoch 18/100\n",
            "74/74 [==============================] - 31s 424ms/step - loss: 1.1236 - accuracy: 0.5762 - val_loss: 1.1588 - val_accuracy: 0.5421\n",
            "Epoch 19/100\n",
            "74/74 [==============================] - 31s 424ms/step - loss: 1.1073 - accuracy: 0.5786 - val_loss: 1.1663 - val_accuracy: 0.5421\n",
            "Epoch 20/100\n",
            "74/74 [==============================] - 31s 424ms/step - loss: 1.1364 - accuracy: 0.5631 - val_loss: 1.1587 - val_accuracy: 0.5421\n",
            "Epoch 21/100\n",
            "36/74 [=============>................] - ETA: 14s - loss: 1.1404 - accuracy: 0.5626"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-b43bb60f745c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1103\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1105\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1106\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    452\u001b[0m     \"\"\"\n\u001b[1;32m    453\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    294\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unrecognized hook: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    314\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    354\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_supports_tf_logs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Only convert once.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1020\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1021\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1082\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1084\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1085\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1086\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    512\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 514\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    508\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    511\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1069\u001b[0m     \"\"\"\n\u001b[1;32m   1070\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1071\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1072\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1035\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHRJ8LZiCGh8"
      },
      "source": [
        "acc = history.history['accuracy']\r\n",
        "val_acc = history.history['val_accuracy']\r\n",
        "loss = history.history['loss']\r\n",
        "val_loss = history.history['val_loss']\r\n",
        "\r\n",
        "epochs_range = range(500)\r\n",
        "\r\n",
        "plt.figure(figsize=(15, 15))\r\n",
        "plt.subplot(2, 2, 1)\r\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\r\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\r\n",
        "plt.legend(loc='lower right')\r\n",
        "plt.title('Training and Validation Accuracy')\r\n",
        "\r\n",
        "plt.subplot(2, 2, 2)\r\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\r\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\r\n",
        "plt.legend(loc='upper right')\r\n",
        "plt.title('Training and Validation Loss')\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-d20SbICGuk"
      },
      "source": [
        "predictions = model.predict_classes(x_val)\r\n",
        "predictions = predictions.reshape(1,-1)[0]\r\n",
        "print(classification_report(y_val, predictions, target_names = ['Rugby (Class 0)','Soccer (Class 1)']))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}