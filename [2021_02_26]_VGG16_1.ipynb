{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[2021.02.26] VGG16 - 1",
      "provenance": [],
      "mount_file_id": "1AkQjO9boiGL2_pcMSxD4oGnzA0Jo8sts",
      "authorship_tag": "ABX9TyNCgs0ILyZWu4LHsAp43b61",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seunghyeon2776/98/blob/master/%5B2021_02_26%5D_VGG16_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBddqM_z-QDp"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "import seaborn as sns\r\n",
        "\r\n",
        "import keras\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout \r\n",
        "from keras.preprocessing.image import ImageDataGenerator\r\n",
        "from keras.optimizers import Adam\r\n",
        "\r\n",
        "from sklearn.metrics import classification_report,confusion_matrix\r\n",
        "\r\n",
        "import tensorflow as tf\r\n",
        "\r\n",
        "import cv2\r\n",
        "import os\r\n",
        "\r\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I29S4vP-_5D4"
      },
      "source": [
        "labels = ['1.Cancer', '2.Precancer', '3.Inflammatory', '4.Normal']\r\n",
        "img_size = 224\r\n",
        "def get_data(data_dir):\r\n",
        "    data = [] \r\n",
        "    for label in labels: \r\n",
        "        path = os.path.join(data_dir, label)\r\n",
        "        class_num = labels.index(label)\r\n",
        "        for img in os.listdir(path):\r\n",
        "            try:\r\n",
        "                img_arr = cv2.imread(os.path.join(path, img))[...,::-1]\r\n",
        "                resized_arr = cv2.resize(img_arr, (img_size, img_size))\r\n",
        "                data.append([resized_arr, class_num])\r\n",
        "            except Exception as e:\r\n",
        "                print(e)\r\n",
        "    return np.array(data)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PT7Z1LTwANiM",
        "outputId": "ed56fe0a-1a86-4002-83e5-eb7bc397e365"
      },
      "source": [
        "train = get_data('/content/drive/MyDrive/train')\r\n",
        "val = get_data('/content/drive/MyDrive/validation')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  from ipykernel import kernelapp as app\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "SPd60tBpAdUT",
        "outputId": "7db3b7d7-08a5-4dc5-91d2-a8a57c840295"
      },
      "source": [
        "l = []\r\n",
        "for i in train:\r\n",
        "    if i[1] == 0:\r\n",
        "        l.append(\"1.Cancer\")\r\n",
        "    elif i[1] == 1:\r\n",
        "        l.append(\"2.Precancer\")\r\n",
        "    elif i[1] == 2:\r\n",
        "        l.append(\"3.Inflammatory\")\r\n",
        "    else:\r\n",
        "        l.append(\"4.Normal\")\r\n",
        "sns.set_style('darkgrid')\r\n",
        "sns.countplot(l)\r\n",
        "\r\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f74c920d290>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2J2v6y-AwH8"
      },
      "source": [
        "x_train = []\r\n",
        "y_train = []\r\n",
        "x_val = []\r\n",
        "y_val = []\r\n",
        "\r\n",
        "for feature, label in train:\r\n",
        "  x_train.append(feature)\r\n",
        "  y_train.append(label)\r\n",
        "\r\n",
        "for feature, label in val:\r\n",
        "  x_val.append(feature)\r\n",
        "  y_val.append(label)\r\n",
        "\r\n",
        "# Normalize the data\r\n",
        "x_train = np.array(x_train) / 255\r\n",
        "x_val = np.array(x_val) / 255\r\n",
        "\r\n",
        "x_train.reshape(-1, img_size, img_size, 1)\r\n",
        "y_train = np.array(y_train)\r\n",
        "\r\n",
        "x_val.reshape(-1, img_size, img_size, 1)\r\n",
        "y_val = np.array(y_val)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAes10iCAwSP"
      },
      "source": [
        "datagen = ImageDataGenerator(\r\n",
        "        zoom_range = 0.2, # Randomly zoom image \r\n",
        "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\r\n",
        "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\r\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\r\n",
        "        samplewise_center=False,  # set each sample mean to 0\r\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\r\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\r\n",
        "        zca_whitening=False,  # apply ZCA whitening\r\n",
        "        rotation_range = 30,  # randomly rotate images in the range (degrees, 0 to 180)\r\n",
        "        horizontal_flip = True,  # randomly flip images\r\n",
        "        vertical_flip=False)  # randomly flip images\r\n",
        "\r\n",
        "\r\n",
        "datagen.fit(x_train)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ByFOsWWBSHoJ"
      },
      "source": [
        "base_model = tf.keras.applications.VGG16(input_shape = (224, 224, 3), include_top = False, weights = \"imagenet\", classifier_activation='softmax', classes=1000)\r\n",
        "base_model.trainable = False\r\n",
        "\r\n",
        "model = tf.keras.Sequential([base_model,\r\n",
        "                                 tf.keras.layers.GlobalAveragePooling2D(),\r\n",
        "                                 tf.keras.layers.Dropout(0.2),\r\n",
        "                                 tf.keras.layers.Dense(4, activation=\"softmax\")                                     \r\n",
        "                                ])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOg-wf-OSQ8Z",
        "outputId": "b0a940ea-49e7-4f13-e3c3-a8929445e282"
      },
      "source": [
        "base_learning_rate = 0.001\r\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(lr=base_learning_rate),\r\n",
        "              loss= tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\r\n",
        "              metrics=['accuracy'])\r\n",
        "\r\n",
        "history = model.fit(x_train,y_train,epochs = 500 , validation_data = (x_val, y_val))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "37/37 [==============================] - 7s 177ms/step - loss: 1.3729 - accuracy: 0.3028 - val_loss: 1.0978 - val_accuracy: 0.5791\n",
            "Epoch 2/500\n",
            "37/37 [==============================] - 6s 174ms/step - loss: 1.0535 - accuracy: 0.6034 - val_loss: 1.0500 - val_accuracy: 0.5816\n",
            "Epoch 3/500\n",
            "37/37 [==============================] - 7s 178ms/step - loss: 1.0297 - accuracy: 0.6009 - val_loss: 1.0141 - val_accuracy: 0.5893\n",
            "Epoch 4/500\n",
            "37/37 [==============================] - 7s 182ms/step - loss: 1.0039 - accuracy: 0.6129 - val_loss: 0.9909 - val_accuracy: 0.5969\n",
            "Epoch 5/500\n",
            "37/37 [==============================] - 7s 184ms/step - loss: 0.9392 - accuracy: 0.6374 - val_loss: 0.9620 - val_accuracy: 0.6071\n",
            "Epoch 6/500\n",
            "37/37 [==============================] - 7s 182ms/step - loss: 0.9404 - accuracy: 0.6355 - val_loss: 0.9484 - val_accuracy: 0.6071\n",
            "Epoch 7/500\n",
            "37/37 [==============================] - 7s 178ms/step - loss: 0.9519 - accuracy: 0.6208 - val_loss: 0.9341 - val_accuracy: 0.6148\n",
            "Epoch 8/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.8890 - accuracy: 0.6518 - val_loss: 0.9122 - val_accuracy: 0.6301\n",
            "Epoch 9/500\n",
            "37/37 [==============================] - 6s 174ms/step - loss: 0.8959 - accuracy: 0.6446 - val_loss: 0.8994 - val_accuracy: 0.6352\n",
            "Epoch 10/500\n",
            "37/37 [==============================] - 6s 172ms/step - loss: 0.8653 - accuracy: 0.6694 - val_loss: 0.8939 - val_accuracy: 0.6352\n",
            "Epoch 11/500\n",
            "37/37 [==============================] - 6s 172ms/step - loss: 0.8361 - accuracy: 0.6656 - val_loss: 0.8762 - val_accuracy: 0.6454\n",
            "Epoch 12/500\n",
            "37/37 [==============================] - 6s 171ms/step - loss: 0.8697 - accuracy: 0.6584 - val_loss: 0.8703 - val_accuracy: 0.6480\n",
            "Epoch 13/500\n",
            "37/37 [==============================] - 6s 172ms/step - loss: 0.8308 - accuracy: 0.6824 - val_loss: 0.8696 - val_accuracy: 0.6403\n",
            "Epoch 14/500\n",
            "37/37 [==============================] - 6s 172ms/step - loss: 0.8477 - accuracy: 0.6646 - val_loss: 0.8538 - val_accuracy: 0.6582\n",
            "Epoch 15/500\n",
            "37/37 [==============================] - 6s 173ms/step - loss: 0.8217 - accuracy: 0.6816 - val_loss: 0.8513 - val_accuracy: 0.6556\n",
            "Epoch 16/500\n",
            "37/37 [==============================] - 6s 174ms/step - loss: 0.8307 - accuracy: 0.6621 - val_loss: 0.8443 - val_accuracy: 0.6582\n",
            "Epoch 17/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.8154 - accuracy: 0.6764 - val_loss: 0.8422 - val_accuracy: 0.6582\n",
            "Epoch 18/500\n",
            "37/37 [==============================] - 7s 179ms/step - loss: 0.7947 - accuracy: 0.6890 - val_loss: 0.8289 - val_accuracy: 0.6684\n",
            "Epoch 19/500\n",
            "37/37 [==============================] - 6s 177ms/step - loss: 0.7637 - accuracy: 0.7031 - val_loss: 0.8229 - val_accuracy: 0.6709\n",
            "Epoch 20/500\n",
            "37/37 [==============================] - 6s 177ms/step - loss: 0.7758 - accuracy: 0.7047 - val_loss: 0.8197 - val_accuracy: 0.6760\n",
            "Epoch 21/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.7998 - accuracy: 0.6890 - val_loss: 0.8217 - val_accuracy: 0.6658\n",
            "Epoch 22/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.7854 - accuracy: 0.6856 - val_loss: 0.8139 - val_accuracy: 0.6760\n",
            "Epoch 23/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.7477 - accuracy: 0.7033 - val_loss: 0.8064 - val_accuracy: 0.6811\n",
            "Epoch 24/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.7462 - accuracy: 0.7232 - val_loss: 0.8088 - val_accuracy: 0.6760\n",
            "Epoch 25/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.7741 - accuracy: 0.6910 - val_loss: 0.8022 - val_accuracy: 0.6888\n",
            "Epoch 26/500\n",
            "37/37 [==============================] - 6s 174ms/step - loss: 0.7717 - accuracy: 0.6970 - val_loss: 0.8059 - val_accuracy: 0.6786\n",
            "Epoch 27/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.7433 - accuracy: 0.6995 - val_loss: 0.7930 - val_accuracy: 0.7015\n",
            "Epoch 28/500\n",
            "37/37 [==============================] - 6s 174ms/step - loss: 0.7250 - accuracy: 0.7281 - val_loss: 0.7989 - val_accuracy: 0.6811\n",
            "Epoch 29/500\n",
            "37/37 [==============================] - 6s 174ms/step - loss: 0.7331 - accuracy: 0.7058 - val_loss: 0.7952 - val_accuracy: 0.6888\n",
            "Epoch 30/500\n",
            "37/37 [==============================] - 6s 174ms/step - loss: 0.7201 - accuracy: 0.7272 - val_loss: 0.7937 - val_accuracy: 0.6862\n",
            "Epoch 31/500\n",
            "37/37 [==============================] - 6s 174ms/step - loss: 0.7027 - accuracy: 0.7248 - val_loss: 0.7870 - val_accuracy: 0.6990\n",
            "Epoch 32/500\n",
            "37/37 [==============================] - 6s 174ms/step - loss: 0.7575 - accuracy: 0.7044 - val_loss: 0.7871 - val_accuracy: 0.7015\n",
            "Epoch 33/500\n",
            "37/37 [==============================] - 6s 174ms/step - loss: 0.6866 - accuracy: 0.7327 - val_loss: 0.7783 - val_accuracy: 0.7117\n",
            "Epoch 34/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.7097 - accuracy: 0.7308 - val_loss: 0.7806 - val_accuracy: 0.7041\n",
            "Epoch 35/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.7162 - accuracy: 0.7276 - val_loss: 0.7855 - val_accuracy: 0.6964\n",
            "Epoch 36/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.7062 - accuracy: 0.7252 - val_loss: 0.7874 - val_accuracy: 0.6913\n",
            "Epoch 37/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.7464 - accuracy: 0.7004 - val_loss: 0.7773 - val_accuracy: 0.7041\n",
            "Epoch 38/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.7708 - accuracy: 0.6980 - val_loss: 0.7853 - val_accuracy: 0.6913\n",
            "Epoch 39/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.7168 - accuracy: 0.7128 - val_loss: 0.7751 - val_accuracy: 0.6990\n",
            "Epoch 40/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.6846 - accuracy: 0.7328 - val_loss: 0.7749 - val_accuracy: 0.7015\n",
            "Epoch 41/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.6960 - accuracy: 0.7307 - val_loss: 0.7687 - val_accuracy: 0.7041\n",
            "Epoch 42/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.6859 - accuracy: 0.7298 - val_loss: 0.7659 - val_accuracy: 0.7066\n",
            "Epoch 43/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.6856 - accuracy: 0.7308 - val_loss: 0.7666 - val_accuracy: 0.7092\n",
            "Epoch 44/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.7017 - accuracy: 0.7345 - val_loss: 0.7702 - val_accuracy: 0.6990\n",
            "Epoch 45/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.6879 - accuracy: 0.7342 - val_loss: 0.7663 - val_accuracy: 0.6990\n",
            "Epoch 46/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.6659 - accuracy: 0.7352 - val_loss: 0.7654 - val_accuracy: 0.6990\n",
            "Epoch 47/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.6616 - accuracy: 0.7541 - val_loss: 0.7585 - val_accuracy: 0.7168\n",
            "Epoch 48/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.6900 - accuracy: 0.7349 - val_loss: 0.7629 - val_accuracy: 0.7066\n",
            "Epoch 49/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.6545 - accuracy: 0.7550 - val_loss: 0.7580 - val_accuracy: 0.7168\n",
            "Epoch 50/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.6545 - accuracy: 0.7462 - val_loss: 0.7604 - val_accuracy: 0.7117\n",
            "Epoch 51/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.6673 - accuracy: 0.7518 - val_loss: 0.7615 - val_accuracy: 0.7015\n",
            "Epoch 52/500\n",
            "37/37 [==============================] - 6s 174ms/step - loss: 0.6607 - accuracy: 0.7340 - val_loss: 0.7560 - val_accuracy: 0.7168\n",
            "Epoch 53/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.6896 - accuracy: 0.7364 - val_loss: 0.7530 - val_accuracy: 0.7168\n",
            "Epoch 54/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.6646 - accuracy: 0.7389 - val_loss: 0.7537 - val_accuracy: 0.7168\n",
            "Epoch 55/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.6258 - accuracy: 0.7623 - val_loss: 0.7520 - val_accuracy: 0.7245\n",
            "Epoch 56/500\n",
            "37/37 [==============================] - 6s 174ms/step - loss: 0.6598 - accuracy: 0.7435 - val_loss: 0.7498 - val_accuracy: 0.7270\n",
            "Epoch 57/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.6289 - accuracy: 0.7626 - val_loss: 0.7531 - val_accuracy: 0.7066\n",
            "Epoch 58/500\n",
            "37/37 [==============================] - 6s 174ms/step - loss: 0.6157 - accuracy: 0.7708 - val_loss: 0.7489 - val_accuracy: 0.7219\n",
            "Epoch 59/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.6555 - accuracy: 0.7501 - val_loss: 0.7575 - val_accuracy: 0.7041\n",
            "Epoch 60/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.6241 - accuracy: 0.7653 - val_loss: 0.7464 - val_accuracy: 0.7270\n",
            "Epoch 61/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.6527 - accuracy: 0.7582 - val_loss: 0.7506 - val_accuracy: 0.7092\n",
            "Epoch 62/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.6440 - accuracy: 0.7396 - val_loss: 0.7527 - val_accuracy: 0.7041\n",
            "Epoch 63/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.6639 - accuracy: 0.7449 - val_loss: 0.7472 - val_accuracy: 0.7143\n",
            "Epoch 64/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.6553 - accuracy: 0.7520 - val_loss: 0.7456 - val_accuracy: 0.7219\n",
            "Epoch 65/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.6634 - accuracy: 0.7385 - val_loss: 0.7442 - val_accuracy: 0.7245\n",
            "Epoch 66/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.6426 - accuracy: 0.7533 - val_loss: 0.7430 - val_accuracy: 0.7270\n",
            "Epoch 67/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.6374 - accuracy: 0.7578 - val_loss: 0.7418 - val_accuracy: 0.7296\n",
            "Epoch 68/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.6262 - accuracy: 0.7620 - val_loss: 0.7440 - val_accuracy: 0.7117\n",
            "Epoch 69/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.6154 - accuracy: 0.7741 - val_loss: 0.7385 - val_accuracy: 0.7372\n",
            "Epoch 70/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.6193 - accuracy: 0.7776 - val_loss: 0.7406 - val_accuracy: 0.7245\n",
            "Epoch 71/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.6418 - accuracy: 0.7467 - val_loss: 0.7384 - val_accuracy: 0.7296\n",
            "Epoch 72/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.6143 - accuracy: 0.7717 - val_loss: 0.7419 - val_accuracy: 0.7194\n",
            "Epoch 73/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.6310 - accuracy: 0.7660 - val_loss: 0.7428 - val_accuracy: 0.7117\n",
            "Epoch 74/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.6088 - accuracy: 0.7789 - val_loss: 0.7370 - val_accuracy: 0.7296\n",
            "Epoch 75/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.6207 - accuracy: 0.7698 - val_loss: 0.7410 - val_accuracy: 0.7219\n",
            "Epoch 76/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.6003 - accuracy: 0.7616 - val_loss: 0.7386 - val_accuracy: 0.7219\n",
            "Epoch 77/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.6108 - accuracy: 0.7747 - val_loss: 0.7393 - val_accuracy: 0.7194\n",
            "Epoch 78/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.6012 - accuracy: 0.7701 - val_loss: 0.7367 - val_accuracy: 0.7270\n",
            "Epoch 79/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.6075 - accuracy: 0.7798 - val_loss: 0.7414 - val_accuracy: 0.7219\n",
            "Epoch 80/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.6430 - accuracy: 0.7592 - val_loss: 0.7394 - val_accuracy: 0.7168\n",
            "Epoch 81/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.6023 - accuracy: 0.7685 - val_loss: 0.7367 - val_accuracy: 0.7245\n",
            "Epoch 82/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.6236 - accuracy: 0.7494 - val_loss: 0.7318 - val_accuracy: 0.7398\n",
            "Epoch 83/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.6158 - accuracy: 0.7766 - val_loss: 0.7313 - val_accuracy: 0.7372\n",
            "Epoch 84/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.6278 - accuracy: 0.7615 - val_loss: 0.7332 - val_accuracy: 0.7296\n",
            "Epoch 85/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.5970 - accuracy: 0.7716 - val_loss: 0.7344 - val_accuracy: 0.7194\n",
            "Epoch 86/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.6058 - accuracy: 0.7658 - val_loss: 0.7315 - val_accuracy: 0.7347\n",
            "Epoch 87/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.5627 - accuracy: 0.7973 - val_loss: 0.7341 - val_accuracy: 0.7245\n",
            "Epoch 88/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.5633 - accuracy: 0.7826 - val_loss: 0.7307 - val_accuracy: 0.7296\n",
            "Epoch 89/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.6005 - accuracy: 0.7731 - val_loss: 0.7313 - val_accuracy: 0.7245\n",
            "Epoch 90/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.5945 - accuracy: 0.7715 - val_loss: 0.7302 - val_accuracy: 0.7321\n",
            "Epoch 91/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.6059 - accuracy: 0.7697 - val_loss: 0.7288 - val_accuracy: 0.7347\n",
            "Epoch 92/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.6183 - accuracy: 0.7560 - val_loss: 0.7336 - val_accuracy: 0.7219\n",
            "Epoch 93/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.5759 - accuracy: 0.7868 - val_loss: 0.7337 - val_accuracy: 0.7194\n",
            "Epoch 94/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.6163 - accuracy: 0.7537 - val_loss: 0.7290 - val_accuracy: 0.7296\n",
            "Epoch 95/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.5452 - accuracy: 0.7960 - val_loss: 0.7285 - val_accuracy: 0.7270\n",
            "Epoch 96/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.5796 - accuracy: 0.7875 - val_loss: 0.7278 - val_accuracy: 0.7270\n",
            "Epoch 97/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.6095 - accuracy: 0.7555 - val_loss: 0.7312 - val_accuracy: 0.7219\n",
            "Epoch 98/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.6029 - accuracy: 0.7645 - val_loss: 0.7324 - val_accuracy: 0.7245\n",
            "Epoch 99/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.6070 - accuracy: 0.7698 - val_loss: 0.7267 - val_accuracy: 0.7270\n",
            "Epoch 100/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.5782 - accuracy: 0.7748 - val_loss: 0.7280 - val_accuracy: 0.7245\n",
            "Epoch 101/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.5718 - accuracy: 0.7873 - val_loss: 0.7227 - val_accuracy: 0.7372\n",
            "Epoch 102/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.6011 - accuracy: 0.7778 - val_loss: 0.7270 - val_accuracy: 0.7245\n",
            "Epoch 103/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.5810 - accuracy: 0.7847 - val_loss: 0.7237 - val_accuracy: 0.7296\n",
            "Epoch 104/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.5822 - accuracy: 0.7810 - val_loss: 0.7284 - val_accuracy: 0.7219\n",
            "Epoch 105/500\n",
            "37/37 [==============================] - 6s 174ms/step - loss: 0.5861 - accuracy: 0.7733 - val_loss: 0.7256 - val_accuracy: 0.7270\n",
            "Epoch 106/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.6020 - accuracy: 0.7785 - val_loss: 0.7226 - val_accuracy: 0.7347\n",
            "Epoch 107/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.5786 - accuracy: 0.7862 - val_loss: 0.7274 - val_accuracy: 0.7219\n",
            "Epoch 108/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.5613 - accuracy: 0.7849 - val_loss: 0.7230 - val_accuracy: 0.7296\n",
            "Epoch 109/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.5823 - accuracy: 0.7752 - val_loss: 0.7228 - val_accuracy: 0.7347\n",
            "Epoch 110/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.5776 - accuracy: 0.7763 - val_loss: 0.7226 - val_accuracy: 0.7372\n",
            "Epoch 111/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.5537 - accuracy: 0.7912 - val_loss: 0.7205 - val_accuracy: 0.7449\n",
            "Epoch 112/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.5488 - accuracy: 0.8083 - val_loss: 0.7235 - val_accuracy: 0.7296\n",
            "Epoch 113/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.5393 - accuracy: 0.7988 - val_loss: 0.7246 - val_accuracy: 0.7296\n",
            "Epoch 114/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.5777 - accuracy: 0.7872 - val_loss: 0.7214 - val_accuracy: 0.7296\n",
            "Epoch 115/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.6054 - accuracy: 0.7579 - val_loss: 0.7269 - val_accuracy: 0.7245\n",
            "Epoch 116/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.5841 - accuracy: 0.7623 - val_loss: 0.7210 - val_accuracy: 0.7296\n",
            "Epoch 117/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.5526 - accuracy: 0.7971 - val_loss: 0.7232 - val_accuracy: 0.7270\n",
            "Epoch 118/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.5319 - accuracy: 0.7982 - val_loss: 0.7192 - val_accuracy: 0.7372\n",
            "Epoch 119/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.5749 - accuracy: 0.7911 - val_loss: 0.7251 - val_accuracy: 0.7245\n",
            "Epoch 120/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.5834 - accuracy: 0.7817 - val_loss: 0.7193 - val_accuracy: 0.7398\n",
            "Epoch 121/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.5760 - accuracy: 0.7890 - val_loss: 0.7214 - val_accuracy: 0.7270\n",
            "Epoch 122/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.5547 - accuracy: 0.7885 - val_loss: 0.7208 - val_accuracy: 0.7296\n",
            "Epoch 123/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.5576 - accuracy: 0.7884 - val_loss: 0.7188 - val_accuracy: 0.7372\n",
            "Epoch 124/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.5780 - accuracy: 0.7837 - val_loss: 0.7236 - val_accuracy: 0.7219\n",
            "Epoch 125/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.5224 - accuracy: 0.8003 - val_loss: 0.7179 - val_accuracy: 0.7398\n",
            "Epoch 126/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.5379 - accuracy: 0.8013 - val_loss: 0.7189 - val_accuracy: 0.7296\n",
            "Epoch 127/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.5572 - accuracy: 0.7847 - val_loss: 0.7278 - val_accuracy: 0.7194\n",
            "Epoch 128/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.5898 - accuracy: 0.7583 - val_loss: 0.7270 - val_accuracy: 0.7194\n",
            "Epoch 129/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.5609 - accuracy: 0.7861 - val_loss: 0.7190 - val_accuracy: 0.7398\n",
            "Epoch 130/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.5371 - accuracy: 0.8065 - val_loss: 0.7161 - val_accuracy: 0.7372\n",
            "Epoch 131/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.5332 - accuracy: 0.8109 - val_loss: 0.7197 - val_accuracy: 0.7270\n",
            "Epoch 132/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.5553 - accuracy: 0.7790 - val_loss: 0.7236 - val_accuracy: 0.7219\n",
            "Epoch 133/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.5372 - accuracy: 0.7887 - val_loss: 0.7173 - val_accuracy: 0.7372\n",
            "Epoch 134/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.5470 - accuracy: 0.7872 - val_loss: 0.7180 - val_accuracy: 0.7347\n",
            "Epoch 135/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.5641 - accuracy: 0.7851 - val_loss: 0.7215 - val_accuracy: 0.7245\n",
            "Epoch 136/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.5300 - accuracy: 0.7892 - val_loss: 0.7191 - val_accuracy: 0.7296\n",
            "Epoch 137/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.5401 - accuracy: 0.7912 - val_loss: 0.7208 - val_accuracy: 0.7245\n",
            "Epoch 138/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.5657 - accuracy: 0.7820 - val_loss: 0.7166 - val_accuracy: 0.7372\n",
            "Epoch 139/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.5479 - accuracy: 0.7887 - val_loss: 0.7172 - val_accuracy: 0.7398\n",
            "Epoch 140/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.5255 - accuracy: 0.8065 - val_loss: 0.7193 - val_accuracy: 0.7296\n",
            "Epoch 141/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.5642 - accuracy: 0.7795 - val_loss: 0.7239 - val_accuracy: 0.7219\n",
            "Epoch 142/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.5241 - accuracy: 0.7963 - val_loss: 0.7257 - val_accuracy: 0.7194\n",
            "Epoch 143/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.5694 - accuracy: 0.7845 - val_loss: 0.7169 - val_accuracy: 0.7347\n",
            "Epoch 144/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.5652 - accuracy: 0.7862 - val_loss: 0.7155 - val_accuracy: 0.7372\n",
            "Epoch 145/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.5328 - accuracy: 0.8112 - val_loss: 0.7184 - val_accuracy: 0.7270\n",
            "Epoch 146/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.5469 - accuracy: 0.7993 - val_loss: 0.7177 - val_accuracy: 0.7270\n",
            "Epoch 147/500\n",
            "37/37 [==============================] - 6s 174ms/step - loss: 0.5042 - accuracy: 0.8101 - val_loss: 0.7177 - val_accuracy: 0.7270\n",
            "Epoch 148/500\n",
            "37/37 [==============================] - 6s 174ms/step - loss: 0.5674 - accuracy: 0.7862 - val_loss: 0.7250 - val_accuracy: 0.7143\n",
            "Epoch 149/500\n",
            "37/37 [==============================] - 6s 174ms/step - loss: 0.4962 - accuracy: 0.8103 - val_loss: 0.7137 - val_accuracy: 0.7423\n",
            "Epoch 150/500\n",
            "37/37 [==============================] - 6s 174ms/step - loss: 0.5393 - accuracy: 0.8059 - val_loss: 0.7168 - val_accuracy: 0.7321\n",
            "Epoch 151/500\n",
            "37/37 [==============================] - 6s 174ms/step - loss: 0.5252 - accuracy: 0.7964 - val_loss: 0.7167 - val_accuracy: 0.7372\n",
            "Epoch 152/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.5494 - accuracy: 0.7977 - val_loss: 0.7135 - val_accuracy: 0.7372\n",
            "Epoch 153/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.5391 - accuracy: 0.8035 - val_loss: 0.7181 - val_accuracy: 0.7219\n",
            "Epoch 154/500\n",
            "37/37 [==============================] - 6s 174ms/step - loss: 0.5620 - accuracy: 0.8019 - val_loss: 0.7208 - val_accuracy: 0.7245\n",
            "Epoch 155/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.5102 - accuracy: 0.8080 - val_loss: 0.7149 - val_accuracy: 0.7321\n",
            "Epoch 156/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.5080 - accuracy: 0.8121 - val_loss: 0.7185 - val_accuracy: 0.7321\n",
            "Epoch 157/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.5152 - accuracy: 0.8026 - val_loss: 0.7151 - val_accuracy: 0.7372\n",
            "Epoch 158/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.5644 - accuracy: 0.7857 - val_loss: 0.7169 - val_accuracy: 0.7321\n",
            "Epoch 159/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.5323 - accuracy: 0.7964 - val_loss: 0.7153 - val_accuracy: 0.7347\n",
            "Epoch 160/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.5512 - accuracy: 0.7937 - val_loss: 0.7139 - val_accuracy: 0.7347\n",
            "Epoch 161/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.5210 - accuracy: 0.8160 - val_loss: 0.7138 - val_accuracy: 0.7372\n",
            "Epoch 162/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.5132 - accuracy: 0.8151 - val_loss: 0.7203 - val_accuracy: 0.7347\n",
            "Epoch 163/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.5559 - accuracy: 0.7780 - val_loss: 0.7148 - val_accuracy: 0.7347\n",
            "Epoch 164/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.5257 - accuracy: 0.8053 - val_loss: 0.7146 - val_accuracy: 0.7321\n",
            "Epoch 165/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.5237 - accuracy: 0.7985 - val_loss: 0.7160 - val_accuracy: 0.7347\n",
            "Epoch 166/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.5141 - accuracy: 0.7975 - val_loss: 0.7126 - val_accuracy: 0.7372\n",
            "Epoch 167/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.5115 - accuracy: 0.8066 - val_loss: 0.7161 - val_accuracy: 0.7296\n",
            "Epoch 168/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.5044 - accuracy: 0.8158 - val_loss: 0.7149 - val_accuracy: 0.7321\n",
            "Epoch 169/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.5157 - accuracy: 0.8096 - val_loss: 0.7146 - val_accuracy: 0.7347\n",
            "Epoch 170/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.5275 - accuracy: 0.7960 - val_loss: 0.7146 - val_accuracy: 0.7347\n",
            "Epoch 171/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.5201 - accuracy: 0.8059 - val_loss: 0.7139 - val_accuracy: 0.7347\n",
            "Epoch 172/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.5117 - accuracy: 0.8235 - val_loss: 0.7160 - val_accuracy: 0.7296\n",
            "Epoch 173/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.5282 - accuracy: 0.8043 - val_loss: 0.7133 - val_accuracy: 0.7347\n",
            "Epoch 174/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.4986 - accuracy: 0.8278 - val_loss: 0.7220 - val_accuracy: 0.7194\n",
            "Epoch 175/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.5158 - accuracy: 0.8050 - val_loss: 0.7171 - val_accuracy: 0.7270\n",
            "Epoch 176/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.5362 - accuracy: 0.7972 - val_loss: 0.7135 - val_accuracy: 0.7398\n",
            "Epoch 177/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.5073 - accuracy: 0.8225 - val_loss: 0.7172 - val_accuracy: 0.7296\n",
            "Epoch 178/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.5208 - accuracy: 0.8016 - val_loss: 0.7137 - val_accuracy: 0.7347\n",
            "Epoch 179/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4750 - accuracy: 0.8344 - val_loss: 0.7151 - val_accuracy: 0.7296\n",
            "Epoch 180/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.4882 - accuracy: 0.8288 - val_loss: 0.7122 - val_accuracy: 0.7321\n",
            "Epoch 181/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.4974 - accuracy: 0.8187 - val_loss: 0.7130 - val_accuracy: 0.7347\n",
            "Epoch 182/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.5245 - accuracy: 0.8101 - val_loss: 0.7158 - val_accuracy: 0.7321\n",
            "Epoch 183/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.5108 - accuracy: 0.8129 - val_loss: 0.7120 - val_accuracy: 0.7398\n",
            "Epoch 184/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.5239 - accuracy: 0.8057 - val_loss: 0.7140 - val_accuracy: 0.7398\n",
            "Epoch 185/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.5365 - accuracy: 0.7987 - val_loss: 0.7179 - val_accuracy: 0.7245\n",
            "Epoch 186/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.5264 - accuracy: 0.8069 - val_loss: 0.7196 - val_accuracy: 0.7321\n",
            "Epoch 187/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4977 - accuracy: 0.8184 - val_loss: 0.7115 - val_accuracy: 0.7423\n",
            "Epoch 188/500\n",
            "37/37 [==============================] - 6s 177ms/step - loss: 0.4983 - accuracy: 0.8225 - val_loss: 0.7115 - val_accuracy: 0.7423\n",
            "Epoch 189/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4674 - accuracy: 0.8483 - val_loss: 0.7122 - val_accuracy: 0.7398\n",
            "Epoch 190/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.5102 - accuracy: 0.8215 - val_loss: 0.7115 - val_accuracy: 0.7398\n",
            "Epoch 191/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4588 - accuracy: 0.8438 - val_loss: 0.7125 - val_accuracy: 0.7423\n",
            "Epoch 192/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.5076 - accuracy: 0.8199 - val_loss: 0.7110 - val_accuracy: 0.7423\n",
            "Epoch 193/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.5057 - accuracy: 0.8245 - val_loss: 0.7135 - val_accuracy: 0.7372\n",
            "Epoch 194/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.4883 - accuracy: 0.8300 - val_loss: 0.7147 - val_accuracy: 0.7296\n",
            "Epoch 195/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.4801 - accuracy: 0.8201 - val_loss: 0.7136 - val_accuracy: 0.7423\n",
            "Epoch 196/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.4859 - accuracy: 0.8225 - val_loss: 0.7113 - val_accuracy: 0.7398\n",
            "Epoch 197/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.5028 - accuracy: 0.8182 - val_loss: 0.7129 - val_accuracy: 0.7398\n",
            "Epoch 198/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.5041 - accuracy: 0.8108 - val_loss: 0.7150 - val_accuracy: 0.7347\n",
            "Epoch 199/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.4709 - accuracy: 0.8333 - val_loss: 0.7133 - val_accuracy: 0.7372\n",
            "Epoch 200/500\n",
            "37/37 [==============================] - 6s 174ms/step - loss: 0.4967 - accuracy: 0.8257 - val_loss: 0.7150 - val_accuracy: 0.7321\n",
            "Epoch 201/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.4842 - accuracy: 0.8178 - val_loss: 0.7119 - val_accuracy: 0.7372\n",
            "Epoch 202/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.5075 - accuracy: 0.8134 - val_loss: 0.7158 - val_accuracy: 0.7321\n",
            "Epoch 203/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.4853 - accuracy: 0.8170 - val_loss: 0.7142 - val_accuracy: 0.7321\n",
            "Epoch 204/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.4883 - accuracy: 0.8190 - val_loss: 0.7165 - val_accuracy: 0.7372\n",
            "Epoch 205/500\n",
            "37/37 [==============================] - 6s 174ms/step - loss: 0.5036 - accuracy: 0.8198 - val_loss: 0.7144 - val_accuracy: 0.7296\n",
            "Epoch 206/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.5041 - accuracy: 0.8167 - val_loss: 0.7112 - val_accuracy: 0.7423\n",
            "Epoch 207/500\n",
            "37/37 [==============================] - 6s 174ms/step - loss: 0.5043 - accuracy: 0.8159 - val_loss: 0.7154 - val_accuracy: 0.7296\n",
            "Epoch 208/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.5050 - accuracy: 0.8153 - val_loss: 0.7131 - val_accuracy: 0.7321\n",
            "Epoch 209/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.5061 - accuracy: 0.7983 - val_loss: 0.7145 - val_accuracy: 0.7321\n",
            "Epoch 210/500\n",
            "37/37 [==============================] - 6s 174ms/step - loss: 0.4809 - accuracy: 0.8318 - val_loss: 0.7173 - val_accuracy: 0.7347\n",
            "Epoch 211/500\n",
            "37/37 [==============================] - 6s 174ms/step - loss: 0.4928 - accuracy: 0.8214 - val_loss: 0.7165 - val_accuracy: 0.7245\n",
            "Epoch 212/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4535 - accuracy: 0.8431 - val_loss: 0.7116 - val_accuracy: 0.7372\n",
            "Epoch 213/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.4686 - accuracy: 0.8372 - val_loss: 0.7123 - val_accuracy: 0.7372\n",
            "Epoch 214/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4619 - accuracy: 0.8458 - val_loss: 0.7116 - val_accuracy: 0.7347\n",
            "Epoch 215/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4798 - accuracy: 0.8138 - val_loss: 0.7137 - val_accuracy: 0.7372\n",
            "Epoch 216/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4663 - accuracy: 0.8203 - val_loss: 0.7137 - val_accuracy: 0.7296\n",
            "Epoch 217/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4763 - accuracy: 0.8213 - val_loss: 0.7157 - val_accuracy: 0.7347\n",
            "Epoch 218/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.4699 - accuracy: 0.8362 - val_loss: 0.7108 - val_accuracy: 0.7347\n",
            "Epoch 219/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.5087 - accuracy: 0.8217 - val_loss: 0.7182 - val_accuracy: 0.7321\n",
            "Epoch 220/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4838 - accuracy: 0.8250 - val_loss: 0.7131 - val_accuracy: 0.7372\n",
            "Epoch 221/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.4832 - accuracy: 0.8246 - val_loss: 0.7151 - val_accuracy: 0.7321\n",
            "Epoch 222/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.5050 - accuracy: 0.8076 - val_loss: 0.7145 - val_accuracy: 0.7270\n",
            "Epoch 223/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4822 - accuracy: 0.8164 - val_loss: 0.7124 - val_accuracy: 0.7347\n",
            "Epoch 224/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4671 - accuracy: 0.8321 - val_loss: 0.7140 - val_accuracy: 0.7347\n",
            "Epoch 225/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4762 - accuracy: 0.8294 - val_loss: 0.7147 - val_accuracy: 0.7372\n",
            "Epoch 226/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4579 - accuracy: 0.8337 - val_loss: 0.7127 - val_accuracy: 0.7321\n",
            "Epoch 227/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.4900 - accuracy: 0.8279 - val_loss: 0.7136 - val_accuracy: 0.7296\n",
            "Epoch 228/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4718 - accuracy: 0.8355 - val_loss: 0.7150 - val_accuracy: 0.7296\n",
            "Epoch 229/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4647 - accuracy: 0.8312 - val_loss: 0.7141 - val_accuracy: 0.7321\n",
            "Epoch 230/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.4694 - accuracy: 0.8247 - val_loss: 0.7141 - val_accuracy: 0.7347\n",
            "Epoch 231/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.5158 - accuracy: 0.8128 - val_loss: 0.7174 - val_accuracy: 0.7270\n",
            "Epoch 232/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.5009 - accuracy: 0.8225 - val_loss: 0.7169 - val_accuracy: 0.7296\n",
            "Epoch 233/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.4835 - accuracy: 0.8062 - val_loss: 0.7123 - val_accuracy: 0.7347\n",
            "Epoch 234/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.4642 - accuracy: 0.8278 - val_loss: 0.7202 - val_accuracy: 0.7296\n",
            "Epoch 235/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4700 - accuracy: 0.8198 - val_loss: 0.7129 - val_accuracy: 0.7347\n",
            "Epoch 236/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4924 - accuracy: 0.8284 - val_loss: 0.7112 - val_accuracy: 0.7398\n",
            "Epoch 237/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.4929 - accuracy: 0.8169 - val_loss: 0.7135 - val_accuracy: 0.7347\n",
            "Epoch 238/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.4791 - accuracy: 0.8207 - val_loss: 0.7145 - val_accuracy: 0.7321\n",
            "Epoch 239/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4841 - accuracy: 0.8201 - val_loss: 0.7125 - val_accuracy: 0.7423\n",
            "Epoch 240/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.4632 - accuracy: 0.8404 - val_loss: 0.7201 - val_accuracy: 0.7270\n",
            "Epoch 241/500\n",
            "37/37 [==============================] - 6s 174ms/step - loss: 0.4935 - accuracy: 0.8092 - val_loss: 0.7233 - val_accuracy: 0.7245\n",
            "Epoch 242/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.4637 - accuracy: 0.8365 - val_loss: 0.7117 - val_accuracy: 0.7321\n",
            "Epoch 243/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.4592 - accuracy: 0.8302 - val_loss: 0.7130 - val_accuracy: 0.7321\n",
            "Epoch 244/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.4596 - accuracy: 0.8337 - val_loss: 0.7142 - val_accuracy: 0.7296\n",
            "Epoch 245/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.4730 - accuracy: 0.8246 - val_loss: 0.7144 - val_accuracy: 0.7321\n",
            "Epoch 246/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.4632 - accuracy: 0.8290 - val_loss: 0.7125 - val_accuracy: 0.7372\n",
            "Epoch 247/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.4560 - accuracy: 0.8407 - val_loss: 0.7136 - val_accuracy: 0.7398\n",
            "Epoch 248/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.4763 - accuracy: 0.8267 - val_loss: 0.7144 - val_accuracy: 0.7296\n",
            "Epoch 249/500\n",
            "37/37 [==============================] - 6s 174ms/step - loss: 0.4828 - accuracy: 0.8229 - val_loss: 0.7154 - val_accuracy: 0.7347\n",
            "Epoch 250/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.4663 - accuracy: 0.8389 - val_loss: 0.7162 - val_accuracy: 0.7296\n",
            "Epoch 251/500\n",
            "37/37 [==============================] - 6s 174ms/step - loss: 0.4709 - accuracy: 0.8262 - val_loss: 0.7134 - val_accuracy: 0.7270\n",
            "Epoch 252/500\n",
            "37/37 [==============================] - 6s 174ms/step - loss: 0.4717 - accuracy: 0.8326 - val_loss: 0.7123 - val_accuracy: 0.7423\n",
            "Epoch 253/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.4538 - accuracy: 0.8509 - val_loss: 0.7138 - val_accuracy: 0.7296\n",
            "Epoch 254/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.5143 - accuracy: 0.8177 - val_loss: 0.7160 - val_accuracy: 0.7296\n",
            "Epoch 255/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.4743 - accuracy: 0.8224 - val_loss: 0.7140 - val_accuracy: 0.7372\n",
            "Epoch 256/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.4583 - accuracy: 0.8340 - val_loss: 0.7145 - val_accuracy: 0.7296\n",
            "Epoch 257/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.4749 - accuracy: 0.8236 - val_loss: 0.7137 - val_accuracy: 0.7321\n",
            "Epoch 258/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.4456 - accuracy: 0.8461 - val_loss: 0.7137 - val_accuracy: 0.7296\n",
            "Epoch 259/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4936 - accuracy: 0.8211 - val_loss: 0.7204 - val_accuracy: 0.7321\n",
            "Epoch 260/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.4685 - accuracy: 0.8275 - val_loss: 0.7146 - val_accuracy: 0.7321\n",
            "Epoch 261/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4481 - accuracy: 0.8477 - val_loss: 0.7147 - val_accuracy: 0.7398\n",
            "Epoch 262/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4736 - accuracy: 0.8163 - val_loss: 0.7154 - val_accuracy: 0.7347\n",
            "Epoch 263/500\n",
            "37/37 [==============================] - 6s 177ms/step - loss: 0.4467 - accuracy: 0.8449 - val_loss: 0.7132 - val_accuracy: 0.7347\n",
            "Epoch 264/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4639 - accuracy: 0.8333 - val_loss: 0.7164 - val_accuracy: 0.7296\n",
            "Epoch 265/500\n",
            "37/37 [==============================] - 6s 177ms/step - loss: 0.4590 - accuracy: 0.8421 - val_loss: 0.7143 - val_accuracy: 0.7347\n",
            "Epoch 266/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4863 - accuracy: 0.8123 - val_loss: 0.7168 - val_accuracy: 0.7296\n",
            "Epoch 267/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4400 - accuracy: 0.8476 - val_loss: 0.7149 - val_accuracy: 0.7321\n",
            "Epoch 268/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4477 - accuracy: 0.8450 - val_loss: 0.7144 - val_accuracy: 0.7372\n",
            "Epoch 269/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4633 - accuracy: 0.8209 - val_loss: 0.7141 - val_accuracy: 0.7347\n",
            "Epoch 270/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4750 - accuracy: 0.8317 - val_loss: 0.7144 - val_accuracy: 0.7321\n",
            "Epoch 271/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4238 - accuracy: 0.8488 - val_loss: 0.7162 - val_accuracy: 0.7372\n",
            "Epoch 272/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4488 - accuracy: 0.8329 - val_loss: 0.7160 - val_accuracy: 0.7296\n",
            "Epoch 273/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.4426 - accuracy: 0.8284 - val_loss: 0.7146 - val_accuracy: 0.7321\n",
            "Epoch 274/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4556 - accuracy: 0.8361 - val_loss: 0.7155 - val_accuracy: 0.7398\n",
            "Epoch 275/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4579 - accuracy: 0.8284 - val_loss: 0.7158 - val_accuracy: 0.7347\n",
            "Epoch 276/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4125 - accuracy: 0.8537 - val_loss: 0.7138 - val_accuracy: 0.7398\n",
            "Epoch 277/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.4544 - accuracy: 0.8397 - val_loss: 0.7160 - val_accuracy: 0.7347\n",
            "Epoch 278/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4490 - accuracy: 0.8349 - val_loss: 0.7176 - val_accuracy: 0.7296\n",
            "Epoch 279/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4388 - accuracy: 0.8476 - val_loss: 0.7155 - val_accuracy: 0.7398\n",
            "Epoch 280/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.4637 - accuracy: 0.8350 - val_loss: 0.7216 - val_accuracy: 0.7270\n",
            "Epoch 281/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4428 - accuracy: 0.8260 - val_loss: 0.7152 - val_accuracy: 0.7372\n",
            "Epoch 282/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.4853 - accuracy: 0.8126 - val_loss: 0.7208 - val_accuracy: 0.7398\n",
            "Epoch 283/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4481 - accuracy: 0.8397 - val_loss: 0.7150 - val_accuracy: 0.7321\n",
            "Epoch 284/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4480 - accuracy: 0.8453 - val_loss: 0.7154 - val_accuracy: 0.7321\n",
            "Epoch 285/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4780 - accuracy: 0.8274 - val_loss: 0.7176 - val_accuracy: 0.7296\n",
            "Epoch 286/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4398 - accuracy: 0.8426 - val_loss: 0.7139 - val_accuracy: 0.7372\n",
            "Epoch 287/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4591 - accuracy: 0.8353 - val_loss: 0.7154 - val_accuracy: 0.7347\n",
            "Epoch 288/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4293 - accuracy: 0.8467 - val_loss: 0.7169 - val_accuracy: 0.7398\n",
            "Epoch 289/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4682 - accuracy: 0.8111 - val_loss: 0.7163 - val_accuracy: 0.7347\n",
            "Epoch 290/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.4410 - accuracy: 0.8472 - val_loss: 0.7185 - val_accuracy: 0.7321\n",
            "Epoch 291/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4624 - accuracy: 0.8321 - val_loss: 0.7165 - val_accuracy: 0.7372\n",
            "Epoch 292/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4723 - accuracy: 0.8207 - val_loss: 0.7174 - val_accuracy: 0.7347\n",
            "Epoch 293/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.4256 - accuracy: 0.8518 - val_loss: 0.7159 - val_accuracy: 0.7347\n",
            "Epoch 294/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.4434 - accuracy: 0.8431 - val_loss: 0.7165 - val_accuracy: 0.7347\n",
            "Epoch 295/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.4525 - accuracy: 0.8292 - val_loss: 0.7164 - val_accuracy: 0.7321\n",
            "Epoch 296/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.4404 - accuracy: 0.8455 - val_loss: 0.7156 - val_accuracy: 0.7347\n",
            "Epoch 297/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4513 - accuracy: 0.8424 - val_loss: 0.7192 - val_accuracy: 0.7296\n",
            "Epoch 298/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4322 - accuracy: 0.8421 - val_loss: 0.7166 - val_accuracy: 0.7347\n",
            "Epoch 299/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4574 - accuracy: 0.8274 - val_loss: 0.7165 - val_accuracy: 0.7321\n",
            "Epoch 300/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.4198 - accuracy: 0.8550 - val_loss: 0.7155 - val_accuracy: 0.7372\n",
            "Epoch 301/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4663 - accuracy: 0.8351 - val_loss: 0.7189 - val_accuracy: 0.7321\n",
            "Epoch 302/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4387 - accuracy: 0.8474 - val_loss: 0.7154 - val_accuracy: 0.7372\n",
            "Epoch 303/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.4616 - accuracy: 0.8427 - val_loss: 0.7175 - val_accuracy: 0.7372\n",
            "Epoch 304/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4532 - accuracy: 0.8398 - val_loss: 0.7151 - val_accuracy: 0.7347\n",
            "Epoch 305/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.4245 - accuracy: 0.8556 - val_loss: 0.7181 - val_accuracy: 0.7347\n",
            "Epoch 306/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4194 - accuracy: 0.8524 - val_loss: 0.7154 - val_accuracy: 0.7347\n",
            "Epoch 307/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.4293 - accuracy: 0.8512 - val_loss: 0.7173 - val_accuracy: 0.7372\n",
            "Epoch 308/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.4038 - accuracy: 0.8591 - val_loss: 0.7159 - val_accuracy: 0.7270\n",
            "Epoch 309/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4447 - accuracy: 0.8442 - val_loss: 0.7164 - val_accuracy: 0.7296\n",
            "Epoch 310/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.4296 - accuracy: 0.8564 - val_loss: 0.7178 - val_accuracy: 0.7296\n",
            "Epoch 311/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.4554 - accuracy: 0.8345 - val_loss: 0.7184 - val_accuracy: 0.7347\n",
            "Epoch 312/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.4358 - accuracy: 0.8380 - val_loss: 0.7177 - val_accuracy: 0.7398\n",
            "Epoch 313/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4199 - accuracy: 0.8684 - val_loss: 0.7214 - val_accuracy: 0.7321\n",
            "Epoch 314/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4350 - accuracy: 0.8316 - val_loss: 0.7210 - val_accuracy: 0.7321\n",
            "Epoch 315/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4412 - accuracy: 0.8440 - val_loss: 0.7166 - val_accuracy: 0.7347\n",
            "Epoch 316/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4566 - accuracy: 0.8383 - val_loss: 0.7202 - val_accuracy: 0.7321\n",
            "Epoch 317/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.4380 - accuracy: 0.8345 - val_loss: 0.7199 - val_accuracy: 0.7347\n",
            "Epoch 318/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.4205 - accuracy: 0.8429 - val_loss: 0.7176 - val_accuracy: 0.7296\n",
            "Epoch 319/500\n",
            "37/37 [==============================] - 6s 177ms/step - loss: 0.4364 - accuracy: 0.8451 - val_loss: 0.7237 - val_accuracy: 0.7321\n",
            "Epoch 320/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.4121 - accuracy: 0.8502 - val_loss: 0.7167 - val_accuracy: 0.7296\n",
            "Epoch 321/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4302 - accuracy: 0.8485 - val_loss: 0.7193 - val_accuracy: 0.7347\n",
            "Epoch 322/500\n",
            "37/37 [==============================] - 6s 177ms/step - loss: 0.4230 - accuracy: 0.8447 - val_loss: 0.7187 - val_accuracy: 0.7296\n",
            "Epoch 323/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.4493 - accuracy: 0.8417 - val_loss: 0.7173 - val_accuracy: 0.7321\n",
            "Epoch 324/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4476 - accuracy: 0.8383 - val_loss: 0.7195 - val_accuracy: 0.7321\n",
            "Epoch 325/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4512 - accuracy: 0.8366 - val_loss: 0.7232 - val_accuracy: 0.7398\n",
            "Epoch 326/500\n",
            "37/37 [==============================] - 6s 177ms/step - loss: 0.4205 - accuracy: 0.8508 - val_loss: 0.7169 - val_accuracy: 0.7372\n",
            "Epoch 327/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4188 - accuracy: 0.8613 - val_loss: 0.7218 - val_accuracy: 0.7449\n",
            "Epoch 328/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4242 - accuracy: 0.8573 - val_loss: 0.7198 - val_accuracy: 0.7372\n",
            "Epoch 329/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4299 - accuracy: 0.8550 - val_loss: 0.7200 - val_accuracy: 0.7398\n",
            "Epoch 330/500\n",
            "37/37 [==============================] - 6s 177ms/step - loss: 0.4387 - accuracy: 0.8424 - val_loss: 0.7187 - val_accuracy: 0.7398\n",
            "Epoch 331/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4168 - accuracy: 0.8511 - val_loss: 0.7203 - val_accuracy: 0.7372\n",
            "Epoch 332/500\n",
            "37/37 [==============================] - 6s 177ms/step - loss: 0.4369 - accuracy: 0.8466 - val_loss: 0.7234 - val_accuracy: 0.7372\n",
            "Epoch 333/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4119 - accuracy: 0.8466 - val_loss: 0.7185 - val_accuracy: 0.7372\n",
            "Epoch 334/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4426 - accuracy: 0.8366 - val_loss: 0.7255 - val_accuracy: 0.7347\n",
            "Epoch 335/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4274 - accuracy: 0.8440 - val_loss: 0.7210 - val_accuracy: 0.7347\n",
            "Epoch 336/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4447 - accuracy: 0.8389 - val_loss: 0.7231 - val_accuracy: 0.7321\n",
            "Epoch 337/500\n",
            "37/37 [==============================] - 6s 177ms/step - loss: 0.4379 - accuracy: 0.8400 - val_loss: 0.7216 - val_accuracy: 0.7347\n",
            "Epoch 338/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4446 - accuracy: 0.8379 - val_loss: 0.7175 - val_accuracy: 0.7423\n",
            "Epoch 339/500\n",
            "37/37 [==============================] - 6s 177ms/step - loss: 0.4528 - accuracy: 0.8335 - val_loss: 0.7204 - val_accuracy: 0.7372\n",
            "Epoch 340/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4430 - accuracy: 0.8462 - val_loss: 0.7227 - val_accuracy: 0.7321\n",
            "Epoch 341/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4121 - accuracy: 0.8618 - val_loss: 0.7215 - val_accuracy: 0.7372\n",
            "Epoch 342/500\n",
            "37/37 [==============================] - 6s 177ms/step - loss: 0.4053 - accuracy: 0.8638 - val_loss: 0.7185 - val_accuracy: 0.7347\n",
            "Epoch 343/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4397 - accuracy: 0.8474 - val_loss: 0.7192 - val_accuracy: 0.7296\n",
            "Epoch 344/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.4112 - accuracy: 0.8649 - val_loss: 0.7203 - val_accuracy: 0.7321\n",
            "Epoch 345/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4109 - accuracy: 0.8543 - val_loss: 0.7191 - val_accuracy: 0.7347\n",
            "Epoch 346/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4456 - accuracy: 0.8353 - val_loss: 0.7244 - val_accuracy: 0.7347\n",
            "Epoch 347/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4225 - accuracy: 0.8552 - val_loss: 0.7199 - val_accuracy: 0.7296\n",
            "Epoch 348/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4321 - accuracy: 0.8481 - val_loss: 0.7224 - val_accuracy: 0.7321\n",
            "Epoch 349/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4064 - accuracy: 0.8600 - val_loss: 0.7199 - val_accuracy: 0.7347\n",
            "Epoch 350/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.3900 - accuracy: 0.8693 - val_loss: 0.7201 - val_accuracy: 0.7347\n",
            "Epoch 351/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.4197 - accuracy: 0.8498 - val_loss: 0.7210 - val_accuracy: 0.7347\n",
            "Epoch 352/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.4209 - accuracy: 0.8550 - val_loss: 0.7215 - val_accuracy: 0.7474\n",
            "Epoch 353/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.4280 - accuracy: 0.8622 - val_loss: 0.7219 - val_accuracy: 0.7321\n",
            "Epoch 354/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.4094 - accuracy: 0.8629 - val_loss: 0.7204 - val_accuracy: 0.7372\n",
            "Epoch 355/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.4507 - accuracy: 0.8376 - val_loss: 0.7280 - val_accuracy: 0.7347\n",
            "Epoch 356/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.4094 - accuracy: 0.8500 - val_loss: 0.7256 - val_accuracy: 0.7347\n",
            "Epoch 357/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.3992 - accuracy: 0.8656 - val_loss: 0.7210 - val_accuracy: 0.7347\n",
            "Epoch 358/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.4433 - accuracy: 0.8401 - val_loss: 0.7264 - val_accuracy: 0.7321\n",
            "Epoch 359/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4289 - accuracy: 0.8438 - val_loss: 0.7213 - val_accuracy: 0.7296\n",
            "Epoch 360/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4151 - accuracy: 0.8511 - val_loss: 0.7251 - val_accuracy: 0.7347\n",
            "Epoch 361/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.4166 - accuracy: 0.8623 - val_loss: 0.7257 - val_accuracy: 0.7296\n",
            "Epoch 362/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4162 - accuracy: 0.8575 - val_loss: 0.7236 - val_accuracy: 0.7321\n",
            "Epoch 363/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4122 - accuracy: 0.8583 - val_loss: 0.7241 - val_accuracy: 0.7321\n",
            "Epoch 364/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4500 - accuracy: 0.8484 - val_loss: 0.7261 - val_accuracy: 0.7398\n",
            "Epoch 365/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4415 - accuracy: 0.8452 - val_loss: 0.7232 - val_accuracy: 0.7347\n",
            "Epoch 366/500\n",
            "37/37 [==============================] - 6s 177ms/step - loss: 0.4146 - accuracy: 0.8567 - val_loss: 0.7227 - val_accuracy: 0.7296\n",
            "Epoch 367/500\n",
            "37/37 [==============================] - 6s 177ms/step - loss: 0.4223 - accuracy: 0.8521 - val_loss: 0.7211 - val_accuracy: 0.7398\n",
            "Epoch 368/500\n",
            "37/37 [==============================] - 6s 177ms/step - loss: 0.4211 - accuracy: 0.8402 - val_loss: 0.7236 - val_accuracy: 0.7372\n",
            "Epoch 369/500\n",
            "37/37 [==============================] - 6s 177ms/step - loss: 0.4072 - accuracy: 0.8688 - val_loss: 0.7260 - val_accuracy: 0.7449\n",
            "Epoch 370/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.3971 - accuracy: 0.8556 - val_loss: 0.7221 - val_accuracy: 0.7347\n",
            "Epoch 371/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4044 - accuracy: 0.8588 - val_loss: 0.7217 - val_accuracy: 0.7321\n",
            "Epoch 372/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4398 - accuracy: 0.8487 - val_loss: 0.7240 - val_accuracy: 0.7347\n",
            "Epoch 373/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4288 - accuracy: 0.8469 - val_loss: 0.7287 - val_accuracy: 0.7321\n",
            "Epoch 374/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4128 - accuracy: 0.8583 - val_loss: 0.7230 - val_accuracy: 0.7296\n",
            "Epoch 375/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4148 - accuracy: 0.8513 - val_loss: 0.7236 - val_accuracy: 0.7321\n",
            "Epoch 376/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4397 - accuracy: 0.8364 - val_loss: 0.7259 - val_accuracy: 0.7347\n",
            "Epoch 377/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.4291 - accuracy: 0.8457 - val_loss: 0.7221 - val_accuracy: 0.7372\n",
            "Epoch 378/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4017 - accuracy: 0.8475 - val_loss: 0.7237 - val_accuracy: 0.7296\n",
            "Epoch 379/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.4310 - accuracy: 0.8493 - val_loss: 0.7262 - val_accuracy: 0.7372\n",
            "Epoch 380/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4025 - accuracy: 0.8600 - val_loss: 0.7238 - val_accuracy: 0.7372\n",
            "Epoch 381/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.3968 - accuracy: 0.8728 - val_loss: 0.7224 - val_accuracy: 0.7398\n",
            "Epoch 382/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4072 - accuracy: 0.8677 - val_loss: 0.7274 - val_accuracy: 0.7321\n",
            "Epoch 383/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4147 - accuracy: 0.8590 - val_loss: 0.7237 - val_accuracy: 0.7398\n",
            "Epoch 384/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.3816 - accuracy: 0.8753 - val_loss: 0.7234 - val_accuracy: 0.7347\n",
            "Epoch 385/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4040 - accuracy: 0.8651 - val_loss: 0.7253 - val_accuracy: 0.7372\n",
            "Epoch 386/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4124 - accuracy: 0.8524 - val_loss: 0.7243 - val_accuracy: 0.7296\n",
            "Epoch 387/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.3830 - accuracy: 0.8679 - val_loss: 0.7241 - val_accuracy: 0.7398\n",
            "Epoch 388/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4121 - accuracy: 0.8568 - val_loss: 0.7261 - val_accuracy: 0.7321\n",
            "Epoch 389/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4031 - accuracy: 0.8679 - val_loss: 0.7238 - val_accuracy: 0.7347\n",
            "Epoch 390/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.3988 - accuracy: 0.8599 - val_loss: 0.7272 - val_accuracy: 0.7321\n",
            "Epoch 391/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.3955 - accuracy: 0.8627 - val_loss: 0.7259 - val_accuracy: 0.7398\n",
            "Epoch 392/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.3845 - accuracy: 0.8774 - val_loss: 0.7237 - val_accuracy: 0.7347\n",
            "Epoch 393/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4128 - accuracy: 0.8594 - val_loss: 0.7250 - val_accuracy: 0.7398\n",
            "Epoch 394/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.4084 - accuracy: 0.8629 - val_loss: 0.7261 - val_accuracy: 0.7347\n",
            "Epoch 395/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.4193 - accuracy: 0.8532 - val_loss: 0.7288 - val_accuracy: 0.7321\n",
            "Epoch 396/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.4063 - accuracy: 0.8628 - val_loss: 0.7244 - val_accuracy: 0.7398\n",
            "Epoch 397/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.4278 - accuracy: 0.8499 - val_loss: 0.7266 - val_accuracy: 0.7372\n",
            "Epoch 398/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4001 - accuracy: 0.8494 - val_loss: 0.7276 - val_accuracy: 0.7347\n",
            "Epoch 399/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4099 - accuracy: 0.8591 - val_loss: 0.7267 - val_accuracy: 0.7372\n",
            "Epoch 400/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.3962 - accuracy: 0.8659 - val_loss: 0.7240 - val_accuracy: 0.7398\n",
            "Epoch 401/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4154 - accuracy: 0.8534 - val_loss: 0.7254 - val_accuracy: 0.7372\n",
            "Epoch 402/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4061 - accuracy: 0.8532 - val_loss: 0.7247 - val_accuracy: 0.7372\n",
            "Epoch 403/500\n",
            "37/37 [==============================] - 6s 177ms/step - loss: 0.4101 - accuracy: 0.8589 - val_loss: 0.7312 - val_accuracy: 0.7321\n",
            "Epoch 404/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4018 - accuracy: 0.8507 - val_loss: 0.7250 - val_accuracy: 0.7372\n",
            "Epoch 405/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4265 - accuracy: 0.8460 - val_loss: 0.7316 - val_accuracy: 0.7321\n",
            "Epoch 406/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.3851 - accuracy: 0.8698 - val_loss: 0.7281 - val_accuracy: 0.7423\n",
            "Epoch 407/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4402 - accuracy: 0.8512 - val_loss: 0.7330 - val_accuracy: 0.7296\n",
            "Epoch 408/500\n",
            "37/37 [==============================] - 6s 177ms/step - loss: 0.3781 - accuracy: 0.8594 - val_loss: 0.7274 - val_accuracy: 0.7449\n",
            "Epoch 409/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.3932 - accuracy: 0.8578 - val_loss: 0.7266 - val_accuracy: 0.7423\n",
            "Epoch 410/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.3943 - accuracy: 0.8762 - val_loss: 0.7276 - val_accuracy: 0.7321\n",
            "Epoch 411/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4102 - accuracy: 0.8510 - val_loss: 0.7296 - val_accuracy: 0.7347\n",
            "Epoch 412/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4095 - accuracy: 0.8591 - val_loss: 0.7309 - val_accuracy: 0.7347\n",
            "Epoch 413/500\n",
            "37/37 [==============================] - 7s 177ms/step - loss: 0.4071 - accuracy: 0.8560 - val_loss: 0.7284 - val_accuracy: 0.7347\n",
            "Epoch 414/500\n",
            "37/37 [==============================] - 6s 177ms/step - loss: 0.3770 - accuracy: 0.8680 - val_loss: 0.7263 - val_accuracy: 0.7372\n",
            "Epoch 415/500\n",
            "37/37 [==============================] - 6s 177ms/step - loss: 0.4290 - accuracy: 0.8441 - val_loss: 0.7315 - val_accuracy: 0.7372\n",
            "Epoch 416/500\n",
            "37/37 [==============================] - 6s 177ms/step - loss: 0.4018 - accuracy: 0.8674 - val_loss: 0.7264 - val_accuracy: 0.7347\n",
            "Epoch 417/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.3834 - accuracy: 0.8721 - val_loss: 0.7293 - val_accuracy: 0.7372\n",
            "Epoch 418/500\n",
            "37/37 [==============================] - 6s 177ms/step - loss: 0.3993 - accuracy: 0.8557 - val_loss: 0.7316 - val_accuracy: 0.7372\n",
            "Epoch 419/500\n",
            "37/37 [==============================] - 7s 178ms/step - loss: 0.4046 - accuracy: 0.8579 - val_loss: 0.7278 - val_accuracy: 0.7372\n",
            "Epoch 420/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.3819 - accuracy: 0.8778 - val_loss: 0.7311 - val_accuracy: 0.7321\n",
            "Epoch 421/500\n",
            "37/37 [==============================] - 6s 177ms/step - loss: 0.3936 - accuracy: 0.8615 - val_loss: 0.7290 - val_accuracy: 0.7423\n",
            "Epoch 422/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4172 - accuracy: 0.8453 - val_loss: 0.7318 - val_accuracy: 0.7321\n",
            "Epoch 423/500\n",
            "37/37 [==============================] - 6s 177ms/step - loss: 0.4035 - accuracy: 0.8530 - val_loss: 0.7318 - val_accuracy: 0.7372\n",
            "Epoch 424/500\n",
            "37/37 [==============================] - 7s 177ms/step - loss: 0.3844 - accuracy: 0.8673 - val_loss: 0.7276 - val_accuracy: 0.7347\n",
            "Epoch 425/500\n",
            "37/37 [==============================] - 6s 177ms/step - loss: 0.4243 - accuracy: 0.8494 - val_loss: 0.7301 - val_accuracy: 0.7321\n",
            "Epoch 426/500\n",
            "37/37 [==============================] - 6s 177ms/step - loss: 0.3697 - accuracy: 0.8806 - val_loss: 0.7279 - val_accuracy: 0.7423\n",
            "Epoch 427/500\n",
            "37/37 [==============================] - 6s 177ms/step - loss: 0.4132 - accuracy: 0.8400 - val_loss: 0.7297 - val_accuracy: 0.7398\n",
            "Epoch 428/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4241 - accuracy: 0.8400 - val_loss: 0.7294 - val_accuracy: 0.7372\n",
            "Epoch 429/500\n",
            "37/37 [==============================] - 6s 177ms/step - loss: 0.3957 - accuracy: 0.8603 - val_loss: 0.7283 - val_accuracy: 0.7372\n",
            "Epoch 430/500\n",
            "37/37 [==============================] - 7s 177ms/step - loss: 0.4006 - accuracy: 0.8450 - val_loss: 0.7348 - val_accuracy: 0.7347\n",
            "Epoch 431/500\n",
            "37/37 [==============================] - 7s 177ms/step - loss: 0.3941 - accuracy: 0.8623 - val_loss: 0.7282 - val_accuracy: 0.7398\n",
            "Epoch 432/500\n",
            "37/37 [==============================] - 7s 177ms/step - loss: 0.3678 - accuracy: 0.8831 - val_loss: 0.7320 - val_accuracy: 0.7347\n",
            "Epoch 433/500\n",
            "37/37 [==============================] - 6s 177ms/step - loss: 0.4108 - accuracy: 0.8558 - val_loss: 0.7333 - val_accuracy: 0.7372\n",
            "Epoch 434/500\n",
            "37/37 [==============================] - 6s 177ms/step - loss: 0.3972 - accuracy: 0.8601 - val_loss: 0.7294 - val_accuracy: 0.7347\n",
            "Epoch 435/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.3774 - accuracy: 0.8689 - val_loss: 0.7312 - val_accuracy: 0.7449\n",
            "Epoch 436/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.3817 - accuracy: 0.8701 - val_loss: 0.7304 - val_accuracy: 0.7398\n",
            "Epoch 437/500\n",
            "37/37 [==============================] - 6s 177ms/step - loss: 0.3950 - accuracy: 0.8581 - val_loss: 0.7291 - val_accuracy: 0.7347\n",
            "Epoch 438/500\n",
            "37/37 [==============================] - 7s 177ms/step - loss: 0.3697 - accuracy: 0.8785 - val_loss: 0.7323 - val_accuracy: 0.7398\n",
            "Epoch 439/500\n",
            "37/37 [==============================] - 6s 177ms/step - loss: 0.4255 - accuracy: 0.8545 - val_loss: 0.7349 - val_accuracy: 0.7347\n",
            "Epoch 440/500\n",
            "37/37 [==============================] - 7s 177ms/step - loss: 0.3865 - accuracy: 0.8637 - val_loss: 0.7322 - val_accuracy: 0.7398\n",
            "Epoch 441/500\n",
            "37/37 [==============================] - 6s 177ms/step - loss: 0.4096 - accuracy: 0.8581 - val_loss: 0.7321 - val_accuracy: 0.7423\n",
            "Epoch 442/500\n",
            "37/37 [==============================] - 7s 177ms/step - loss: 0.3730 - accuracy: 0.8631 - val_loss: 0.7306 - val_accuracy: 0.7398\n",
            "Epoch 443/500\n",
            "37/37 [==============================] - 7s 177ms/step - loss: 0.3643 - accuracy: 0.8730 - val_loss: 0.7344 - val_accuracy: 0.7449\n",
            "Epoch 444/500\n",
            "37/37 [==============================] - 6s 177ms/step - loss: 0.3853 - accuracy: 0.8693 - val_loss: 0.7317 - val_accuracy: 0.7372\n",
            "Epoch 445/500\n",
            "37/37 [==============================] - 6s 177ms/step - loss: 0.3874 - accuracy: 0.8706 - val_loss: 0.7317 - val_accuracy: 0.7372\n",
            "Epoch 446/500\n",
            "37/37 [==============================] - 6s 177ms/step - loss: 0.3950 - accuracy: 0.8600 - val_loss: 0.7362 - val_accuracy: 0.7372\n",
            "Epoch 447/500\n",
            "37/37 [==============================] - 7s 177ms/step - loss: 0.4087 - accuracy: 0.8532 - val_loss: 0.7334 - val_accuracy: 0.7398\n",
            "Epoch 448/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.3643 - accuracy: 0.8743 - val_loss: 0.7324 - val_accuracy: 0.7347\n",
            "Epoch 449/500\n",
            "37/37 [==============================] - 6s 177ms/step - loss: 0.3941 - accuracy: 0.8637 - val_loss: 0.7335 - val_accuracy: 0.7372\n",
            "Epoch 450/500\n",
            "37/37 [==============================] - 7s 177ms/step - loss: 0.3918 - accuracy: 0.8593 - val_loss: 0.7336 - val_accuracy: 0.7347\n",
            "Epoch 451/500\n",
            "37/37 [==============================] - 6s 177ms/step - loss: 0.3677 - accuracy: 0.8740 - val_loss: 0.7323 - val_accuracy: 0.7321\n",
            "Epoch 452/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.3648 - accuracy: 0.8711 - val_loss: 0.7315 - val_accuracy: 0.7372\n",
            "Epoch 453/500\n",
            "37/37 [==============================] - 6s 177ms/step - loss: 0.3725 - accuracy: 0.8695 - val_loss: 0.7338 - val_accuracy: 0.7398\n",
            "Epoch 454/500\n",
            "37/37 [==============================] - 7s 177ms/step - loss: 0.3544 - accuracy: 0.8775 - val_loss: 0.7312 - val_accuracy: 0.7372\n",
            "Epoch 455/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.3793 - accuracy: 0.8719 - val_loss: 0.7315 - val_accuracy: 0.7347\n",
            "Epoch 456/500\n",
            "37/37 [==============================] - 6s 177ms/step - loss: 0.4151 - accuracy: 0.8535 - val_loss: 0.7338 - val_accuracy: 0.7398\n",
            "Epoch 457/500\n",
            "37/37 [==============================] - 6s 177ms/step - loss: 0.3622 - accuracy: 0.8826 - val_loss: 0.7331 - val_accuracy: 0.7296\n",
            "Epoch 458/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.3782 - accuracy: 0.8637 - val_loss: 0.7322 - val_accuracy: 0.7296\n",
            "Epoch 459/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.3953 - accuracy: 0.8654 - val_loss: 0.7326 - val_accuracy: 0.7372\n",
            "Epoch 460/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.3909 - accuracy: 0.8669 - val_loss: 0.7332 - val_accuracy: 0.7270\n",
            "Epoch 461/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.3860 - accuracy: 0.8717 - val_loss: 0.7374 - val_accuracy: 0.7398\n",
            "Epoch 462/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.4017 - accuracy: 0.8564 - val_loss: 0.7325 - val_accuracy: 0.7372\n",
            "Epoch 463/500\n",
            "37/37 [==============================] - 6s 177ms/step - loss: 0.3849 - accuracy: 0.8706 - val_loss: 0.7345 - val_accuracy: 0.7423\n",
            "Epoch 464/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.3842 - accuracy: 0.8610 - val_loss: 0.7362 - val_accuracy: 0.7398\n",
            "Epoch 465/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.3828 - accuracy: 0.8693 - val_loss: 0.7345 - val_accuracy: 0.7347\n",
            "Epoch 466/500\n",
            "37/37 [==============================] - 7s 177ms/step - loss: 0.3921 - accuracy: 0.8572 - val_loss: 0.7342 - val_accuracy: 0.7372\n",
            "Epoch 467/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.3895 - accuracy: 0.8676 - val_loss: 0.7323 - val_accuracy: 0.7372\n",
            "Epoch 468/500\n",
            "37/37 [==============================] - 7s 177ms/step - loss: 0.3917 - accuracy: 0.8578 - val_loss: 0.7361 - val_accuracy: 0.7398\n",
            "Epoch 469/500\n",
            "37/37 [==============================] - 6s 177ms/step - loss: 0.4007 - accuracy: 0.8529 - val_loss: 0.7349 - val_accuracy: 0.7270\n",
            "Epoch 470/500\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.4124 - accuracy: 0.8531 - val_loss: 0.7331 - val_accuracy: 0.7347\n",
            "Epoch 471/500\n",
            "37/37 [==============================] - 7s 177ms/step - loss: 0.3843 - accuracy: 0.8576 - val_loss: 0.7344 - val_accuracy: 0.7398\n",
            "Epoch 472/500\n",
            "37/37 [==============================] - 6s 177ms/step - loss: 0.3854 - accuracy: 0.8663 - val_loss: 0.7380 - val_accuracy: 0.7321\n",
            "Epoch 473/500\n",
            "37/37 [==============================] - 6s 177ms/step - loss: 0.3584 - accuracy: 0.8792 - val_loss: 0.7334 - val_accuracy: 0.7321\n",
            "Epoch 474/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.3567 - accuracy: 0.8833 - val_loss: 0.7367 - val_accuracy: 0.7398\n",
            "Epoch 475/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.3620 - accuracy: 0.8748 - val_loss: 0.7331 - val_accuracy: 0.7372\n",
            "Epoch 476/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.4065 - accuracy: 0.8500 - val_loss: 0.7420 - val_accuracy: 0.7372\n",
            "Epoch 477/500\n",
            "37/37 [==============================] - 6s 177ms/step - loss: 0.3943 - accuracy: 0.8613 - val_loss: 0.7366 - val_accuracy: 0.7270\n",
            "Epoch 478/500\n",
            "37/37 [==============================] - 6s 177ms/step - loss: 0.4113 - accuracy: 0.8585 - val_loss: 0.7364 - val_accuracy: 0.7372\n",
            "Epoch 479/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.3953 - accuracy: 0.8559 - val_loss: 0.7377 - val_accuracy: 0.7398\n",
            "Epoch 480/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.3921 - accuracy: 0.8495 - val_loss: 0.7432 - val_accuracy: 0.7347\n",
            "Epoch 481/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.3866 - accuracy: 0.8581 - val_loss: 0.7364 - val_accuracy: 0.7270\n",
            "Epoch 482/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.3931 - accuracy: 0.8591 - val_loss: 0.7352 - val_accuracy: 0.7398\n",
            "Epoch 483/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.3791 - accuracy: 0.8666 - val_loss: 0.7372 - val_accuracy: 0.7398\n",
            "Epoch 484/500\n",
            "37/37 [==============================] - 6s 177ms/step - loss: 0.3602 - accuracy: 0.8783 - val_loss: 0.7368 - val_accuracy: 0.7449\n",
            "Epoch 485/500\n",
            "37/37 [==============================] - 6s 177ms/step - loss: 0.3795 - accuracy: 0.8631 - val_loss: 0.7376 - val_accuracy: 0.7296\n",
            "Epoch 486/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.3623 - accuracy: 0.8776 - val_loss: 0.7372 - val_accuracy: 0.7372\n",
            "Epoch 487/500\n",
            "37/37 [==============================] - 6s 177ms/step - loss: 0.3686 - accuracy: 0.8781 - val_loss: 0.7378 - val_accuracy: 0.7449\n",
            "Epoch 488/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.3893 - accuracy: 0.8605 - val_loss: 0.7381 - val_accuracy: 0.7423\n",
            "Epoch 489/500\n",
            "37/37 [==============================] - 6s 176ms/step - loss: 0.3835 - accuracy: 0.8618 - val_loss: 0.7370 - val_accuracy: 0.7270\n",
            "Epoch 490/500\n",
            "37/37 [==============================] - 6s 177ms/step - loss: 0.3892 - accuracy: 0.8607 - val_loss: 0.7390 - val_accuracy: 0.7321\n",
            "Epoch 491/500\n",
            "37/37 [==============================] - 6s 177ms/step - loss: 0.3921 - accuracy: 0.8668 - val_loss: 0.7360 - val_accuracy: 0.7372\n",
            "Epoch 492/500\n",
            "37/37 [==============================] - 6s 177ms/step - loss: 0.3640 - accuracy: 0.8818 - val_loss: 0.7381 - val_accuracy: 0.7398\n",
            "Epoch 493/500\n",
            "37/37 [==============================] - 6s 177ms/step - loss: 0.3728 - accuracy: 0.8747 - val_loss: 0.7383 - val_accuracy: 0.7347\n",
            "Epoch 494/500\n",
            "37/37 [==============================] - 6s 177ms/step - loss: 0.3963 - accuracy: 0.8539 - val_loss: 0.7380 - val_accuracy: 0.7321\n",
            "Epoch 495/500\n",
            "37/37 [==============================] - 6s 177ms/step - loss: 0.3997 - accuracy: 0.8569 - val_loss: 0.7386 - val_accuracy: 0.7372\n",
            "Epoch 496/500\n",
            "37/37 [==============================] - 6s 177ms/step - loss: 0.3639 - accuracy: 0.8768 - val_loss: 0.7402 - val_accuracy: 0.7449\n",
            "Epoch 497/500\n",
            "37/37 [==============================] - 6s 177ms/step - loss: 0.3904 - accuracy: 0.8592 - val_loss: 0.7389 - val_accuracy: 0.7372\n",
            "Epoch 498/500\n",
            "37/37 [==============================] - 6s 177ms/step - loss: 0.3738 - accuracy: 0.8699 - val_loss: 0.7363 - val_accuracy: 0.7347\n",
            "Epoch 499/500\n",
            "37/37 [==============================] - 6s 177ms/step - loss: 0.3935 - accuracy: 0.8626 - val_loss: 0.7446 - val_accuracy: 0.7347\n",
            "Epoch 500/500\n",
            "37/37 [==============================] - 6s 177ms/step - loss: 0.3772 - accuracy: 0.8700 - val_loss: 0.7388 - val_accuracy: 0.7372\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "id": "91QSdgW_TK-a",
        "outputId": "774c04b8-e523-427e-dc01-b72a559f4a2c"
      },
      "source": [
        "acc = history.history['accuracy']\r\n",
        "val_acc = history.history['val_accuracy']\r\n",
        "loss = history.history['loss']\r\n",
        "val_loss = history.history['val_loss']\r\n",
        "\r\n",
        "epochs_range = range(500)\r\n",
        "\r\n",
        "plt.figure(figsize=(15, 15))\r\n",
        "plt.subplot(2, 2, 1)\r\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\r\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\r\n",
        "plt.legend(loc='lower right')\r\n",
        "plt.title('Training and Validation Accuracy')\r\n",
        "\r\n",
        "plt.subplot(2, 2, 2)\r\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\r\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\r\n",
        "plt.legend(loc='upper right')\r\n",
        "plt.title('Training and Validation Loss')\r\n",
        "plt.show()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2oAAAGiCAYAAACWDzX7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd3hU1dbA4d+ZlknvFUKTErqhhRaqIIqgIIgVL4iAXrBy9fNaAbGLWOHSRFFUQIEoFkCQJiA9IIROAqSTXidTvj8mGRiTQEgfWO/z+Dhzzj77rOyEnKzZTbFYLBaEEEIIIYQQQtQbqroOQAghhBBCCCGEPUnUhBBCCCGEEKKekURNCCGEEEIIIeoZSdSEEEIIIYQQop6RRE0IIYQQQggh6hlJ1IQQQgghhBCinpFETVyzCRMmsGrVqmovW5cGDBjAn3/+We31PvTQQ6xYsQKAqKgoxo8fX6Gy1yo+Pp7w8HBMJlOlrhdCCFG35NlacfJsFTcKSdRuEOHh4bb/wsLC6NChg+19VFTUNdW1cOFCRowYUe1l66P58+fzwAMPlDqelpZGu3btOH78eIXrGj58OIsXL66WuP758AsJCWH//v2o1epqqf+fLBYLAwcO5Pbbb6+R+oUQwhHJs7Vy5NkKrVq1IjY2ttrrFdcXTV0HIGrH/v37ba8HDBjA66+/Ts+ePUuVMxqNaDTyY1Fi+PDhzJkzh3PnzhEaGmo7/vPPP9OyZUtatmxZh9HVnt27d5OWlobRaCQ6OpoOHTrU2r3lZ1IIUV/Js7Vy5NkqRMVIj9oNbteuXfTp04f58+fTq1cvXnjhBTIzM5k0aRLdu3ena9euTJo0icTERNs1lw8j+OGHH7jvvvt4++236dq1KwMGDGDz5s2VKnvu3DkeeOABwsPD+de//sX06dOZNm1amXFXJMY5c+Zw7733Eh4ezvjx40lLS7OdX716Nf379yciIoK5c+eW2z5BQUF0796dNWvW2B1fvXo1d95551XjuFzJ119i+/btDBkyhM6dOzNjxgwsFovtXFxcHGPHjiUiIoKIiAieffZZsrKyAPjPf/5DfHw8kydPJjw8nAULFnD+/HlatWqF0WgEICkpicmTJ9OtWzcGDRrE8uXLbXV//PHHPPnkkzz33HOEh4czdOhQDh06VG4bAKxatYoBAwbQt29fVq9ebXfuxIkTjBs3jm7dutGzZ0/mzZsHgMlkYt68edxyyy2Eh4czcuRIEhISSsUKpX9O7r33Xt544w0iIiL4+OOPr9geAAkJCUyZMoXu3bsTERHBjBkzMBgMdOvWjWPHjtnKXbx4kY4dO9r9LAghRHWTZ6s8WyvybC1LdnY2zz33HN27d6d///589tlnmM1mAGJjY3nwwQfp3LkzERERPPXUU4B11Msbb7xBjx496NSpE8OGDbumXklRf0miJkhNTSUzM5NNmzYxc+ZMzGYzI0eOZNOmTWzatAknJydmzJhR7vXR0dE0bdqUnTt3MmHCBF588UW7X4wVLTtt2jQ6dOjArl27mDJlSqlf4JerSIw//fQTb775Jjt27KCoqMg2NOLkyZNMnz6dd955h61bt5KRkVHuAwDgrrvushvCcvr0aWJiYhg2bNg1t1WJtLQ0pkyZwlNPPcXOnTtp1KgR+/bts523WCxMmjSJrVu38ssvv5CYmMjHH38MwLvvvktISAjz5s1j//79PProo6Xqf+aZZwgKCmLr1q189NFHzJ49mx07dtjOb9y4kaFDh7Jnzx4GDBjAzJkzy401Pz+f3377jeHDhzNs2DDWrl2LwWAAICcnh3HjxhEZGcnWrVtZt24dPXr0AODzzz9n7dq1zJ8/n3379vHGG2+g1+uv2jZg/TkJDQ1l+/btPPbYY1dsD5PJxKRJkwgJCWHjxo1s2bKF22+/HZ1Ox+233273vfvpp5/o0aMHPj4+FYpDCCEqS56t8my90rO1PDNnziQ7O5sNGzawdOlS1qxZw/fffw/Ahx9+SK9evdi9ezdbtmzhwQcfBGDbtm3s2bOH3377jb179zJnzhy8vLyu+d6i/pFETaBSqXjiiSfQ6XTo9Xq8vb259dZbcXZ2xs3Njccee4zdu3eXe31ISAj33HMParWaESNGkJKSQmpq6jWVjY+P59ChQ7Y4unTpwoABA8q9Z0ViHDlyJE2bNkWv1zNkyBCOHj0KwK+//kq/fv3o2rUrOp2OJ598EpWq/H8KgwYNIjU11fbLfs2aNURGRuLj43PNbVViy5YttGjRgiFDhqDVann44Yfx8/OznW/cuDG9evVCp9Ph4+PDuHHjKlQvWHuX9u3bx7Rp03BycqJ169aMHj3a7uHcuXNn+vbti1qt5s477yQmJqbc+tatW4dOp6NXr17069cPo9Fo+7T2jz/+wM/Pj/Hjx+Pk5ISbmxsdO3YEYMWKFTz55JM0a9YMRVEICwvD29u7Ql9DQEAADz30EBqNBr1ef8X2iI6OJjk5meeeew4XFxecnJzo0qULACNGjGDt2rW2P1jWrFnD8OHDKxSDEEJUhTxb5dl6pWdrWUwmEz///DPPPvssbm5uNGzYkHHjxtkSWo1GQ3x8PMnJyXbPOo1GQ25uLqdPn8ZisXDTTTcREBBwTfcW9ZMMmBZ4e3vj5ORke5+fn8+bb77J1q1byczMBCA3NxeTyVTmhNrLfwk6OzsDkJeXV+a9yiubnp6Op6en7RhAcHAwCQkJZdZTkRj9/f3t7lUSU3JyMkFBQbZzLi4uV/zkydnZmSFDhrB69WrCw8P58ccfef755yscR1n+GYOiKAQHB9vep6amMmvWLPbs2UNubi4WiwUPD49y6/tn3Z6enri5udmOhYSEcPjwYdv7y78Per2ewsLCcudQrF69mttuuw2NRoNGo2Hw4MGsWrWKQYMGkZCQQKNGjcqMIzExsdxzV3N528CV2yMhIYGQkJAyY+/YsSN6vZ5du3bh7+9PXFwcAwcOrFRMQghxLeTZKs/WKz1by5Kenk5RUREhISF290hKSgKswzM//PBDRo0ahaenJ+PGjWPUqFH06NGDBx54gBkzZnDhwgUGDx7M888/bxercEzSoyZQFMXu/eLFizlz5gzLly9n3759fP311wDlDrmoDv7+/mRmZpKfn287Vt6DpKoxBgQE2A3HyM/PJyMj44rXjBgxgl9//ZXt27eTm5tL//79qxSHv7+/XQwWi8Xu6509ezaKovDjjz+yb98+3n333Qq3f0BAAJmZmeTk5NiOJSQkEBgYWKHrL5eYmMjOnTuJioqiV69e9OrVi99++40tW7aQlpZGcHAw586dK/PaoKAg4uLiSh13cXEBoKCgwHYsJSXFrsw/fyav1B4lf3RcPuftciNGjCAqKoqoqChuvfVWuz+chBCipsizVZ6t18rb2xutVkt8fHyZ9/D39+f1119n27ZtTJ8+nenTp9tWjhw7diw//PADP//8M2fPnmXhwoXVFpeoO5KoiVJyc3NxcnLCw8ODjIwMPvnkkxq/Z4MGDWjXrh0ff/wxBoOB/fv3s2nTphqJ8dZbb+WPP/5gz549GAwGPvroI9tE3fJ06dIFd3d3XnnlFdv8p6rE0bdvX06cOMG6deswGo18+eWXdkNacnNzcXFxwd3dnaSkpFK/cP38/MpNkIKDgwkPD2f27NkUFhYSExPDypUrKzXkb82aNTRp0oRff/2V1atXs3r1an777TcCAwNZu3Yt/fr1IyUlhSVLlmAwGMjJyeHgwYMAjB49mg8//JCzZ89isViIiYkhPT0dHx8fAgMDWbNmDSaTiZUrV5b7tVSkPTp06IC/vz/vv/8+eXl5FBYWsnfvXtv54cOHs2HDBqKiorjrrruuuQ2EEKI6yLO1tBv12VqiqKiIwsJC238AQ4YM4YMPPiAnJ4cLFy7w+eef2+5RMq8OwNPTE0VRUKlUREdHc/DgQYqKinB2dkan011x2KlwHPJdFKU8/PDDFBYW0r17d8aMGUNkZGSt3Pe9997jwIEDREREMGfOHLtf2tUZY4sWLXjllVeYNm0akZGReHh4lBpq90+KonDXXXdx4cIFuz/2KxuHj48PH374Ie+//z4RERHExsbSqVMn2/kpU6Zw5MgRunTpwsSJExk8eLDd9RMnTmTu3Ll06dKFRYsWlap/9uzZXLhwgcjISKZMmcLUqVPLXDL6alatWsX999+Pv7+/3X/33nsvq1atws3NjcWLF7Np0yZ69erFrbfeyq5duwAYN24ct912G+PHj6dTp068+OKLtgfRzJkzWbRoEREREZw8eZLw8PArxnGl9lCr1cybN4/Y2Fj69+9Pnz59+OWXX2zng4ODadOmDYqi2MbzCyFEbZNna2k36rO1xNChQ+nQoYPtvx9++IGXX34ZZ2dnbrnlFu6//37uuOMO7r77bgAOHTrE6NGjCQ8P57HHHuPFF18kNDSU3NxcXnrpJbp160b//v3x8vLikUceqXRcov5QLDXZ5y5EFTz11FM0a9aMJ554oq5DEQ7uhRdeICAggKeffrquQxFCiDolz1YhHIf0qIl6Izo6mri4OMxmM1u2bOH333/nlltuqeuwhIM7f/4869evZ9SoUXUdihBC1Dp5tgrhuGTVR1FvpKamMnXqVDIyMggKCuK1116jTZs2dR2WcGBz5szhiy++YOLEiYSGhtZ1OEIIUevk2SqE45Khj0IIIYQQQghRz8jQRyGEEEIIIYSoZyRRE0IIIYQQQoh6ps7mqJnNZkymqo26VKuVKtdxPZJ2KU3apDRpk7JJu5RWHW2i1aqrKZobgzwja4a0SdmkXUqTNilN2qS0mn4+1lmiZjJZyMjIq1IdXl4uVa7jeiTtUpq0SWnSJmWTdimtOtrE39+9mqK5McgzsmZIm5RN2qU0aZPSpE1Kq+nnowx9FEIIIYQQQoh6RhI1IYQQQgghhKhnJFETQgghhBBCiHpGNrwWQgghhBDCQZhMRtLTUzAaDbV636QkBdl+2d61tIlGo8Pb2x+1uuLplyRqQgghhBBCOIj09BT0ehdcXYNQFKXW7qtWqzCZzLV2P0dQ0TaxWCzk5maRnp6Cn19wheuXoY9CCCGEEEI4CKPRgKurR60maaJqFEXB1dXjmntBJVETQgghhBDCgUiS5ngq8z2ToY9CCCGEEEKICsnMzODJJx8HIC3tIiqVCi8vbwAWLPgCrVZb7rUxMUf49de1PPXUf654j8mTxzNv3uIqx7pv3x6+/fYr3nlnTpXrqguSqAkhhBBCCCEqxNPTiyVLlgGwaNH/cHZ24f77H7KdNxqNaDRlpxhhYW0IC2tz1XtUR5J2PZBETQghhBBCCFFps2a9hk6n4/jxY3To0JGBAwfz4YfvYzAU4uSk57//fYVGjZrY9XAtWvQ/kpISiY+/QFJSEvfccx+jR98LwKBBkaxfv5V9+/awePF8vLy8OH36FK1ateaVV2aiKAo7dmzj448/QK93pkOHjsTHX6hwz9n69b+ydOnnWCwWevTozeOPP4HJZOKtt2YSE3MERVEYOnQ4Y8Y8wIoV37Jmzfeo1WqaNGnK9Olv1mRT2pFETQghhBBCCFElKSnJzJu3GLVaTW5uDp9+ugCNRsPu3bv43/8+Zdasd0tdExcXy0cfzSMvL4/777+bESNGleqNO3HiGEuXLsfPz5/HHnuE6OiDhIW15t133+STT+YTEtKAV1/9b4XjTE1NYe7cj1m06Cvc3d155pkpbNnyBwEBgaSkJLN06XIAsrOzAfjqqyWsWBGFTqezHastkqgJIYQQQgjhgNb+nUTU4cRqrXN4uyCGtg285uv6978FtVoNQE5ODq+//hrnz8ehKApGo7HMa3r06IVOp0On0+Ht7U1a2kUCAuzv3bp1W9uxFi1akpgYj4uLMyEhDQgJaQDAoEG3EhW1qkJxHj36N+HhnfH2ts6rGzx4CAcP7uPhhycQH3+BDz54hx49etOtW3cAbrqpBTNmvERkZD8iI/tdY6tUjaz6KIQQQgghhKgSvV5ve71w4Tw6derC0qXLefvtDzAYyl6WXqvV2V6rVCpMJlOpMjrd1ctUBw8PD5Ys+Ybw8M6sWfM9b701E4B3353DyJH3cPx4DI8+OrbcpLMmSI+aEEIIIYQQDmho28BK9X7VtJycHPz9/QH4+ecfq73+Ro0aEx9/gYSEeIKDQ/j99/UVvrZ163bMmfMeGRkZuLu7s379OkaNuoeMjAy0Wg39+g2kUaPGzJjxCmazmeTkJDp16kKHDjezYcM68vPzcXd3r/avqSySqAkhhAPZey6DnWfT+Xdk00pdbzJbUKtK7+USHZ/F9wfjmdizMX6uTqTkFDL/z1ge6tqQrl4uVQ1b1LIVB+JpFuhB52C3ug5FCHEDeuCBsbz++mt88cUievToXe31OznpeeaZ53n22ano9c60bl3+SpJ79uxmxIjbbe9nznyLyZOn8MQTk2yLiURG9uPEieO8+eZ0zGYLAJMm/Ruz2cyMGS+Tm5uDxWJh1Kh7ay1JA1AsFoul1u52maIiExkZeVWqw8vLpcp1XI+kXUqTNilN2qRs9b1dur6/BYCoR7uRmmOgfYjHVa/Zey6DNkHunE7NZcK3B3n51pbc3ubSJ7CpuQZGLvqL/CJzqWub+Diz/um+VW4Tf//ae7BdD6r6jLxnyR5aBbkzc0iraozK8dX3f991RdqltPrcJomJsQQFNa71+6rVKkym0s+JupKXl4eLiwsWi4X333+b0NBQxox5oFZjuNY2Ket7d6Xno/SoCSGEA7p3yV7yikz8Mrk7fq6Xxu9/viuODiEedA71AuDghUwmL4/mlpb+tA12x2i28Oovx7itdQCKYu1ZW7r7HAajmbeHtyEhs4DNpy5y9mIerw5phV4rU5kdkUqBevT3lBBCVLsff1zFL7+sxWgsokWLVtx55911HVK1k0RNCCHqkMls4WhSNu2CS/eMbTl1kZfWHkWrVmEyW5g/pqPtXF6RdTL1jjNpbDyRirNWzeibQ/hs21kAbvJzwWyGM2nWT4Q3HE8hq6DIdv0zq/9m++k01CoFo9lC72Y+DGjhB8B9nRtgMJrRa9U19WWLGqZSFMx1M2BGCCFqxZgxD9R6D1ptk49KhRCiio4mZbPmUEKlrl28K45xyw6w5dRF27EzF/NYuCOW9zeeJL/ITFaBkVyDiYU740pdP+O342w7ncZfseks23vedvxUap4tSZtxeys0KoW/4jJwd7J+PrftdBqDw/wxFo/Fb+nvartWpSiSpDk4taJgMkuiJoQQjkx61IQQoorGfrUfsO49UzKc8Ere2nACvUbNlMgmfLP3AgCfbDnDyZRclu45R05h6aWHNSqFTSdS0agU5o/pyGfbz+KiVXM2LY8ANx17zmWy7XQannoNmQWXlg5u5uvCba0DOZmSy5e7z9OzqTe/xaQAMOP2MH4/norRbKGZr2upewrHpShQR1PQhRBCVBNJ1IQQoppk5Bfh7aIjKbuQZXvP0yXUi8ibfO3KmC0Wvj9o7X07n5FPdqGRuzsG8+PhROZuP2sr17uZD9tOp9neDw7z5+cjyTT00tM+xIO5ozvYzm0+mcqec5kYzRbeHNaamKQcUnMNLNt7gQA3JwD+HdmUIA89EY296dvcj0bezqgUBSeNCqPBRFNfWdnxeqJWKZgkURNCCIcmiZoQQlzmnd+OkV9QxBN9mvKfNUe4vU0AA1r6V+ja7w8mcOBCJp0aerFs7wU2Hk9lz7kMLmQU0LGBB9/uu0C/5n628puLhztO7tnEdv3T/ZrRv4UfQe5OpOQYcNaqMVksmMwWUnMMdqs1lgj1dgYgwE1H51AvujbyJupwIgCq4gHuKkVh9M0hADQqLg8wa2hr/vfnWUnUrjMqRcEsi4kIIYRDkzlqQojrTqHRzA8H469pMQWD0cyKA/Es2HaGr/acJzG7kM2nLrLmcCIbT6SyeGccP/2dyIHzmbZrjiRm89Hm07b3//szll2xGaw9kgRAYnYhy/ZeYPOpi3y05QzJOQaWH4gHYGibAACcNCq8XLRMiWzKI90bcWf7III99CiKQoC7E+56DV7OWnxddXw6ukOZG5s29HRGr1ExOCwAVfHQy5K5aFfTq5kPXz7YCa1aHgfXE7WC9KgJIWrE1KmT2LVrh92x5cuX8d57b5Z7zZQpE4mJOQLAtGlPkJ2dXarMokX/Y9mypVe895Ytf3DmzKXn7sKF89i9e9e1hF+mffv28NxzT1W5nuomPWpCiHrPYDSjKFQ4mVi8M5bFu87hrtcyqJW1N+y3o8lsOJ7CzNvDWLwrjou5Bh7qEoqfmw6dWsXzPx6xG2p4NNH6EDlwPot95zIpMF7qnmjq40Kf5r4cis9i32WJW4m49Hy7928Na82nW88Q6O7EnnOZOGtVvHRrK6b2aWZb8MHNScPkXk2uqV1K6DQqvnqoE0EeetuxDiEeqFUKY7uGVqpO4dhUKln1UQhRM2655VZ+/30dERE9bMc2bFjH448/UaHr33vvo0rfe+vWP+jZszdNmzYDYMKEyZWuyxFIoiaEqPeGzNuJu17DmgndKlQ+KccAQGa+dTn62LQ8Xvo5BoDHV0RzKMGahEUdTiLUS8+gsAC7JA3gcHGZkmXwbw3zx0OvxWAycyIlly/+OnfFGLo28mJ3XAY9m3ozsKU/A1v6E3UokT3nMmns7YJGpeB72f5nVdXYx37ooq+rjp1PR1Zb/cKxKIqCWVZ9FELUgP79B7JgwVyKiorQarUkJMSTmppCx47hvPfemxw9eoTCwkL69x/II49MKnX9qFHDWLhwKV5eXnzxxSJ++WUt3t7eBAQE0qpVawCiolYRFbWKoqIiGjZsyMsvz+TEiWNs27aFAwf28cUXi5k16x2WLFlIz5696d//Fvbs+YtPP52DyWQiLKwN06a9gE6nY9SoYdx22x1s374Fo9HIzJlv07hxkwp9revX/8rSpZ9jsVjo0aM3jz/+BCaTibfemklMzBEURcXQocMYM+YBVqz4ljVrvketVtOkSVOmTy+/h7GiJFETQtS5U6nWxOelwS3RaUr3mmUXGskuNGK2WEjMKuTjLad5cXBLXHVqTGYLx1NyWRWdwAuDWliH/hX3JKTnF2E0W1h3LAUFaOCl51BCNp56DbNHtCPqUCJrDify9Z7zdG/izd5zGRSZrNf+EJ1AEx9nzqZZe8dG3xxCxwaeAGTkFTFornXYx+y72uLqpOaNdSeIvawnzVOv5YsHwml22dyvbo2tm1D/O7JJtbehqBsvvPACf/zxB76+vvz000+lzkdFRbFgwQIAXF1dee211wgLC6vxuNQKFEqiJoSoAR4enrRp05adO7cTGdmPDRvWMWDAIBRFYeLEx/Hw8MRkMvHkk49x8uQJmjdvUWY9MTFH+f33dSxZsgyTycj48Q/aErW+ffszfPgIAObP/4yfflrNqFH30rt3H1tidrnCwkLeeGM6c+Z8RqNGjZk58xVWr17JPffcD4CnpyeLF3/NDz+s4JtvlvJ///fyVb/O1NQU5s79mEWLvsLd3Z1nnpnCli1/EBAQSEpKMkuXLketVpGRYR1Z89VXS1ixIgqdTlfm0M7KkERNCFHntp9O45ejyQxvF0SXRl525y5fYvzxFdHsPWf9hahWKWQXGomOz8JZqyYlx8Aj3RtRaDSzMzYDgPl/xvLFX+coNJoJb+DB7W0CmbX+BG5OGjqEeGCxWFhzOJFCo5lBLf05eCHTlqjlGkxMj2zKZ9vOcvpint3y9V4uWpY+GM7aI8l0a+yNk0ZF22B3YtPzbas1Bro70SbI3e5rCfLQs/vZPjXShqJujBw5kgcffJDnn3++zPMNGzbkq6++wtPTk82bN/Pyyy+zYsWKGo9LJT1qQtwQnGJWoj/6bbXWWdD6XgrDRl2xzC233MqGDeuIjOzH77+vsyU+GzeuJypqFSaTiYsXUzl79nS5iVp09H769OmPXm8dtt+796Xn4+nTp1iwYC45Odnk5+fTrVv3K8YTFxdLcHAIjRo1BuC22+7ghx9W2BK1vn0HANCqVWs2b95UgVaAo0f/Jjy8M97e3gAMHjyEgwf38fDDE4iPv8AHH7xDr16RdOkSAcBNN7VgxoyXiIzsR2Rkvwrd42pk9rgQos6l5FqHKu45l2F3PKfQyLQ1R2zvS5I0gN9iUvjzTDo5hSZSioc6bjudxqjP93CxuD6wLiwCcEurAPq1sK64OLabdd5WywA3W7lBYf6l5sD1buZL/xZ+tPB3xV1v/7lWWKA7z/a/CafiHsAmxUMPm/u58smo9kzu1fham0E4oK5du+Lp6Vnu+U6dOtnO33zzzSQmJtZKXGqZoyaEqEG9e/dl797dHDsWQ0FBAWFhrYmPv8A333zFnDlz+eKLb+nRozcGg+HqlZXhjTem8/TTz/Hll98xbtyjla6nhFZrnWqgVqswmYxXKX1lHh4eLFnyDeHhnVm9+nveemsmAO++O4eRI+/h+PEYHn10LEZj1e4D0qMmhKgHUnMKAdhbnKgdTsgiLj2fP05eZEvxEvZlcdWpyTVc2hz6oy2nS5Vx1qrILzIzoKUfXs5adjwdiVopOadmbNdQ2gS54axVo1HZb1atVilM6tmYST2vnnSNvjmEkym5jL45hAB3p6uWFzeelStX0qdPxXpU1WoFL6/Kb5mg06ox5xurVMf1SK1WSZuUQdqltPrcJklJCuriDxaNbe8hp+091X4PdXnHi+/r7u5G585deOutGQwefCtqtYqCgnycnZ3x9PQgIyOdnTv/pHPnLqjVKhRFQaVS2a5XqxU6derMzJmv8vDD4zGZTGzfvpW77robtVpFXl4eAQEBWCwm1q//FX//ANRqFa6urhQU5NvqKam3adOmJCYmEB9/ntDQRqxb9wudOnW2u59arUKlssai/scHs5fKXTrerl17PvzwPbKzM3F392DDhnWMHn0v2dmZaLVaBg4cVDwX7SUUBS5eTKFr126Eh4fz++/rMBgKcXKyn4uuKNf2u10SNSFErVkXk0xGfhH3hDewO17SI3Y4IZuzaXlM/O6gbQhieebd04GOIR70/Xg7huKy+UVmbmnpzx1tA3FzUmM0Wwj1cuZkai5+xQt3/DMZm+fq0Q8AACAASURBVNqnqe31qJtDmP9nLADjIqy9bopiX748bk4aZt3RukJlxY1n586drFy5kmXLllWovMlkISMjr9L3M5vMmMzmKtVxPfLycpE2KYO0S2n1uU0sFgsmU+1vlGjtjbp034EDb+W//53Ga6+9gclkplmz5rRo0YoxY0YSGBhI+/YdMZutsVosFsxms+16k8lC8+atGDBgEA89dC/e3t6EhbWxlZ8wYTITJozFy8uLNm3akZeXh8lkZsCAQbzzziyWL/+G119/x1avRqPlhRde4cUXn7MtJjJ8+Ei7+5lMZsxmc5ntZzKZ2bNnN8OHD7EdmznzLSZNmsK//z3RtphIr159OHHiOG++OR2z2YKiwMSJ/6aoyMirr75Ibm4OFouFu+++FxcX11L3sVhK/27397efJnE5xWKpm7ERRUWmKv8DqM//iOqStEtp0ial1WabfPDHKZbtvWB776JVU2A0MS6iEZN7NeHOhX9RUGQiLa8IBWtP1oJ7O+Kp1zJy8W67ugLcdLx2Wyu6NrKOGR+3bL9thUaAD0a0pXcz30rFabFY0LvqycjMQ69RVThJu95Vx8/KlR5Eju78+fNMnjy5zMVEAGJiYpgyZQoLFiygadOmZZb5p6o+I5+POkJcRgHfjO1U6TquR/IsKJu0S2n1uU0SE2MJCqr94fX/TNTEtbdJWd+7Kz0fZY6aEKJGmS0WW5Lm5awFrEveN/V1YdHOOL7Zd4HUnEL6t/BDr1FhAZ7s24x2wR6Eejtzd8dgwDq0EODLBzvZkjSA1oGXfsGpVQq9mvpUOlZFUXDWqXHWqiVJE9UiPj6eqVOn8s4771Q4SasOKkXmqAkhhKOToY9CiErbFZvOp1vPMO+ejjhrVTzx/WEGtPRjRIdgW5kTKbmANfkKC3DjsRXRADzaozH/9+NRZm86BUAjb2dWju9KkclMQy9n2/X/GdCcyT2b4OmsYXz3RqX2HmsdaF0QZFLPxtzfuaEkWKJWPfPMM/z111+kp6fTp08fpk6daptAft999/Hpp5+SkZHB9OnTAVCr1fzwww81HpdKQRI1IYRwcJKoCSH4+UgS7Yt7sMA6BHD5/nhuaxOAh15b7nXvbTzJ2bR8tpy6SNdGXuyMTWdnbDoeeg0t/d3Ycy6D/OINo29p6Ydec2l6ct+bfLm7YzDfH0wAoEOIB4FlLMKhVil4uVhj8Ctjg+gOIR6oFOsKji668qY/C1EzZs+efcXzs2bNYtasWbUUzSUqlYJJlucXQgiHJomaEDe4rIIiXv3lGCGeetZM6AZAdHwW7206xaGELF4femmBDIPRTIHRhMFk4Zu9522bQS/ff4GcwkvL0P7fj0dpH+zOoYRs2ge709BLT5CHdZ+UzqGeDA4LQKNW8fzA5rZErW1Q5eYwNfZx4fvxXWngqa/U9UJcj9TSoybEdc1iscgIEgdTmWVBJFET4gZlsViIOpxoWwUxKavAdi4j35p0JefY71vy2q/HWH8sxe5Y2yBrQnaoeEGPhl56zmcU2N4fSsjmzvZBtvLz7uloe60oCm8Pa41TFeeEXT5UUghRMketrqMQQtQEjUZHbm4Wrq4ekqw5CIvFQm5uFhpN6ZFBVyKJmhDXuYSsAt7ecJIZt7eyDWO0WCys2Huemb8dt5VzdbL+OigoMpFQnLQZjGb+s+ZvHujckJsbepZK0v7duwlju4Vy4EImk76zzj1bNrYzAz75Ew+9hrS8IgB6XmGBjwEt/avvixVCAMWJmmRqQlyXvL39SU9PIScno1bvqyhKpXqFrmfX0iYajQ5v72v7m0cSNSGuc59uPcP2M2n8ceIiHnoN3Rp781tMMm+sP2FXLqfQyDf7LvDhH6cILh5G+HeitVcs12BiQo9Gpeq+u2MIKkWhU0MvZt/VluScQpy1ap7q24xQb2ee/OEwYJ2PJoSoPSoVmOQPKiGuS2q1Bj+/4KsXrGb1ecuCulLTbSKJmhAOymKx8P6mUwwOC6BDiAc5hUbMFgvvbjzFxB6NWbQrjtEdg8kunju28UQq28+k0djbmbDilRKXje3EmYt5HEvO4cvd520rMJ7PKLC71+64DHbHWT+5e6R7I25rHUCuwYS7/tKvkMjLkrExnawbWq8c1wUnjQq1SoZmCFGbVIosJiKEEI5OEjUhHNCus+k08nHmu/3x/PR3Eh+ObMeEbw/azp9OzeV4Si5r/04i2MO6kuL2M2kAxKbnE5uezy1hAbTwd6OFvxvtgj34cvd5AMZ3b8TinXG2ugLcdHZz1UZ1DMbPrfTqjGVp7ONS5a9VCHHt1IqCdKgJIYRjk0RNiDq2/3wme89lMKHHpZ3qr7SaU3xmAVO+P4Sz1rpffa7BxOPFe5OVSMwutL1OyLr02lOvIbPA2sPWroGn7XiIp56hbQPZG5fBpJ6NiWzmg1qlkJVvJL/IxH+ijtjKVjRJE0LUHUWRoY9CCOHoJFEToo5N/M7aE3Zvpwak5RXx85Eklu+PJ+rRbrg5abBYLBy8kEXHBtbVnY4UzxvLLzLb6jCYLIyPCGXxrnMAZBUnYwvGdKShtzMfbj7Nr0eT6d7Emwaeevadz2Rwm0C7OF65tSVmswWVotAu2MPu3I6nevPeplP0bS5zzYRwBGqVLCYihBCOThI1IeqJmKQcZq47TnymdX7YseQcOod6sfpQIm+sP8Fbw1ozsKU/R5OyS10b3tCTR3s2sSVqJcIC3dBr1TzaozEt/Fzp38LPtqn1PyfAqhQFlbrsXjyNWsX/3dKiur5UIUQNUymK9KgJIYSDk0RNiFpWaDTzyDcHyC8y4eWsxctZS0Z+EY/9Y/ji6Yt5dA71YuOJVMC6CfVHm08Tn1VIC39XTqTk2sr6uujQqBTGdg3ll6NJpOQYUCmg16oBaOTtzNhuobX3RQoh6pTsoyaEEI5PVdcBCHEjOJuWx9d7zmOxWNhxJo1jyTnEpecTHZ9FfpHJruzYrqE4aVS88/tJ5m4/a1ttce3fScQXzze7vU0gfq6XNk30dbXujza1T1M+GNEOQP5IE+IGplKQoY9CCOHgJFETooYkZxdiMFrnkX1/MIE5m0/z59l0Nhy33zS60GhmfPdLe5T5uelw1Vl7whbvjKNNoDttg9xti4C08HdlVMdgfnikK3e0tc4z870saWsV4MaY8BAm9myMEOLGpFLJ0EchhHB0MvRRiEooKDLxQ3QCo28OQasu/XmH2WLhgaX7iGzmwytDWnE61TpM8eMtp21z0C7Xws/V9trXRcusoa2JSc6hyGRm9M0hLNwRx9+J2WjVCsvGdraV1Wus93YpHuJYYtqA5tXydQohHJNaAYvlyivICiGEqN8kUROiEpbuOc/8P2Nx1am5s30wuQYjakXhu/3xFBpN3N4mkIz8ItYeSeLujsEcS87BU6/hVKp18Q53J41tI2qA5pcnaq46Ood60aWRl+3YXR2C+Hrv+VLDGYuKD2jKWQRECHFjUhUnZyYLaOTXgxBCOCRJ1ISogF+OJhHZzJftp9Po0dTb1kMWn1XI+Yx8Hv32IK46NbHp+QC2hT7MFvjXsgMAPNarCZkFRagVhbj0fDafughYN5Ru4ntpY2hfFx3/1MTHhZcGt6Chl7Pd8Zb+bgA09paNpYUQl5QkahaLBZBMTQghHJEkakKUoaDIZFsxMSYpm1d+PmY7d3/nBvxdvJfZ9tNp5BlMpOYaSL20CCN/nLQmYeMiQvl81zkUIKKxF22L9yfbey6Dzacu8snd7Wkb7A6Aj4uWtLwifIoXBvmnO9sHlzo2+uZgOoS4ExboXuWvWQhx/VAV52Yms4V/jIwWQgjhICRREwI4WdwD1tzflb3nMpi8PJr5YzoS3tCTXIP9qozR8VkkFK++eCw5h2PJOYQFuHEsOYd/Tt1/vHdTHu/dtNT9Ood6sfvZPnbHPh3dgU3HU3F3qvg/S0VRJEkTQpSiLs7UZOFHIYRwXLLqo7ihfPDHKQ6czyx1/L4v93Lfl3sBa28XwMTvDrLmUAJpeUV2ZQ8nWHvTnh/YHG9na+9XMz8X3PX2CdY3D3fmWjT3c+XRno1l4r8QospKhj6aZeVHIYRwWJKoievKKz/H0P2DraWO74lNJz6zgGV7L5TaWPpyfydms+Nsuu396+tOsC4m2fY+LMDN9vrmBp6MvjkEAFedhq6XLf7ROdTTboEQIYSoTSWf90iiJoQQjkuGPorryi9HrUlVyZLUx5JzWLb3PD8fScazuMfLaLawdPc5HuoaCkDGZT1m//p6PwD+bjpeHdKK56OO2OabAdwTHsKM344D0NBLT5/mvszfEUvkTT50DPHkzvZBqBWF1jIcUQhRh9QlPWrmOg5ECCFEpUmiJhxansFE34+389qQVgwt3vwZIDPfiKezhgeX7rt0rODScvgfbTlDq+LesX+vPASARqXgodeQllfETb6uRDT2pm9zX34+cqlHrXPopV4zvVZNqwA3tj/ZG13xfmY9mvjUzBcqhBDXQKUqWZ5fetSEEMJRSaImHFpytnVRj8+2nbFL1FJyC8ksKCrvMuBSglbim4c708THhc0nL9IqwDpscVArf34+kkyIhxNP9ruJEE893/2rM5n5l5K+kiRNCCHqC7UMfRRCCIcniZqod1JyCnHWqnGrwOqHJclYgdHM2Yt5tuPnMwrIukqiVuLx3k2Ijs+y7VHWt7mv7VxEY2/cnNQ09XVlQAs/AJr5ytwzIUT9piiy6qMQQjg6SdREvXP7/3YR4KZj7aTutmMrDsQT0dibRt72Gz6nF88vyyowMnrJHtvx56KOlFn3J3e3JzY9j3c3nsLHRcvUPk25o21QubFo1SreuqNNqRUdhRCiPlPLqo9CCOHw5K9PUS8l5xh4Y/1xTqXmcSGzgIu5BnRqhe1PRdqVS8uvWK8ZwE8TIwh0dyKiiTeDWvnjrFXbNrW+kogm3tccvxBC1CVV8Yhsk3SpCSGEw5JETdQrRaZLS5Stik60O2cwWfj5SBJtAt0J9Xbm+4PxJBZvPA3grFWRX1T+EmeB7k62194uumqMWggh6heVDH0UQgiHJ4maqFcyr9JD9uovxwCYNTSMdzeesh1v6uvCp6Pak11o5LOtZ9l86tKS+use646npwsUGUvVJ4QQ1yMZ+iiEEI5PlqsT9ca20xf5OzGnQmW3nk6zvQ710rP8X13wd3Oima8rA1r62ZX1dtHh4yo9aEKIG4dseC2EEI5PetREnTIWj8s5l57P06v+rvB1vx69tLeZl7N9EnZb6wBCvZx5Y/0J2gbJxtNCiBuPWiUbXgshhKOTRE3UqXFf7yctz0Cfm3yvXrgcg8P87d4rikL7EA++ebhzVcMTQgiHVDJHTTa8FkIIxyWJmqhTMcnWoY7nMwrKLeOiVfPFg+GM/nyP3fHnBzanhb8rHRt41miMQgjhaEoSNYskakII4bBkjpqoUUazhT1xGQBk5BVxLOnSHLQ8g8n2+vTF3HLrCPJwoomPC+/d2ZbHezexHW/q6yJJmhBClKF45CMmydOEEMJhSY+aqFGLdsSycGccvZr6sP2MdQGQnU9HolYpnEnLs5VLzjHQIcSD6Piscuvq29yXvs19+WzbWQBCPPU1GrsQQjgqlW2OmmRqQgjhqCRREzXqwIVMAFuSBtD9g61M7NmY1ByDXdleTX149842WCwwa91xJvdqwpe7z/Fwt1C7cn6uOlJzDfi7OSGEEKI0nSkPJwyy6qMQQjiwCiVqW7ZsYdasWZjNZkaPHs3EiRPtzsfHx/P888+TnZ2NyWRi2rRp9O3bt0YCFvXT0aRsYpJyCG/oyY6z6dzXqQEAOYWmMsvP/zMWgEGt/Fl/LAUAPzcdPsUbUc8e0Q6A14e2LnXt5/ffzKnUPDQlY3uEEELY6bbnCf6r8cRs6VrXoQghhKikqyZqJpOJGTNm8PnnnxMYGMioUaMYMGAAzZs3t5WZO3cut912G/fffz8nT55k4sSJbNy4sUYDF/XL2K/2A+Ch15BVYGRE+yASswvt5p4FuTuRmF0IwLcPd0atKDT2cWZXbDpZBUZ8K7jXWZCHniAPGfYohBDl0RZl00Apwig9akII4bCuuphIdHQ0jRs3JjQ0FJ1Ox9ChQ/n999/tyiiKQk6OdZGI7OxsAgICaiZaUe9lFRgBOJSQxeTl0bjqNDhrrT9mP06MAOAmPxdu8nOlia8LiqLwr+KhjSGSfAkhRLUwa5zQY8Akc9SEEMJhXbVHLSkpiaCgINv7wMBAoqOj7cpMmTKFRx55hK+++or8/Hw+//zz6o9U1GuuOjW5l63i+PiKQ/i4aJk3pgNB7noMRuuuq+se645eq7a79sEuDRnY0l8WBxFCiGpiVjvjrOSSLj1qQgjhsKplMZG1a9cyYsQIxo8fz/79+3nuuef46aefUKnK77BTqxW8vFyqdF+1WlXlOq5HddEuvm5O5F62iiPAf29vTaeb7DejLi8ub2/XGosN5GelLNImZZN2KU3axPGY1Xr0GJAONSGEcFxXTdQCAwNJTEy0vU9KSiIwMNCuzMqVK1m4cCEA4eHhFBYWkp6ejq+vb7n1mkwWMjLyyj1fEV5eLlWu43pUU+1iMlsoMJpw1Vl/bHIKjbjo1Mz49RhxaaXv56ai3nx/5GelNGmTskm7lFYdbeLv715N0YiKsGhKEjXJ1IQQwlFddY5a+/btOXv2LOfOncNgMLB27VoGDBhgVyY4OJgdO3YAcOrUKQoLC/Hx8amZiEWdeXP9Cfp9/CfpeQaiDifS/5M/eXltDGuPJJdZvqKLgwghhKheZrUevWLAZK7rSIQQQlTWVXvUNBoNr7zyChMmTMBkMnH33XfTokULPvzwQ9q1a8fAgQP5v//7P1566SWWLFmCoii89dZbKIosnX69WXPY2rM6Zsle0vOLAFhXvLR+WfwkURNCiDph1jjjTKH0qAkhhAOr0By1vn37ltoX7cknn7S9bt68Od9++231RiZqVUZeEafTcunU0KvM8wVFlxYKKUnSrsZVp756ISGEENVPrUdPERZJ1IQQwmFddeijuDFM+PYAk76Lpshkxmyx8N7GkxxPziEtz8D0X4+x5lDiVesY2sZ+WwbpVRVCiLph1uhxUQpleX4hhHBg1bLqo3B8sen5ACRlWx/s3+2PZ/PJi3Rr7MVPfyfx099JeDtry+xNc9KoKDSa6RDiwatDWtFt9tbaDl8IIcTlNMXbnRgL6zYOIYQQlSaJ2g1u//lMdpxNs71/LuoId7az7puXmmvgzMV827k72wex5K9zACwb24mCIjPJOYX8eSaNqMNJgLUXTa9RESx7ogkhRN3ROlv/byyo2ziEEEJUmiRqN7iJ3x20e38iJZf3Np0CwGi2cPpiru1cU99L+yi18Hezvd53LhOAguJNrTdN6Qky7FEIIeqMWmdN1EyG3KuUFEIIUV/JHDVxRbmGS4uINPK2PvhDPJzsykQ08QYgLNCavGnUKjQqSdSEEKKuqHWuAJiK8q9SUgghRH0lPWo3sCutBnZLSz82HE+1Oxbq5czmqb34Zw7W5yZf1j/WAy8XbU2EKYQQ4hppnKwfrJkLJVETQghHJT1qN7CFO+Ls3s8Z2Y4+N/kC8EiPxiy8tyPvDm9DeAMPADydtbjo1Oi1pZfdlyRNCCHqD5XWOlTdUpRXx5EIIYSoLOlRu0HkFBo5cCGTr/ec59UhrXDXa5i/IxYAjUrhib7N6NXUh4hGXqTkGgj2uLQYSPcm3uRcNgRSCCFEPae1/g63GKVHTQghHJUkate5zSdTCfV2ZsySvbZjwxb8hU5tHb/YyNuZrx/qZOsl06hVdkkagF5bdi+aEEKI+smisQ59tBhk1UchhHBUkqhdxwqKTPz3p6M08HIudc5gss5Pe2Noa0nChBDiOmMp3kdNkR41IYRwWDJH7TpgsVhYF5NMQZHJ9n7rqYtsO52GwWThzMXy5yg09Jb9zoQQ4npj0RRvpyKJmhBCOCzpUXNQJSs2KorCseQcXlwbw61h/sy8PYzZG04wb8tpAFQKBHvouZBZ9vAXV538CAghxPXGorUuz682ymIiQgjhqOSvdAf10toY1h9L4YMR7Sg0WTea/i0mhUB3J77cfR4njYpCo5kOIR5M7tWEBTti2Vu8MTXA28Nak5prqKvwhRBC1CBL8T5qWpNseC2EEI5KEjUHs3x/vHWo47EUAJ5addi2ETXAl7vPc3+3UMxGM9/uu0BEY286h3rROdSLHWfT8HPVoVWraOLjUldfghBCiJqm1mNGhcYkPWpCCOGoJFFzINtOX+TdjSdLHY9Lz0evUXFf5wZoVAr/ua01x86lk5JTyKibQ2zlejTxqc1whRBC1BVFoUDljNYkc9SEEMJRSaLmQA4lZJd7roGXnsd7NwWs89aCPPS8NaxNbYUmhBCinilUOeNklh41IYRwVJKoOYiX1h7lt5iUcs+HeMjqjUIIIS4xqFxwKpIeNSGEcFSSqNVzPx9Jwt9NZ0vSPPUaMguMpco90KVhbYcmhBCiHitSu6AvlERNCCEclSRq9VhOoZFXfzlmdyzA3cmWqG14vAdatYr8IhO+rrq6CFEIIUQ9ZdS4orfIqo9CCOGoJFGrZ5bvjycj38D4iEZsPX2x1Pk+N/ky6uYQuoR64emsBcBFp67tMIUQQtRzJo0LLqRiMltQq5S6DkcIIcQ1kkStnriYa8ACtlUdv90XT1Hx/mglbm8TwIQejdHIA1cIIcRVmLSuuFJAgdGEq04e90II4WjkN3c9kJFfxJB5O+2OZRdahzeGN/Bg/4UsAFr6u0mSJoQQokIsWjdclQJSDZKoCSGEI1LVdQACjiXnlHuuhb+b7bWbkwxxFEIIUTGKk7VHLcdgqutQhBBCVIIkanXIYrHw1A+HmbLykN3xT+5uj5PG+q1xvSw5c3OST0SFEEJUjErvjotSSG6hoa5DEUIIUQmSqNWhk6m5bD+TZnu/6pGurBzXhYgm3iy692YA+jX3s52XRE0IIURFqfXuABTmZtZxJEIIISpD/vKvQ2m5RXbvG3o52163CnRj97N97M5LoiaEEKKiVC6+AJhy04DGdRuMEEKIayY9anVkd1w67286ZXvfqaFnuWVLllV2k2X4hRCiXnnhhRfo0aMHd9xxR5nnLRYLr7/+OoMGDWLYsGH8/ffftRab1sMfAHNe2lVKCiGEqI8kUaslT686zKPfHgDgcEIWj684xJm0PAB+mdydufd0KPfakpUepUdNCCHql5EjR7Jw4cJyz2/ZsoWzZ8+ybt06Zs6cyWuvvVZrsTm5Fw+dzy+9J6cQQoj6TxK1WrLtdBoHLmSRazAyeXm03TlvZy0qpfxl9+/uGAyAuyRqQghRr3Tt2hVPz/JHRPz+++/cddddKIrCzTffTFZWFsnJybUSm97T2qNGQXqt3E8IIUT1kkStFpjMFtvrLacuUmg0M6R1gO2Y+ip7oz3Ztxmbp/ZCp5FvlxBCOJKkpCSCgoJs74OCgkhKSqqVe+vcrYmaWhI1IYRwSNJFUwsSswtsr9/5/STBHk6M7dqQX49W7FNVlaLgIvPThBDihqFWK3h5uVStDpWCERXOpswq13W9UKtV0hZlkHYpTdqkNGmT0mq6TSRRqyFpeQbGfrWf9+9qS3repT1scgpNzBnRjiB3fR1GJ4QQojYEBgaSmJhoe5+YmEhgYOBVrzOZLGRk5FXp3l5eLmTjjio/vcp1XS+8vFykLcog7VKatElp0ialVUeb+Pu7l3tOxtLVkJ1n00nKLmTSdweZ/2ec3bkOIR64OUkPmRBCXO8GDBjA6tWrsVgsHDhwAHd3dwICAq5+YTXJVrmjL8qotfsJIYSoPtKjVkNKFgfJNZg4lJBFEx9nzqblA6AUnwtv6El4A486i1EIIUTVPPPMM/z111+kp6fTp08fpk6ditFoBOC+++6jb9++bN68mUGDBuHs7Mwbb7xRq/HlqjxwMcmG10II4YgkUashGfn2m1m/O7wto5fsoXczH9ux+WM61nZYQgghqtHs2bOveF5RFF599dVaiqa0ArU7HkW1s8qkEEKI6iWJWg3Yeuqi3WbWLw9uSRNfF755uDMNPWVumhBCiNph0LjhYjhb12EIIYSoBEnUqsGZi3mYzBaa+7sC8Mzqv+3Oh3o7A9Dcz7XWYxNCCHHjKtJ64GrJwXD1okIIIeoZSdSqwT1L9gAQ0diLdsGl55yVJGpCiNKU/DT8Fncgu+9bFLR7sK7DEeK6YtK64WbJI81iAeXKe3YKIYSoX2TVxyqyWC5tZr0rNoNFO+O4fP/q+zs3wNdFWweRCeEY1FnWVVH1R5bVcSRCXH9MOg/UigVTQXZdhyKEEOIaSaJWSX/FpjP/z7Mk55QeUGIuzt0GtPDj6X432VZ5rEuq3ET8P22I7uyGug5FXEecYlbg/2lDFENO5SsxFy+8o1Ts15H2/Hb8P22IKjO28vesIHXqEfw/bYgm6UCV69JHL8Zr5TD7gyYD/p82RB/9eZXrryi3Tf/BZ0ln9NGL8ZvbBEz2Cx9pEvbg/2lD1Gknai0mUYOcPAEoyEmv40CEEEJcK0nUKiEhq4B/rzzEgh1x/HIkyXZcARoXD3N8qm8z3hzWuo4iLE2TYB2eqT/6bR1HIq4nrrvnAKDKPlfpOlSFWdYXFUzU9H9/BYA2cU+l71lRJfdw2TOn6nUlHUCbtB+l4NIfzOqMMwC4/vV+leuvKOcj36DOTcL1r9koZiPa89vszuuP/wCA7tzmWotJ1CC9dTh+Ya7spSaEEI5GErVK2H/+0p40n247a3utUSvc0sofgAaeetteavWBymAd9mLRlb/7eXXxjLof9/VTa/w+utO/4je3GW6bnsd123T85jbD6dj3eK4ejcvOd8q8RpMcbe2NyYor83yV4jn5E36fNYai8neo153+peo9UPWQKiexzONum57DZefbV7xWKSz+A1JVsU3gFVNxL7ZSVuSdEQAAIABJREFUs5vGu/3xAu6b/wuA7h/JzOVKet3UGaet122chuufr5cqp8q/CIAm7Zi1ztiN+Hw7EACL07Xtp6jkX8RnSRe057df03WXM/m0AMDp9K9lF7CYK123qD/UemuPWlGeJGpCCOFoJFGrhCOJ2eg1KsaEh9DU14UXBln/4Gnm68qd7YPoHOpJu5D6tZG1UmB9SJtrIVHTnduC/viqGr+PNmk/itmA85GvcTm4AMVsQBf3B7oLO3Dd+xFcNn+whP7IN9YYYzdVezxuO95EsZhQ55adtAC4/vUBAOrMs9V+/7qkzokv87gublP5iUAxpdD6wYelgr+OFFOh9f8FNTuUy/nvpZfuaSwo8+cJQB+zArB+cACgO78d/eGlYMy3K6cUJ2rqtOMAuG38j+2cRXNtCw5p43ehzk3E7Y/nr+k6JS/V9rrkwwrVP793xe2ryk9FOD6NszVRM+ZLoiaEEI5GVn2shJikHMIC3Zg2oLntmF6jokuoFwHuTsy7p+obWatyEvCMup+sW+di8g2rhvqsf4wpZXxK7rnmXgyN+pEfPhlt/E5c/nqfzGHLcD78Bdr4XWTdtuD/2bvv8Diqq/Hj35nZvqvVSrIsS+7GxgUbY5viAjYYg3GhQygJhBBSKEl+aYTQEsgbAikk5C0QQktIgxBCM4SObcA2mGIDBvciN1l9e535/TGr2V2tZMm4yJbP53nyZHfmzsyZkYT37L333KJjvItvBZuLyJQb9zq2TqVjlP9tJqGT7yQ1aIZ5H6FtBP59PpnAMDK+moLmhqJi27XSeh94fA4tX3ihk0pnHX/o/jwc657Ds/JBSMezcccL9vsXXEly8MnEx16O0Ta8L1M4t1GJNxN44kxCs+8lXTmuw+uYbc7CcJeTqpkMRgY1Uke6Ygy2xk8JnfZ7M55Nr+J5925aznsKtM9XyMa36CYyJQOJTfhmp228i25BC5rzxEre+BHuD+6j5bx/Y3j6mA30NGqkDpR68341R4fnUbOJ2u4q0nnf/jmG3YOh2nFsecM8rrNEQk8TeOpCDNWBYXcTnPcIJS9dS6Z0KNFjv0XZP+dj2D2ky4aT7jcJx5aFBM/4A77XfoDuHwyzOk5+lGSoWz1faqwRJR3FseUN9JKBlLz8LVrOe9KK1/PuPbg/+lNB/GqsEa1lA/7/fJPWuQ+h+81e19KnLyYy+QZ8b91O5Pjvkhw2B+faZ/C/dA0AttZNoKfxLvkF6Gl0Xw32nctJDD8T1yeP0nr2Y5CKEXjmEiKTf0TJq9+zrqlFzGHbaiqcbXMxkeN/YH3RoIY6Tr7FocXmCQCQjgV7OBIhhBB7ShK1z2FjU5TTskMc28wdU7VPr2Hf8Q625rX4Ft1M67lP7PX52no8Ohpy59j6Jo6tbxKb8E1sO5bj2LYENVKH782fAmaSp+cnRakonpUPAezXRE1r3YIWqsX35k9ovvQNAGz1K9FCW9FCW0kMPpV0xWgSw88EPYWSCJoJU5a94WOUaD2Gt2/xyTvpHfk8Sl8sTGbyn7HWsgHnppdwbnqJ+NjLreF9SrLwQ5N929vYWjfhWfYrgvP/3OF17Dvexda6EVo3Yt/5Xt4es/cyNOseUBRKXv4WajKI1rL+8yX5hoFz9ZOkK8bsNlHzfFRYAMPWuhHn+ueIj7sCADWyy/xiwNDRWjZ0Gktbj5rSrgcqn3P98xiqDVtLbiF5NdbUYVv7tqXYd7yb25BJ4Fr7NACJI8/B1vip2W7neyTiLTg3voh9y0Lc2fmbqVO+V3RO83oNZHaXqBk6pKIoaXPoq3PdcyjJMLbmtThqF1vxatE6iJpJUnT817DvfA973ft43/ovbI2rcG54gdgxX8Ox8T/Yd31I4JmLASh57Qc0DpuD740bCi6rNa3B8+EfCp9B7SLUVATbzvfRQlux172P783b0MLbisJWkiEcm1/FvvM9vEt+YfYeYn5ZJA59dq+ZqBkxKSYihBCHGhn6uIdiqQzBeJp+Jc7PfQ41spPAY7OLhxwVtgLAsX1p90+cSVH61IUoW5YUny1kfkBTkrkSzWpwC4HH51rvvYtvxfPef5v7Yg1kSgYA5odk36KbcH3yVzOmLYXDBtXWTeZ1o4U9HOWPTsOz7Fdmm/AOSp/6AmqkDsfm1/AvuAL0NOhp/M9/FXvt4qKYlUw8+/+5qnRa3rf8WrAW3VNJ9NhvEz3++2QqcsVbYmO+CECfRyZS8tK1qG/fg3vFg9ZwNispSEUJPHEWgSfOpPTpi7FvX2be85qn8L3+I+uZlT5zKVp94ULmnVHznrFj/fMAZHz92+4KAPvO9wk8eV5RkpJ/rNaygdKnvoDWsIrSf1+A1pxLUjqixJvxvvUz1GwS6FrzFKVPX1LwMwcgGTHv519fpuyv07HXvpm91oUosSbU8A7UZKjT4YzmDaWKNqUDw/Au+QVl/zgNNbSt4Pe75LXvdzpvUM0Oy7XvWoF3yZ3FDQwDNbyjaLho+x41z7JfUfLiNVZi06bi4Ym5YyJ1BftsdR+Y8b2eG4Zou+8ESp8tXs9NiTWhJEPZ3xfzf+WPTsOzwuxx9i29E8/7/wuA7vDjWvs0zs2vAuB/6RoUPYlBYa9h7OivEDvK/F11ZNv63roN18eP4lz3fEFb3V1ByUvXWT/fNuWPnV4Uq+4xv0gqe/KcXCGUbHXNxLAzrHaGzY2SCOHM/p4aDp/1c9NCW3FsepWSV79bdH5x6HD6+pA0NOzRzodkCyGEODhJj9oeqgua8zeq/J8/UXN9+hj2hk9wffwo0cmdDbPK+zCWjoPN1eV5tVAtjm1LMJ67Di7NJT5KZBe2xlXZ8+Y+tHve/z/s9bmhgm29ZGAOxdI9fc3eq5aNuD/+EwDxMZdaleoAMHRK3vgxjm1LcGx9k8SR5+TiCW7Guf4Foif8EPfKh3BsexvXx3/Gs/z3KBjYty0FDJwbXyTjH0Rq4EmFz6BtSJyRycWV9+Ffa91Eus8Y630mMMR6nao5DvcqM7F0rX0a1j6NL+/cbcPttNZN2Ovez+3QU7Se+y/8L18HQPjEn+Jc828ctYvwOPyEzrivIMaOCi7kP2N7NhEw2ob9qeafnPfduwGzoETiyHPRQjuy95z7uTs2v4Zj29uU/esslHTcOldntPD2gp4Vz/v/A5hJZ3zsZbnzbn0TR+0iMxzA/dHDqNF67HXvY9+xDEMzf9fUyE7z/jqoxqhGdwGQ8VYRPe676M4AhsOH67MncK19Ctfqf5EpHZJ7DrtWYN+1gtjEq4sK2lg/52zM0YlXY2RLioM5t0vRC4eK6u4+VnEOMJ+554P7rPlrBbHmnb/tCwvrmWXvQwtvJ102HBQNW9NqHC2bis8Ta0DbsLHg9yXj7VfQxvP+/wEQPe7/4Vn+e9RE4bygdJ+jsDd8nLuPkgEkB88kNvpilEzSqrhYsvDHZDx9yfgHW8NLDYcf19qnrGNb5/2J0gVfLooTskMi2143r8v+v1luv+0LGIB0+ZHZvwHzd8u+bQkKBunSIdhaN1Hy6nfRvVX7cKCwONB8bgfbjT64ojKUVQghDjWSqHXTuvoIizc0EnCbc36q9qJHre2DsNJuLlO+/OFzzg0vYK99k/BMs3fK99oPSYy+0JynlK/tfNlhfY4NL2DbtRLdV41i6GRKBhT2rujpzq+fnWcDhT0XWsOqgg+fSrwFe1uvn17cy2L1XGXnZHmX32PtCzxzMak+R5nnDW/H9+r3sTWuIlM6FMVIk+przvXTQltxv/+/6N7qgkRE0ZPobfOhgIy3Ove67MhO7w3M5MBeuwjfolsKtju2LyPwz3nWe/dHj+Bb8vOCNs5PH0cLbSVdOQ7XZ48Vnzu/VyxbOMLWuhHfa98vTnp0MwltS0BtTavxvf4j8xzZ5K7t96SjJCRfQQKdx7vsVzjXPo3uq8ZwlOD+uHBopWPzqyjZ3wUlHUdrNYtMKHrKHAoXb0JNtBKc9d84ti7Gvn2Z1SsTOuXXpAafYp0rNehktPA2vMt+STo71FF3llrJkmPjSzi2vonauoXwyXfiW3Qztl2Fa5QF/jmf5OCZpAbNwL75dRKjLizYHzn++2iNq3HULsS/4ArCM+7Avm2p9Xx0RwnJYWdYRT7y+V8rHtaY8VWjhXeQOPI8EkNmddhDBVD6wlXornKrPUB04rWULM79DinZv4FUv2NpnfcwZU+eW3AO3dcP8hI1FBXDU0l45q/N57PpZatXVYvuIjzlRtwrH0SL1FkLgwMkBs8kOeRU6314yo/xLflFwbVi476M+6M/Fd2HnpeoZcpHYtu1EjXRiu4osa4dPe67+F/5Dmq8idj4r9Lx7EJxKPDYNdZQyeC4JGpCCHGokUStG5JpnXsWbWDpptwY/76+vUjUbOaxu0/Uch/2/dlS95EpN6C1bsL92WPY6z+i+eKXCo5p/+196QtfAyA+8nwynipS/SZh27Uid43dJGpqrAEllR2OF9pqbbc1rynoAVGj9daHUzXWaCUe7e+jrXQ5mEO44qMvMnv0GszhhPbtS81ePHcF9vqPAKzhWEDRh9A2hqsid15frndDd5YSmnGHVV69PSXRSuCZS6330fFX4VnxgBlL3jNqG8pm3vtaMHS87/waJZMsSGAz3iqrOIP1s0vH0YKbMRQVxdBxf/oYurtwbqPaVrghr6ewrSewM9FjvoF7xQMoRuGztmV7enRHCemqCVavWarveJxbOq5yGZ5yE/a691FjDdh3vIsaa7TKxwN4PrjXem3f+R6lz19p3lr5SPNa7Qq6AESO+x6BZy7B1vgZGf9gDEWxEjXXqr/hyA4v9S28Acf2ZSQHzcCxxVyzS7f7wObGvfIha75huqqwOI/uroA+R6Gufw7nplfI+AehBXO/o4ar3Kogmd8jVfAMj/4q7o8eRjF0Ysd8A615HbExl3S5fEWq73gzcdRToKfJBIZ12E53V6D7BxKdeA26w4+SSaDGGokc9z305b8l46sp6HFs0zrvTzg3vYR7xUMoepJMxSgi036K/6WrUeO5OXltPY7BU38Hqq3D/5Zk/IOt5CtdNtzqWcuUDDTPoWikA8NwZfvL4kd9Ec8HZo9xcuB0Isf/AFvjp8RHXyyJ2iFMURR2qVWMT7xP5//iCCGEOBjJHLUuxFIZpt3zZkGSBnuXqFk9JbvpISmaVwSo8Wac654FMIdptT8mL4EquFzjZ2QqRmLkfWMO7LZHTY01omTXA8ufG6TGGguGkml5Cx2rsYbiaoapMI71CwoShZZznyQy5UZSlUebYbgrUWONGIpK5ITrrXaG2vX3CLonl6ih5X4mhrOU+NjLC4Z55XNln2Ob2NFfJT78zKJ2aqKFdPlIohOvRWvZYJZFD28vmh8VG/8167WtYRX+Zy/D/9K1KIZOqmZK7nyx+oLjfEvvxPvm7Tg3v0piyCyi7Yp3JAcUDgdNDDqFyLRbyASOKNhuoFhzpYJzHiB29JXZ408keOajdCY59HSCc/5Iy7n/wlA0lFgjWtNqdFd5Udv8YXZtPVO6r7qoXWrgSYRP/Kn5ut8kDLs56NRQbVaSBmbvZTpwBK3z/0JyoFnVMzj3QYKz70XJG2znf+X/mdfKxqS7K0gMz/V6Oje9imPLG2Q8eUVjstUuo5Ou6/C+IyfdRir7bDMlAwiffCeGp7LLIcbBMx8lMeIsEiPPJzH6IjLlhT23yf5TszH2AUUlMuVGYpOuI3r89wnPuAPD04fw9J8Tm3gtySPmFZ0/XXM8kak3kxx0svm+fCSJEWcW/V60JWqJUReQOPIcdFdp+1OZVVGzf0PpPmNz27N/E7q3CsMZsLbHR1+SO7+7D9Hj/h/BM/6A7t23hZLEgddk70dJphlSnRfsEUIIcfCRHrXdMAyD1XW5IYjzxvRlwapdDKvw4LDtRY7bliB1MfRRdwYKesnUWAO2bEELxShOstR4x2XO7Q2fEB1/lfnNe96Qyt1V2VNjjdY6UPmJmRJrRIm3ojv8ZmXBdklcWwEQgNioi3B/9pg1/Cp6zDdAUcmUmUlG6NS78Xz4B3R3Hzwf3EuqZjLJAdNy12qXSBqKRnz0RWTKhuN763YAdE8HFR3JLSAcnPMAro//jJM4+o6VVq9CcftS2gp9RCZ9Gy24BfuOZWjhHWR8NaT6TcKjp/B10kMXG/dltKa1uD97DOf6BVYvI0By6Gk4tnW+MLFnxf0AxEdeUPQziY86n3TlWKtnK11pfuBOlx+JrXlNrt3Yy6whjbqv2iytP+YSYuO+AkDrnAcofeEqq3104jU4ieV6dRQV3V2BGq3H1rSW+MjzssmzBnY3rs/+WfTFQmLYGZ2Wq4+PuhBb3YdETrgeJRXBvfIBlEwK1+onSA44CTWyA1vzOrNip6IQPuk23B/eT6r6eNDs2SUHVuWe4aCTMewes/qju4JMYBjRCVejNa3Gufk185rjvoJ32V0YikLkuO+hpGPEh59lFQpJDjiRdMUYMuXmlxyhmb/G+/bPSeX9zgGk5/6O5M51aI2rrHNHjv8+6YoxtGc4S4lOuNqag5gcdDLpdc+C3dPhc+mu6KRr0X39rB5LPa/nGEDPS7Da4rCOPeYb2JpWm8+y7Z4qx0F2fptekj2nrwbDafYgGpqTTOkQgrN+jxqt3+1SCeLQE3RWQ8r8Yq39lwtCCCEOXpKodWJjY5QvPLKcaUNzPQvnj6/hh6cOx6F9/iTNvvl13Nkhdq51zxAfc4n5gdjmIplXjU1NhcwkRFFQswv7lrz2Q2sYlxJvxf3h/aQrx5Hqb/bYKNmkTmneaFVobJMpPxI12oCSSeD/z9fN4XAbX+w0TjXWYM1Ry+f54F4U3Zw/pu5agdaamxelxBqtD/OhGXcCOnz2GLamNSSGnEZkWuF8sEzFKEKn/taKNTH8THT/oE5jSg04kfApv0QNbbcStfZrqeWCMX9G6cqxhE/5JbaAh9ZddfT5Y64yZHDWPfhf+Q5gVrtrGz6WrjyK6OTrKXnxGrR1z6D7akgOnI7uKMHWvBbdVV4wDA0Am5vwqb/Bse0ttLyhomaMxb1O7UWP+QbJ4fOxFZTdh+SQ00mMvADXqr+hJlrNxAbz50leEcjwjDusRC3jqwbNTviUX+XOM+wMwlNvwff2z4iNu4LIlBuxBzzQkvsZG+5yq0R9unIs8aNylQ87mu8VPKN4fT3rXM5SQqf/Ty6+U36F+8P7YTUkhs/HUbswl6gBmbLhhE/JVYVMDD+zIFFrnf8onnd+g5Pnzd4qIDL1JpTILhyPTEL31ZAYOgvvsrsABcPb11yuIE/r/D8XrOWm+6oLYrRin3A5kZYoZFJU3jcUMOdsdSYy9aaC9+nq4zpt213pfpMI95uUizVvLiZQ0HsMhYlb+78zgHTFSOu14SxFt/vI+Kqt3s5M4AhQNRIjz9vr2MXBJ+KqgbBZKVcSNSGEOHRIotaJPy4xE6K3NjZR6rJx42kjGFtdgrKX3zT73v4vbHnztQLP5IYb1V+b+4CvJEIYDh+6qlqJWv5cGyXRYiUrbcflD30seaOwmmQmMIx0+UgcG8bh2PCfgvlfHVHDO8wCJHmFEyDXy5UpHYqt/mO05ty9mL1wZqJm2JygaNntDR3OZWqTHHAiiSGnkRg+3xwuNulbeLPLBAAkjpiHoajEsyX3DUeufmP7oXets+8rqGSZz3CUEBtzCWgODEUjVZUr246imh+4FYXkoJnmPWY/0OglNWBzEZ10Hc61zxI/6kuULDTXsooPP5PksDl518h+8PVVkxw4neSQ00kNmEZiyOlowc3Ymlaju8rI+PqT7ns0SjqGEm8hNt7s7UpXjiNxxDx0V1l2aJrZYxWa9XscG/9jLUGQOGKeufZV3ny61nl/wrHxRbC5O7z/+OgvYN++hOjEazvc3za/0FAdJAdOL9gVnPkbHFvfQkm0YrgrSA48aY97XRJDTsO+bQmJ4fPRPZVmYY68BKIw1gux7VyO7ulDqvoEUBQSw+dja15DJi+ZN7x9iU28mkzpUDJlI4iPOLto7beWs/6Gc/0LnS643SnNTmzMJVYy2ZNS/Y4lVTUhV/mzXeGe/B61jhT0PCsq8aO+SKr6OPTsnLy0fHjv1RK+AdBQON9YCCHEwU8StU6s2JZLeo6qLmHmkZW7aZ2jJEO437+X6LHfQgvvwL7lDeLZ+UJa4+qCQg0dca94gOSgU1CSIQxXKUYnQ6jy17jyLP0liVEXFCQ37WV8Nej+QbR84QXK/jazYNhch+cPmnPP9JKBVqJmKJpVwEJ3l6N7+1pVDTP+wWjN6ylpq6qnOQti312vkl46mOC83OLJ0ck/wrnuWWytm0hVH0fwjMLFfA27N/e63RCw5PD5JIfP7/Ra+b1M+aXwATJlRxCcm1swu+3Da1uvXWzitcQmXgupmJWohWbfW3AOw2EmVrqvhvDM31jbg/MewrXyIUoW30py8KmEZv2u4wA1R9H9AiSHnFpQ5S9TMZKWsx+n8o8jO23TnuEqIzjvkU73t5Vvb77oxaKezcToi0iMvqjTY7tDDwy1fs7JoaeTHNpxdUUA3duP4PzCioWZilEEz7i/qG3+ouuh0/+3aH9q4HRS7RLP7sr/felJemAoLRc8i+edu82lHdoVkmk/FLI9w1W4v63XTcsu/p0p7zhhFr2D6u1LwrAXVA4VQghx8JNiIh2IpzLsCueKYgwq6/58E9+iW/C+93scW96g9N8XUrL4Vmuul3P9c7s9Vok343vzp7g+/jNKKoxuLzEr3LWTKRlo9bIBeN/7PaXPfHG359bz1nvSXWVF+1P9jiVy7P/LxZId9pgODM1ty/twqKRj6L4atKhZ6TAx/EwMp98qFmFozt32fHWlrfpeR0UtULXc673o4eyywl/NZJI1J5CqOaFwh91NfMTZBE+/t+iYjN+sqNe24HC+xKgLSfafSuzor3zumAvj8JAcOJ3WOQ923bYbgrN+T/zIc8mUj9gn5xP7XnzMJaQrRlu9yxa7h+Sgk2md80DB5uDp/0uyZjK6py/hyTcQPfqrBfsz/iEk+08jMXTW/g5d9CC/x8lWow+01nbdWAghxEFDetQ6UNtSWNBhYKDjoWQdaavKiGq3CoEoqRiG5sK5bveJmq3OXE/K1rTGHProLMHoYBhbpuwIq9pibMwluFf9vaD6Yoc6GPbVOvdhSp83k4aW85/CsenVojbpvsfAp8VrhamROjK+GuyYc6piYy8jdvRXqHjEnFdj2Jzo9lwitLuhjx1pS6I6nYO2L3SR5BnuclrP/VeH+zrquQFIDJuLa/W/rLXICs7nKKH1nMf3PM7OKAqtZ/1tn50uMfI8maN0kNN91TRf/HLxDkWh9cy/FG1ODZxOa7Y3MdZRBUy7m9Zziv++Re/id9nYalRSHZRETQghDiXSo9aB2ubCRG1Q2e5Ldlv0jFVMQ0lFrYIWSiqC1rQaW/Na0mWd91bYs4UktKbVqPFmDGcpRl6PWrp8JBn/YHPOTlYqWw4cIOPpS7J/YQW7jkSm3ki6dAip6uMIT7nRqg7XUTn8/NLcwVn3kPFVk/HVEJ14XUHyZTh86PnzZDSHVVEOIN2unHx3dZbgJYbOJjqx49Lre8I8Tydztj6H5KAZpPqMJTL5R103FkKIA6Dc42CXEUCL1nfdWAghxEFDetQ6sCWbqB1Z6WVNfYRqf/cSNTU7DBDAsellq9S6kgrjXPecWRBj1AX4lvwCQ9EIT/9ZwYLM3uXmvCUtugsoXAcpNuYSa76Mc/UT1jGpqonmMEObi6bLl4FmJ2CPYv9d58UB0v0m0fylN83zTryG2MRrzB1Kcd5u2HLDPhMjzycx8nzrfX7RDsPuKxiSaA59zCVqhrfjMvqdaVtGoLMhk/lzyfbGvjqPxeai5aL/7NtzCiHEXqjw2llDCbZEMxiGLL8ghBCHCOlR68DOUIJSl427zx3Ld08exqCy7g19VPOqI7rW/Nt6raSi2LcvI933GDL+weY2I9Px/Ks8uq8GI1uGW8lbSFrPW8RZ9/QlMeQ0YmO/bC3yi6cC3V1J+MTbSJcO7XbPU7rPUYC5ZlQbw+4mOvG6DnsCC3rJ8ueNAYbmwnD4yZQMIDT9v7p1/XxK0iz0sV+HPgohxGGgwuugyfCj6QlIFS+7IoQQ4uAkPWodqAslqCpxUlXi5NJJA7o+ICs/UcunpCJo4e1m71d+xcK8tZFCM+4o6F0DM1HT2hZAzkvUUv2OzTWyuwmdcV+7Cyo0XmmW8Y6NLywesDuGu5z6a7eiBrfifcesWGjY3ESm3EBkyg1F7VMDphZts9icoGo0Xb6029fPp1o9apKoCSHE3ij3OGjCHOGgxpvQHd4ujhBCCHEwkB61dpZvaeH92lb6lji7btxOfsn8fEoyhBreie6rLkjUdHeuMqDuqSI54CSS/aehZ9tkfNWk+pmL5yZGXpA7oWojfuR5u53vtjd0byW6owRDte++WqPmJDHkdFKVRxftMrQ9f375otnCB/oeDpkUQghRyGlTiWrmEg1qrLGHoxFCCNFd0qOWpyWW4up/mvOuqrpI1JR4C1rLBpR0jFS/Sdi3L8NRuxDD5rFK27fRWreg6EkyvpqCRC2TVzLfsHvNCn6KQuCJM1HqP8FwV2AoasFC2G1Cs+7Zf/MMNCeNV64EjC4XCQ7OfbDjOPZ0ceF2YuOvshaBFkIIsXcy7nJISKImhBCHEknUsj7ZGeKKv35gve/r232i5n/+qzh2mGuGxUecjXPdsyiGbiZt2eqNbbTmdYBZGMPIH3KS99qwe6yEJ1UzGVA6LO5h2d+Twdvmu3Wlkzj2tkdNCCHEvqNkEzUlbw1OIYQQBzdJ1LJW7woXvE9l9N22t9evsF471z2HYuiEp/yY2PirqLyvsBS9rXktkC0OYu94bkD+9siUH5uVuQ5hhk0SNSGEOFjYfJXQIj1qQghxKJE5akB9OME7m5vRVIUXr57MaSMrOW/8buZmYVYVJpwIAAAgAElEQVQ1bKMYGQB0X3/ooCdJa1kPmEMdDbuv4/M58rYralEVxUNF7KgvmS+kR00IIQ4abm+AuGFHzS7/IoQQ4uAnPWrAJX96j9Z4mppSF+UeB3dNtZHx7n6OlWFzQaLdtrx1w/KpiVYMFHPx6k6GMxp2T4fbDzXh6T8nPPWW3Q/bFEIIcUBV+JzUGn0Z0LK5p0MRQgjRTfJpGmiNp80XhoHWuJryv5+Cfeubuz3GsBWvraZ3kqgBGK4ys5csO6crOXA6APFRXzD3dzIk8pCjagVz74QQQvS8co+dzUZfaN3U06EIIYToJknUAC1bD6MunEQLmRUW24YrtqeGsiX4ba6ifQXDF9vR3bk10xquXEnrvIcBCJ18Fw1f+WCvqyQKIYQQnanwOthiVOEIbj7k50ALIcThQhI1IOAxk6S7zhyNEmsAOl4Tzb7lDSr+fDxa46cYSvEcMsPh7/Qaurs8185dnpvDpdkxPJWdHCWEEELsvXKvg81GFVomhhKt7+lwhBBCdMNhn6gZhkEonuLy4wYwY3gfqyKWGt5R1Na1+l8AaK2bUdKx4nN1s0dNCCGEOJAqPHbWGTUA2Os/6uFohBBCdMdhW0zk/a0t3P/2ZhJpnWTGwO8y1w3LJWrtetTSMRwbX8q2aUBJFZbzh1yili4bYZXkt3QwVFIIIYQ4EMo9Dt7VR5FQPTg2vEByyKk9HZIQQoguHLY9arf9Zw3v1bby8Y4QAKUuM2dtS9S08A5zHL9ult53bFmImopk2zShpKIkhs6m8cvv5k6qmudoOf8pohOvAcCwmdUclXjT/r8pIYQQogMOm4rX7WGV53gcW97o6XCEEEJ0Q7cStUWLFjF79mxOO+007r///qL9d9xxB2effTZnn302s2fP5thjj93nge5rXkfhHDO/u61HzZyjpoZ34v7wD1TeOxglEcS57ll0Vzm63YsSa0BJRUhXjEL3Fa+3ZjhLSQ44CYDE0NMAyPgH78/bEUIIIXarutTFBqMaNVIHerqnwxFCCNGFLoc+ZjIZbr/9dh5++GGqqqq44IILmDlzJsOHD7fa3HjjjdbrRx99lFWrVu2faPehtF5Y9aqtR02JmT1fip7E+87dAKihrTg3vkx85Hk4ahejhbahGPpu1z5LDTyJlrP+Tqr/VOJHfZFU1YT9dCdCCCFE16r9Tjbu8KNgoMYa0L39ejokIYQQu9Flj9rKlSsZPHgwAwcOxOFwMG/ePF599dVO2y9YsID58+fv0yD3Nd0w2NZiFgOZrb7DJteleBL15jpq4R3ozgAASjoKgGvtMyjpKInhZ6J7+qAFzQVDu1r7LDXwJFA1Uv2nQgfrrgkhhBAHSrXfxYa4ud6nGqnr4WiEEEJ0pctEra6ujn79ct+6VVVVUVfX8X/gt23bxtatW5k8efK+i3A/WN8QIZkxuPG0Efx68HIAxmpbsNWvRI3VEz/y3IL2rk/+gu7uQ6rmBHR3H7TWLUAuUWu65DWaLnrpwN6EEEIIsQeq/S62pksBUCO7ejgaIYQQXdmnVR8XLFjA7Nmz0bTiNcba0zSFQKDzoYPdoWnq5zrHP15ei8ehcdakgXi3mWuo+UtcKLWvYqg27NOuho8ettqriRYyE79CoNyPGuiHstHsafMEKnAHPBA4Zq/uY1/7vM+lN5NnUkyeScfkuRSTZ9I7VPud7DLMESPSoyaEEAe/LhO1qqoqdu7cab2vq6ujqqqqw7bPP/88t956a7cunMkYtLREuxlmxwIBzx6fwzAMXlu9i9OOrERLpUmlDZxAJBzHWb8Bu68/LWo1fTQnSiZhHRcJjCXREkUbfSVOLYBhcxMrPwH28h72h8/zXHo7eSbF5Jl0TJ5LsX3xTCorS/ZRNOLzqi510UApBgpqZGfXBwghhOhRXQ59HDduHJs2baK2tpZkMsmCBQuYOXNmUbv169cTDAaZMOHgLpqxtSVOOJFhbHX2Q4OimP9vZFASrejOUlCUoknWus9cKDRTdgTRE35IbNJ14Nj9HDUhhBDiYFHtd5LGRthegda6safDEUII0YUuEzWbzcatt97KVVddxdy5c5kzZw4jRozgnnvuKSgq8vzzzzN37lyUtsTnIPVpnblu2uiqwm93lXQMNdGK4TKHhWQCQwv2d1SGXwghhDhUeB02Sl02Vrsn4Niy0FonVAghxMGpW3PUZsyYwYwZMwq2fec73yl4/61vfWvfRbUfrdoZxqEpDOuTnW+hmLmqkoqiJFrJlPQHIF0+smBR0Ey2R00IIYQ4VPXzu3hbPY5jEy9T8sp3CJ3+Pz0dkhBCiE50a8Hr3qIxkmTF9lZGVPqwa223nu0BTMdQEy0YTrMiVqa03QLVu1kzTQghhDgUVPudPJOcSKrveFxrn4JUrKdDEkII0YnDJlH7YGsrZ9y3lI93hBhd5cvbYyZqbT1qbYma7uvfA1EKIYQQ+0//Uje1wTTRsVcAoEV29GxAQgghOrVPy/MfrDK6wR0vr7HeDynP7x3TAVBjDSh62iwmAiQHzSB6zDfQfTXonsoDGa4QQgixXwwud5NI69SrfSgF1PAOMoFhPR2WEEKIDhwWidryLS1saopx02kj2NYaZ+4Yc3kB16p/4Nz0CgCeFQ8AWD1qqDYi027piXCFEEKI/WJwuRuAzekyhgNqeHvPBiSEEKJTh0Witr4xAsCM4RWUeRzW9pLXf1DUVs9WfRRCCCF6m7YRJZ/F/JwKaJKoCSHEQeuwmKNW2xzD59QIuO1dN1YOi9xVCCHEYajMbafEaWNDSwbdVY4akkRNCCEOVr06UTMMA90wqG2JMTDg7nKNN91ZSqrmhAMUnRBCCHFgKYrCkHI3m5tjpCvH4ly/ADVS19NhCSGE6ECvTdTiqQzH372YE+5ezLLNLZTnDXkEwDCKjmm+cIG14LUQQgjRGw0q97C5KUr4xNtQEy04V/+rp0MSQgjRgV6bqLXEUgXvjx9cmIApqXDRMbqver/GJIQQQvS0IWVu6sNJgr6hpMtGYN+2pKdDEkII0YFem6iFExnr9Q9nDueSiXnrohk63qV3FR+kOQ9AZEIIIUTPGZwtKLK5KUaq/xTsO95BSQR7OCohhBDt9dpELZRIW6+nDi0rmJ9m374M90ePFLRPDJtzoEITQgghesywCjNRW1cfIT7yfJRMAt/iW3s4KiGEEO312kQtnE3Ufn/+WAYE3AX71NDWgvcZ/2CCc/54wGITQgghesrAMjdeh8andSHS/SaRHDob2873ejosIYQQ7fTeRC1pJmo1flfRPlvT6oL3kROK11MTQggheiNVUTiyr4/Vu8y52pnSIWihraBnujhSCCHEgdR7E7XsHDWfM29dNEPHueYpbA2fWpsaL3+HxJHnHujwhBBCiB4zusrHmvoIumGQ8Q9C0VOokZ09HZYQQog8vXZ157ahj/mJmvOzJ/C/9r2Cdrq77IDGJYQQQvS0weUeEmmdulCCQf7BAGjBzegl/bs4UgghxIHSi3vU0tg1Bactd4v5Qx5j466g/tqtYHN3dLgQQgjRaw3Kzt3e0hwjUzoIAK11c0+GJIQQop1enKhlKHEWdhiqsQbrte7uc6BDEkIIIQ4KA8vMRK22OYbu64/uLMW+490ejkoIIUS+XpyopQvnp1H4baEkakIIIQ5XlT4HTptKbUsMVI3koJNxbH4NDL2nQxNCCJHVexO1ZBqvQ8ttSMewNayy3uru8h6ISgghhOh5qqIwqMzNhsYoAMmhZ6DGGqj8v0E41z7Tw9EJIYSAXpyo7QgmqPA6rPeOza+jpKPWe+lRE0IIcTgb2dfH6rowhmGQOGIOGW8/ANwrH+zhyIQQQkAvTdQaI0k2NkY5pn+ptc2xZSG6M/fecFf0RGhCCCHEQWF0lY/mWIq6UAJUGy0XPkeq3yS05vUyBFIIIQ4CvTJRe6+2BYBJA3OJmRrdhe6rsd7rkqgJIYQ4jI2qKgHg0zpz4Wvd24/46EtQEy1msiaEEKJH9cpEbdH6RkpdNusfIQA11oju7kNiyCwAjLzeNSGEEOJwM6qvD5dN5d0tLda2VM3xANh3SgVIIYToab0uUYunMixe38QpI/pgUxVru5molROcfS+Nl78DirKbswghhBBdW7RoEbNnz+a0007j/vvvL9q/fft2LrvsMs455xzOPPNMFi5c2ANRdsxhUzl2UIC3NzZhGAYAmdKh6M5SSl6/Hteqf/RwhEIIcXjrdYna1pY40VSG4wYFCrYr2R41bG70kppOjhZCCCG6J5PJcPvtt/PAAw+wYMECnnvuOdatW1fQ5t5772XOnDk89dRT/Pa3v+W2227roWg7NnlwGdta4+wMJcwNioKeLSpS8voP8L71sx6MTgghDm+9LlFrjacAKPPYcxvTcdRUWAqICCGE2GdWrlzJ4MGDGThwIA6Hg3nz5vHqq68WtFEUhXDYnAMWCoXo27dvT4TaqXE1fgBW7QxZ20Kn/paMtwoAz4d/QEm09khsQghxuOuFiVoagFJXLlFTY02AFBARQgix79TV1dGvXz/rfVVVFXV1dQVtrrvuOp599lmmT5/O17/+dW6++eYDHeZujaj0YtcUPtmRS9TSfY8mOPsP1nutdXNPhCaEEIc9W08HsK8FY2aPmt+VvTXDQI3sACRRE0IIcWAtWLCAc889lyuvvJIPPviA66+/nueeew5V3f33pJqmEAh49uramqZ26xxjqv181hApbBuYTvq8h7A9eSVl/5xL+pInMIbN3Kt4DgbdfSaHG3kuxeSZFJNnUmx/P5Nel6i19agF3HYcm1+j9LnLrX26p7KnwhJCCNHLVFVVsXPnTut9XV0dVVVVBW2eeOIJHnjgAQAmTJhAIpGgubmZiordf3GYyRi0tET3Kr5AwNOtc4yq9PL0RztpaIoUFOGiYhpt/2ra/n4B9d/cCJq9w3McKrr7TA438lyKyTMpJs+k2L54JpWVJZ3u63VDH4PxFA5NwWlTsdcusrbHRl9EumpCD0YmhBCiNxk3bhybNm2itraWZDLJggULmDmzsNepurqaJUuWALB+/XoSiQTl5eU9EW6njqouIZ7W2dTY7sOGw1vw1rfwxwcwKiGEEL2vRy2WptRtR1EUdE9u0nZ4xp2g9Lq8VAghRA+x2WzceuutXHXVVWQyGc4//3xGjBjBPffcw9ixYzn11FO54YYbuPnmm3nkkUdQFIU777wT5SBbHuaofmZBkY92BBleWZicRY79Drq7D7b6j3Gue5bwjF8c8r1qQghxqOh9iVo8Zc1PU1IRAFrOfkz+YRFCCLHPzZgxgxkzZhRs+853vmO9Hj58OP/4x8G9HtnAgIu+Pgdvb2zi3KOrC/ZFT/ghAI71C3B/9hieD+4jeuy30Fo2oLVuIjn40J+3JoQQB6te18XUGk9bFR+VVATd7iM1YFoPRyWEEEIcnBRFYfoRFSzd1Ew8lemwTar/VAC8y+7CXruY8r9Op/S5y/Es+xVKInggwxVCiMNGr0rU6sMJNjVGrTXUlFQEw+7t4ighhBDi8DZjeAXxtM67W1o63G+4ymg56+8AlLzxI2u7d/k9eN777wMSoxBCHG56VaL22AfbCSbSfOnYAQAoqSiGQxI1IYQQYncmDgjgdWgsXN/YaZvUgGkYmhMtuAXDlitHLT1qQgixf/SqRK0hnKDS62BstTkxWkmGpUdNCCGE6ILDpjJlSDmL1zeiG0bHjRQVw2H++xqa+RtrsxbcciBCFEKIw06vStSaoilr2KP7vf/BuflVDLsszCeEEEJ0ZcbwCpqiKT7ZEeq0TfCMewme+lsSI84k1Xc8AI6ti7FvfetAhSmEEIeNXpWotcSyiVoqim/pnQAYdl8PRyWEEEIc/KYOLUNTYNHuhj/WTCYx6kIAWi5cQOvchwDwvfnTAxChEEIcXnpVomb2qDlwbH7N2iZDH4UQQoiu+V12xtX4Wba5udvHJIeeTnjKj7E1fooa2o538U+w7VqxH6MUQojDR69J1AzDoCWWotxtx9a0OrdDFrkWQgghuuWEwWV8VhemJZrq9jFta6mVPnMJnpUPUvrcFfspOiGEOLz0miwmmsqQSOuUeeyosdywDSUp1aiEEEKI7jhxWDkG8Pq6hm4fkykfRWLwqdha1gOgxurxvf6jLo4SQgjRlV6TqDVnv/1rn6ipUjZYCCGE6JaRfX0MKXfz/Kq67h+kKIRm/obQjF/QcMX7JIbOxr3qrwT+OQ81uBVb3YfQWSVJIYQQneo1idrra81v/yp9TpRYA7qzFJD1XYQQQojuUhSF00ZWsmJbkJZY94c/Gp4+xMdehuHtS2zclwGw71pBxaOTKXtiPs41/9pfIQshRK/VaxK1R96p5bhBASYNDKDGmkhVn0Bi0CmEZv6qp0MTQgghDhmTh5jDH5dvaflcx6f6HVe0zbnu+YL3jk2v4P7wj5/r/EIIcbiw9XQA+0I6oxOMp5k4oBSbqqDGGkj1n0J4xh09HZoQQghxSBnTrwSfU+OtjU3MGlm55yewu2k+/2kUPY0arMVWvxL3x3/BvuUNUgNOBNVG6YIrAIiNvwoUZd/egBBC9BK9IlFriacBCLjtoKdR4i3orvIejkoIIYQ49NhUhRnD+/D62gZumDUCp23PB9+k+00yX9ScQKrmeDwrHyLw7JdI1kxGC2+32nnevRsttI3QzN9IwiaEEO30iqGPbePoA247rs8eR8FA9/Tp4aiEEEKIQ9Oc0X2JJDMs+GTnXp9L9w+iZf6jJI6Yh2P7UrTgFmuf993f4vrscbSmz/b6OkII0dv0ikStNS9R8y69C4B05bieDEkIIYQ4ZB0/KMCEAaX835ubSKb1vT5favApBM/4A+GpN5PxDy7a7/r0sb2+hhBC9Da9KlHro0ZQY42Ep9yUG3YhhBBCiD2iKApXHD+Q1niapZub99l5YxO+SdNlb9HwtU8BSBwxj/iR5+JZ8QDexT9BiTVh3/rWPrueEEJ0SU+DsWdfSNlrF+E8AF8w9Y45atlErTKxEYBMxcieDEcIIYQ45B0/KIDfZePFT3cx/YiKfXpuw1FC/dfXguYADHRXOZ6VD+JZ+SBAthhJCt+iW4mNuYTkEXPQvf3QmtaCopApG75P4xFCHF7s25ehNa0mPvZyyh+dQrrvMQTndL8SbeCZSwFIHXvx/goR6DWJWraYSGQ9AOlySdSEEEKIvWHTVOYfVcVj72/juuBQqv2ufXsBu9t6GTnpNlIDT8L3+o/QonWU/etsa1/J4ltg8S0kjpiLc71Z5r/p4lfIVIzat/EIIXo/QwdFJfDv8wFIV4xGC+9AC++w9gGgZ1DSMWx175PxD0YxMpCO4333tyipqHU6ZeNC6Dt9v4XbSxK1FF6HhiNci6E50X01PR2SEEIIcci7ZGJ/HvtgO39/bxvfO+WI/Xqt5JBZNH3lPfzPXY5z82sApPodi33ncgArSQMoefW7tFzwHKjafo1JCHEQSMWw73iH1MDpu68Oq6fx/+cbxMdcgu6uQPfVoHursO1YTrrPGJwbX6Lk9euJHvM165CyJ8+1Xpe8/G3UeBNay0aUeDNqKtx1bJG6vbmzLvWKRK0pmiTgtqMkQujOUinxK4QQQuwD/fwuzhhVyVMf7eCb04bgcez/xCg4+w+AgRbZiWH34nv9eiKTf4S97n1cnz5OfMzFlLx+Pfati1Gj9WihbejOUhKjLsRw+NCa12Gr+4Dk0NkYTv9+j1eIw5JhgJ4Ezfm5DrdvfQvXqr8TOvU3qJF6dP8AALSmNfjeuo3wtJ8C4NzwPEq0Ac9HDxOcdQ+Gw4/u60fGU4WtdSPpshHYty8hOfhUHJtfw7nxRZwbXwRAt/tIV0/CsWUhhuZEySQA8C6/J3cbikZ87GW4PvkLrrVPYdg8pGqOJ+PtB4qGc+3TqKkwsdEXk6o+jnT1cTg2vYLvrdtpvOxt/INGQUuU/aVXJGoNkSR9fQ6UVBjD4evpcIQQQoheY86YKhas2sWH21qZOvQArFGaHRKZCQwDIDj/T+b7PmOIH/Ulc/jR2z8n8OyXCg5zf/wooVm/o+Tl67C1bCA64WoiJ/wA35u3o6SjhE797f6PXYjezDBwbHoF9AzOtU/hWvcsDV/9CMNVhta4mkzJABzbl5Ip6Y8W3IJhcwEq9m1voyZaCE+7BWzm33fps5eh6Elca58CIDzlJpJDZuF/6RpsjZ9Rtn0uSjpWcHn/K98pDsnmRknH0B0lKMlcD5juKEF3V+DYsjDXVrWj6CnrffN5/yZdNQFUG7FxV2Df8S7x0Rflhj8C4VPuQonswvD2tbbFjvk6sXFf/txJ6p7oFYlafTjJyL4+lEQQw1HS0+EIIYQQvcb4Gj82VeG92pYDk6h1xeYiOunbeJf9kvjI89FaN+LYtgRb8xrK/jnXauZc/SRKKoL74z8DEBv3FQhMhnQcrXk9mcqjPt/1DcOcyyLDLsWBZOgoqcgefc611y4mXTEa43OsLWzb+R6gkO430dqmrF5A6YIrCto5Nr6MGm/C9/Z/FQxVNhTNnNeVx/3xn8n4qtF9/VH0ZME+35Kfw5KfAxAb+2VsdR9gr18JQMY/mMjkG1CDm8mUDsG+czmu1U+ixpsAg/DkG7C1bCBTMoDEsDNwbHmD+FFfwnCU4F75IJnAMNKBI0BRMFzloKfQWjYUVIjPlA3vtEhRfpJmOQBJGvSSRK0hnGTaUAdqc1gSNSGEEGIfctk1jq7x88a6Rq49aSjqQTC9IDbhG8TGX2UlS0oyjK1+Jc7VT+LYtoTwiT/B/59v4v74z6QrRpnf0P9zLvrAyZQ3bkCL7iI85UZca56i5ey/Y7hzVS1dKx9G91SSHD6/w2u7Pv4zJYtuInTKL4mPuXS3cWrN68x14zT7vrt5cUhTog0YrrI9TvTdKx/G9+ZPaDnncbTm9cRHXoAW3EQmMBz7trdIDTgRVBtqsBYUDQydwDOXkKw+gfDJd6J7q9Ca12I4A7g+eRSAyNRbAAM1UmcmP5/8hdjRV5KuPNoq6JPqNwklGSZ08l0omxcVxeV/7XvW67YkDcCwuVBSEQDioy7Eue45lHQMLbwDNdaUa6dohE+6HVv9R2AYKOkY4en/BYBt1wrSfY8u6OECSA6fT+TEn0Im2zvW7u8r1mdM7vX4qzp8nofKMl6HfKIWSaaJpjJU+hwoO4PogaE9HZIQQgjRq5x3dDU3P/8Zb25o2uel+j+3vA+6hsNHqv9UUv2nmj1eikLjV943P8BWn4B36Z24P/0Hau1S6xjfkjsA8Hx4P9FJ38K2czned39nfdhsqniD0qcvIjL1ZhJHnosa3oEa3o6j1vyw6l7xIPExl5q9FpXjMFyBgvBcH/3JTOhOvov4UV8Ew6DssdOJjb2M+NjL9/fTOTilothaNpCuHNvTkexTSqIV+7YlJIedYW4wDGwNn5Duc1SubkIqhmPbW5QuuIL4yPOJTL4B3VdtJhuqzWrn/OwJlGSQ+NFXFlzDuebfAASe+gIAJQt/DIDuLEVNtBId/zVi46+i7PE56K4yEiPOAsCxYxnlfz8Fw+ZBSRfOpXKteRqMTLZnyuTYtsSs95Bl3/keurOUsifPKTi25cy/oqTjeJbfQ6rmeCJTbsK79E6c654BRSN0yq9QUlGSA04Eh5foxGuzSaRKqv9U1PB2sLkwVDuGu+Oe+nTVMbt/8IfBFyCKYRhGT1w4lcrQspeT7wIBDx9uaODCh5dz+9yRfPGds0gNmEbo1Lv3UZSHpkDAs9fPtreRZ1JMnknH5LkU2xfPpLJSRjvsiX31b+S++l1O6wbnPvAObrvG/RePJ+A+9D4gBf45D/uuFQDExl5uDYnsjvCUm/C+82uUTML6YGyg0Hr2Pwg8fRHRCVeT8Q8mUzoY3VtFxj+QikeORU20Eh95AaFZv0Nr2UD5X80y3vXXbgVAbd0Mmr24WnUqVrB8QXvexT8h1X8yyWFz9vApdGy//XcvkygYIlb291OxNa2m/utrwO7p1imUWBOGs3SPe6C05vU41z1DcuAM0n1GW3Ojumt3z8S2ayWOTa8QH3MJhqOEkpe/jXPTSzRd+gaZsuG4Vj5MyeJbSPafQvyoy0gMPxP/81fi3PSydQ5DdRA84w943/4Zht1H67xHQLPT58FxAGS8/QjOvhdbwyc4tr6Jc8N/iuLQnQGUTBwlHd+je8uXKRmAYXOhBWuJjb8K+7a3QbUTmvFz3B//hcSIMzFUByVvXI/a7yjCNadgaA6SR8zt+ITZL0oOF/v738dDvketIWyOca30OlFSYXQpJiKEEELsUzZV4dJjB3D36+u58m8f8MSVxx0UQyD3ROvchwkkN9FcdjwYBsn+U0lXjsO+awXepXeiBbcQOeF6XJ8+hhbcXHCsLzt3BkBNtJIcOANH7UL8L5jDqjwf3FvQPjzlRjOZU+1ojZ9i3/oWzg0vAGBkh3EpsUYq/jIN3VVGaObdJIfMAkXBtmM5ZU+eQ8vZj5EaMK3oPpREq7kw+MoHrYSvgGHgee/3KNEGItN/tlfPrCNKZBcKBrq3arftHOufp/Q/X6fpi4vIBIahtm7G1rQaAK1lY/fmCCYj9HnoaGLjvkx4+s+7bt9Gz+B/4avYmtfhfec3xEZfRPjku8yeK0CJ1mNrWlPwfB0bX0INbSV+9JW4Vv0dZfDR4BmDGtqKXjLATD7ScRxb3sD/4tUoegrvu4UdA+V/O5nohG/i+uyf5jm3LcGxbQm8dE1RiIqexP/CV1EMHYA+j0ws2K9Fdlql43W7FzC/MPAt+Tm6s5TkoJMJnfY/YGTAyOBa9Q+8S+8kMu0naE2rsTWvIXjq78y5W6WDcX/4R2JHfQkFA1vdBySOmIeSSZhJcL68RCs8I/fMmy9+hUDAQ6KrpOQQ++/Cwe6QT9SCcXN8aqlLQ0mGZI6aEEIIsR9ceEwNW5tjPP7hdlZsCzJhQGnXBx1EDG9fjP5DzI2FRnYAACAASURBVFLaimLNQUuUDiYxZBZqvBm9pD/RY78Negb3yofQgptRkiFSNVNwf3g/tuY1AERO+CGO2oWoyRAZbz+0yE4AdIcfNRnEt+QOUv2OJVVzAp73/5fA0xdZcSiGTulTF6KGdwCgxpspff4r6A6/OVenYRVgFl5QI3Xo7nJQ7WZSkYrheec31rnK/nYKiSPPJTrxGjB0bA2r0Fo34V32KwCik3/UeTVsPQ0oKKkIyqbleD99ifjoi9EdJWBzUfrURei+aoKzfg8OM1HQ6j+h7MmzUdJxGr72WfG5Mymc657Bt/Amaw0q+9Y3yQSG4dj2ttXM1rKhIFFTWzbi3PSymUgkw9jrPiA59HQcO5aZz+KjPxGdcA1qdBeOTa+ihWqJHf1V0n2PxrZjOfbtS0kOOgUtvA3dGcD/6ncLkm33p4/h2Pw68TGXoEbqcH/6D2tfYvBMDJsH1/rnAPCseNA6tjLv1lL9JqHEmrC1bjRv1dcfLbyt6LF6Priv4H1s1EXYGj5B9/UzqxJqTlrn/xnXqr9SsvBGohOuRncF8L5zN+k+Y9DdlSSOmIthd2NrWktyyKmk+4zFVvcB6apjiI2/ElRHLiFSbICN+Lgvm1VR2/U8pjzmXUSm3ZL7MWUrqppVGduRROugcsgPffzrWxv56X9W8/TlYxj/+DGEp95MbMI391GUhyYZulVMnkkxeSYdk+dSTIY+HngH29DHNrFUhjn3LWXq0HLumD96n577QNjbZ6IGazFsbgxPH5yrn8Cz/L9pnfcIzo0vkhh2BnrpEHwLb0JJhghPuxU11kjgyXMBg8jUm7HtWoF71d+s87UNo+wO3V2JGqvvcJ+haKT7jMFe/1HBdqtXLpPAvv0dfItuJjloBuk+YwuKQOxOaMadpPpPNucftRt+l+o7HsPuQQ3vQC8ZgH3n+0XzoBJHzEN3VxQMNU0OnA7pBOnKsSjpGK5PH0MxMsRHnI297kO04GZ0VxlKvAWFzj+mpvoeg63+o6Lqgl3RnaUYmpmkqPEmDM2BmoqQDgxDa93c6fkyJQOJTL4ew+4j1Xc8/le/S/jEn6K1bkJrXoeip8yELt6M4S7HvuM9osd+q5Mg0jg2v05y0AzQHGYl0XZFMw428u9jMRn62IVYyvxj8mCutSDrqAkhhBD7h9uucf74Gh59t5ZvThvCoLI9m/dzqNP9/7+9+wyMqsr7OP6dkt4mpEwooSb0LiyCIBKaghSlqCBiYfGxgYoNXVnXFd21rOKuClgRd+2KCjaKGkEEadKRFgiETCCV9MzMfV4EB2OCiCRMJvl93oSZuffOfw6ZnPnNOffceM+/S9qMpaT1GDCZKnxB/MvpYq7gaLKu+R4MF0ZgJOYmffE78gOF591C6LcPkXfJfMzH08pHOMxWAn76gIDdn1DSejSYTJ7RmaJ25SNy1syd+GX8iDMykeK2Ywn5YQ6GyYy5LL9CSDve/x+EfXMfto+uwB0Yibk4GwADE8E5e6t8bcUJIwnc8/HJ13H+fQTueo+wb+6rcnvDbPWc8wdAbgpOWyuMoAYUtbvKEwQD9i7xbFIW1wNz/hH8U5Nx+4fjf2QNhtmP4o6ToKyIoJ1vl7dbeDPcARFYXKWUNjofV2QC1qOb8Tv8Pc6YjpQkjMRcmIFfxiZKWo+mqNO1BOxdgiusCYG73ie/70O4wuLLRwtdxViPbcMIiCR4/b8pOP+e8kVnPC/EDYYbc0EG7rBGmEryMJUVEB7o4nhOHoZfCCa3E1dEs/LVFH8x4pQ78r/l9TZIhBaDK7VRhef5NbOV0l/uU8tDmnhH3Qlq7vIlQA3/cG+WIyIiUqdd1b0Rb6xL5ZOt6dzSr56vtPw7pokZASc/l7gjmpE94SugPOj9mjO2c/my4ycU9piOJXMnzoY9T27kLj8nCYs/Rd1vAcAvNRlzQQZGYCSmokxK2o3HevRHrMe2Y/iHl1982GQid9Q7BG57A0vOPvIHPA7uMoLXPYtf0j0cLwvBCLRhmCwU9piOERyNy9aCwB1vg2FQ0HsmfmlrCPv2QTKvWYM7tBH+B5bjjEw8cX2vUNzhTT1l5ln8cUU0I3TlQ5S0Go4ztguu0Ib4H1qFqTiboi5/xj/1G5yRCbgjmoPhpqzJBbgimle4dlcFpQWeaZiV2s7eDYDiTteebPsTP11R5aO/pc0HVt7RZAaTGXdY+YIuRkB4+f+ZLRiXVaNH4l0+H9SKy8pPwgx0/RzUNKImIiJSU6JDA+jdvAGLtzm4/vymBPnpws81xfAPqxjS4MQ5SL86Dyn+wkr75g94ospjFp5/T4XbBf3+hi0kGHIKye//aIXHSlsNp7TVcM9tV3T78ksLnDgPqrT5oFPWXtK6fDn3nDEfVbi/uP3JMFdhf5OZkjaXn/J4wClDmkhd5fPjrEVlLvwtJqxFDgBcwb+9CpGIiIicnWv/FM+xglJeWn3Q26XIuXaGy+SLyB/n80Gt2OkmyM+CJT8NwDN0LSIiIjWja5MIRnWMY+EPqWxJy/N2OSIidZLPB7WiMheBfhbM+UcwLAEYATZvlyQiIlLn3TmgFWGBVv67vopreYmIyFnz+aBWXOYiyM+MOT8NV2gjXf9BRETkHAj2tzC6Uxxf7T7GnmMF3i5HRKTO8fmgVlT289THI7hDNe1RRETkXJnUM54Qfytzvt6Hly7LKiJSZ9WBoOZihPNL/NLX6fw0ERGRc8gW5MeU3k35/kA23+3P9nY5IiJ1is8HtWKnm+7OTQAU/eLaGSIiIlLzxnVtRNPIIJ7+ei/FJ65tKiIiZ8/ng1pRmYtIcilt1AtnbBdvlyMiIlKv+FnM3JXUigPZRTy5Yq+3yxERqTN+V1BLTk5m6NChDB48mPnz51e5zaeffsqwYcMYPnw4M2bMqNYif0txmYtwdy5GUPQ5e04RERE5qXfzBlzdowkfbU1n7QFNgRQRqQ7W023gcrl4+OGHefXVV7Hb7YwdO5akpCQSEhI826SkpDB//nzefPNNIiIiyMzMrNGif6mozE24OQd3UNQ5e04RERGp6PpeTVm66yjT3t/C61d3p3VsqLdLEhHxaacdUdu8eTPNmjUjPj4ef39/hg8fzvLlyyts88477zBx4kQiIiIAiIo6d6GptKyUINdxBTUREREvCgu08trEbvhZzPxP11YTETlrpw1qDoeDuLg4z2273Y7D4aiwTUpKCvv37+fKK69k/PjxJCcnV3+lVXC7DYKdeZgxFNRERES8LDrEn8s6N+SzHRnsdBz3djkiIj7ttFMffw+Xy8WBAwdYuHAh6enpXH311XzyySeEh4efch+LxYTNFnxWz1tY5qKBKQ+AoOhGBJ7l8eoKi8V81m1b16hNKlObVE3tUpnaRM7En3s344udGTy6dDevTOiG1WzydkkiIj7ptEHNbreTnp7uue1wOLDb7ZW26dKlC35+fsTHx9O8eXNSUlLo3LnzKY/rchnk5BSeRelQZDITdSKo5btDKTvL49UVNlvwWbdtXaM2qUxtUjW1S2XV0SYxMWHVVI3UdmGBVmYMaMUDS3Zy78fbeXJUe0wmhTURkTN12qmPnTp1IiUlhdTUVEpLS1myZAlJSUkVthk0aBBr164FICsri5SUFOLj42um4l8oKHESS/nqUu7g2Bp/PhERETm9IW1jmXZhC5L3ZrJ4m+P0O4iISCWnHVGzWq3MmjWLKVOm4HK5GDNmDImJicyZM4eOHTsycOBA+vXrx6pVqxg2bBgWi4V77rmHyMjIGi8+v8RJI1MWAK6QhjX+fCIiIvL7TOzRhOS9mTy2bDe2ID/6tdK55CIiZ8JkGIbhjScuK3Od9VSabZmFHHzjFq4KWkPO1O3VVJnv09StytQmlalNqqZ2qUxTH8+96ugja8Pvcl5xGbe+t4V9mYV8cH1PYsMCvFpPbWiT2kjtUpnapDK1SWU13T/+rgte11b5xU4amrIoDY47/cYiIiJyToUH+vHYiHY43Qb/XL6HvOIyb5ckIuIzfDuolThpaMrEqWmPIiIitVLjiCBu6duclfsyGf/aer7bn+XtkkREfIJPB7WCUhcNTZkQ1tjbpYiIiMgpTOoZz4KJ3QgPtDLr050Ul7m8XZKISK3n00GtqCCfKNNxTOGNvF2KiIiI/Ia29jDuHZhAbrGTT7QSpIjIafl0ULMUHCn/R7hG1ERERGq77k0i6NY4nPnfHSCrsNTb5YiI1Go+HdT8TgQ1d6hG1ERERGo7k8nEPQMTKSpzce/H2ylzub1dkohIreXTQS2g8OegpsVEREREfEFCTAizhrZm0+E8Hl26G6fCmohIlXw6qIWWlM9x18WuRUREfMeQtrFc0zOexdscjHl1HZkFmgYpIvJrPh3UbGUZ5JrCwC/I26WIiIjIGbi5b3P+MiSRzIJSHliyA6fb8HZJIiK1ik8HtcZlKTjMdm+XISIiImfIYjYxqlND7h+cyPrUXOZ8sw+3obAmIvIznw1q5vwjJJRsZ431T94uRURERP6gYe3tXNGtEW9tOMxfP9vl7XJERGoNnw1qlqxduLGQ7H+ht0sRERGRs3DngFZc3aMJn+/IYH1qjrfLERGpFXw2qJXF9+f2hq+TbtU11ERERHyZ2WTiz72b0cQWyP+9s5lp72/hWH6Jt8sSEfEqnw1qmExkmaMAk7crERERkbMU7G/hhXGdGde1EetSc7js5R/Yl1ng7bJERLzGd4MaYBgGZuU0ERGROiEuPJB7BiawYGI3DODF7w5iaIEREamnfDyooaAmIiJSxyTGhDKpRxOW/XSUN9Yd8nY5IiJe4dNBzW0YmExKaiIiInXNn/s0IykxmudXprByX6a3yxEROed8PKiBcpqIiEjdYzaZuG9QAi2jgrnjw21Me3+LzlkTkXrFp4MaoBE1ERGROioy2J+XrurKkDYxrE7J5v/e3syNb//ItiN53i5NRKTG+XRQcxuGb78AERER+U1BfhZmX9qOBRO7ER5oZcOhXF7/QeetiUjd59M5p/wcNW9XISIiIjWtfVwY713fkyu6NWLF7mM88uVPuNxaEVJE6i6fDmqGoamPIiLiPcnJyQwdOpTBgwczf/78Krf59NNPGTZsGMOHD2fGjBnnuMK6Z2KPJvRr2YCPtqRzz8fbWbUvizKX29tliYhUO6u3CzgbWp5fRES8xeVy8fDDD/Pqq69it9sZO3YsSUlJJCQkeLZJSUlh/vz5vPnmm0RERJCZqdULz1bD8ED+dVlH5nyzjzfWHSJ5byaXdrDz14vbeLs0EZFq5dMjam7DwISSmoiInHubN2+mWbNmxMfH4+/vz/Dhw1m+fHmFbd555x0mTpxIREQEAFFRUd4otU6admEL3rm2B0PbxvDZdgdb0rTAiIjULT4d1Ay0PL+IiHiHw+EgLi7Oc9tut+NwOCpsk5KSwv79+7nyyisZP348ycnJ57rMOstkMtEiKpjb+7ckNiyAm9/dzJqUbFbtz/J2aSIi1cKnpz663QZmJTUREamlXC4XBw4cYOHChaSnp3P11VfzySefEB4e/pv7WSwmbLbgs3pui8V81sfwBTZbMO/e2JuRz3/Hre9vAeCdqefTLd5Wadv60iZnSu1SmdqkMrVJZTXdJj4d1AwDTXwUERGvsNvtpKene247HA7sdnulbbp06YKfnx/x8fE0b96clJQUOnfu/JvHdrkMcnIKz6o+my34rI/hKwKAV67qwjsb0/jf+sM8/Mk2nhjZnujQgArb1ac2ORNql8rUJpWpTSqrjjaJiQk75WM+PvVRy/OLiIh3dOrUiZSUFFJTUyktLWXJkiUkJSVV2GbQoEGsXbsWgKysLFJSUoiPj/dGuXVe44gg7rioFf8c0Y4djnxGvrSWR774iQmvryc9r9jb5YmInDGfDmpuA019FBERr7BarcyaNYspU6YwbNgwLrnkEhITE5kzZ45nUZF+/fphs9kYNmwYkydP5p577iEyMtLLlddtSa1j+O+k7tiC/Phoazq7jxaweJvj9DuKiNQyPj31URe8FhERb+rfvz/9+/evcN/06dM9/zaZTMycOZOZM2ee69LqtVbRIcwd3wXH8WJe/O4A8747gC3IjykXJZx+ZxGRWsKng1r5OWpKaiIiIlJR08ggmkYGERMawN8+38UTK/YQEuLPxQlRmPQtr4j4AJ+e+mgYhi54LSIiIqfUvEEw/xnbiT81i2TWx9u5f/EOsgtLvV2WiMhp+fSImtvQddRERETkt4X4W5lzeUfe3eLg6WU/seZADtef35TjJU5u6NUUf6tPf28tInWUjwc1Q9MXRERE5LTMJhM3XtiSno3DuPuj7cz5Zh8AjcIDGNWpoZerExGpzKe/QjJAUx9FRETkd2sZFcJ/J3XntQldad4giKe/3scLK/drCX8RqXV8O6hpRE1ERETOUKCfhQ4Nw3n6so70iLfx2tpUrlywntfXppJxvMTb5YmIAD4e1NwGWvNRRERE/pAmtiCeHN2B967rSUSQH//+dj/jX1vHtiN53i5NRMS3g5phaOqjiIiInJ34yCDev64Hb15zHhFBftz4zmY+2+HAMAxvlyYi9ZiPBzVNfRQREZGzZ7WYSYgJ4eWrutLOHsqsT3dx/ZubSN6bSUGp09vliUg95NNBTVMfRUREpDpFh/jzwrjOzBycSMbxEmYs2sblL//Ait3HcGuETUTOIZ9ent/AwKwRNREREalGVouZyzs3ZGjbGD7bnsHzK1O49+PtAFzSLpZZF7fBBFh0/oWI1CDfH1HT30gRERGpASH+VsZ2bcQnU//EoNYxAHy2I4PeT3/LzMU7dA6biNQonw5qhmFo6qOIiIjUqBB/K49e2pbVd/Tjmp5NAPhq9zHOf/pbDuUUebk6EamrfDyooamPIiIiUuNMJhNWs4nbLmzJqul9Gd0pDrcBd3+0ndRshTURqX4+HdTchqGpjyIiInJO+VvNPDCkNXMu78jR/BKuen09/1i2m73HCjQdUkSqjY8HNbQ8v4iIiHhFnxYNeG5cZ9rZQ3n/xyNcuWA9j3z5E063QWZBKd+nZFHqdHu7TBHxUb696qNh6ILXIiIi4jVtYkN58cquLNt1lBW7j/HxVgfrUnPJLCilxOnm+vObctMFzb1dpoj4IN8OaoBJy4mIiIiIlw1qE8OgNjEMbB3Nos3ptGgQTFpuMW9vOMzIjnYaRwR5u0QR8TE+HdTcGlETERGRWmRg6xgGnljK/1BOEVcv3MDol37AYoK+LaN4fFR7LYQmIr9LHThHzdtViIiIiFTWxBbE3PGdGdg6GpcB3+zNZMLr65n95U+4teiIiJyGT4+oGYahxURERESk1mprD+MfI9qTU1TGA4t3sPZgDnuPFZJdWEZsWAA3XdCcsECf/jgmIjXEp/8ylF9HzdtViIiIiPw2W5Afc8Z0YmtaHvNXH+CbvZkAbE7Lo01sCC4DHrq4jZerFJHaxKeDmtswtJSIiIiI+ASr2UTXJhE8N7YTqTnFpGQVMmPRNnZl5ANwaXs7PZravFyliNQWPh3UDHQdNREREfEtJpOJppFBNI0M4slRHXj/xzQ2p+Vx87ubGdHRzoWtorGaTfRuEamFR0TqMZ8NaoZhaOqjiIiI+LT+CVH0T4gir7iMV75P5Z1Nh/l4q8Pz+JOjOtA/IcqLFYqIt/huUDvxU9dRExEREV8XHujH7Re15Ooejdmclse87w6wL7OQh7/YRcPVgQxqHU3PZpF0iAvzdqkico74blA7kdQ0I0BERETqiujQAJJax5DUOob1qTm8uuYgqTnFPLcyBVam8MbV3fkxLY/OjcJoa1doE6nLfDiolSc1zd0WERGRuui8eBvnxdtIzyvmv+sP8/GWdK5+YwMAoQEW/nfNeTQMD/RylSJSU3z2gtdujaiJiIhIPRAXHsiMAa14/epujOvaiGv/FI9hwFUL1vP+j2kUl7l4bc1BDucWebtUEalGvjuiduKncpqIiIjUB80aBHPPwAQARneO42+f/8Q/lu3h+ZUp5BU7+XLXUR4f2Z6iMhcJ0SFaGVvEx/nsiJqmPoqIiEh91TgiiHnjO/Ov0R1oYgsCYPfRAi57+QcmvL6BV9ekYhgGX+7MYOuRPC9XKyJ/hM+OqGnqo4iIiNRnJpOJfq2i6NcqCrdh8PzKFBzHSygocfLCqhTe+zGNo/mlBPmZWX5LH/wsPvv9vEi95MNBrTypaVhfRERE6juzycSt/VoA4HQbzF2VwrH8EgpKXXy9J5OL535PnxYNmDGgFfszC0mMCSE0wGc/BorUCz7/DtUFr0VEREROsppPhjbDMHhj3SEWbUnn8x0ZLN2ZgcuA/q2ieHJ0By9XKiK/xWeDmkbURERERH6byWRiUs94JvWM58fDuSzZ7qDMZbB4m4MHP93J4DYxXNotyNtlikgVfDiolf9UTBMRERE5vS6NI+jSOAKn2yDYz8JHW8tH2WYs2kaP+AjuSkqgVXSIt8sUkRN8Nqj9vD6/pj6KiIiI/H5Ws4m7ByZwx0Ut+WxHBt8dyGHV3mNcuWA9bWJDaRMbQlGZG3tYADf2aUagn8XbJYvUSz4b1Nxo6qOIiIjIH2W1mBnRMY5JfVuSciSXhT+k8voPh9iVkY/ZVD57admuo/z14jb0aGrD5Taw6BtykXPGd4Oapj6KiIiIVAtbkB+3XdiSYe3t2MMCCLCa+cey3Xy81cHN726mXVwYe48VMHNQIhe3i1VgEzkHfDao4bngtZfrEBEREakjfnmO2v2DW/Pn3s14+fuDbD1ynBKnm4c+38VDn++iZ1MbV/dogskEPeJtukabSA3w2aB28oLXSmoiIiIi1c1iNhEXHsgDQ1oDcCCrkGnvbyEtr4QdjuNM/2ArAC0aBHPHgJYkRocQFeKvz2Yi1eR3BbXk5GRmz56N2+1m3LhxTJ06tcLjH3zwAY8//jh2ux2Aq6++mnHjxlV/tb/gWZ6/Rp9FRERERACaNQjm3et6YgBOt5tHv9xNXHggS3dlMO398tDWt2UDrukZT36Jkx5NbQRpIRKRP+y0Qc3lcvHwww/z6quvYrfbGTt2LElJSSQkJFTYbtiwYcyaNavGCj0Vs761ERERETkn/K3lUxwDMDP70nYATOndlKU7j3Iwp4gFa1NZuS/Ls31iTAi39GtBn+aRFDvd5Jc4iQkN8ErtIr7mtEFt8+bNNGvWjPj4eACGDx/O8uXLKwW1c+3k1EevliEiIiJSrwX5WRjZKQ6AIW1iSMkqpNTl5n/rD7P7aAG3f7CV9nFh7DtWgNsweOmqrrSzh3m5apHa77RnfjocDuLi4jy37XY7Doej0nZffvklI0aMYNq0aRw5cqR6q6yCZ+qjgpqIiIhIrdA6NpQhbWO5tEMc/7vmPJbf0pvzm0eyPf04LaNDsJhN3PLuFhZtPkJ6XrG3yxWp1aplMZEBAwZw6aWX4u/vz1tvvcW9997L66+//pv7WCwmbLbgP/ycue7yn6EhAWd1nLrIYjGrTX5FbVKZ2qRqapfK1CYi8keFB/rx9OgOZBeVER3iT1peMfd8tJ3ZS3djNsGIjnEMbB1N9yY2AqxmXatN5BdOG9Tsdjvp6eme2w6Hw7NoyM8iIyM9/x43bhxPPPHEaZ/Y5TLIySk8k1oryM0tAqCoqPSsjlMX2WzBapNfUZtUpjapmtqlsupok5gYTXMSqa+sFrPnvLTGEUG8fFVXfjycx9d7jvHB5iN8tCUdswnsYQE4jpcwvX9LLmkXS2Swv5crF/Gu0wa1Tp06kZKSQmpqKna7nSVLlvDUU09V2CYjI4PY2FgAVqxYQatWrWqm2l84ueqjvnURERER8RWBfhZ6NY+kV/NIbruwJSv3ZbIt/TiHc4oJ9LPw9Nf7ePabfcRHBnHVeU34avcxGkcEMrVPMxoovEk9ctqgZrVamTVrFlOmTMHlcjFmzBgSExOZM2cOHTt2ZODAgSxcuJAVK1ZgsViIiIjgscceq/HCT+Q0XfBaRERExEcF+1sY0jaWIW3Lv/A/klfMsl1HySkqY/lPx3hs6W4ArGYT3+7N5PaLWpFVUErnxuG0jAohwKoLbUvdZTKMnyPPuVVW5jqrqTT7Mgu44rX1PHppOwa3ianGynyfpm5VpjapTG1SNbVLZZr6eO6dbR8J+l2uitqkarW1XQpKnSxYm8qAxGjMmHhgyQ4OZBd5Ho8N9Wdqn2bscORzSbtYujSOqLbnrq1t4k1qk8pqun+slsVEvMGtETURERGROivE38rNfVt4br81+TwWb3NgNpnILS5j0ZZ0HvmyfMRt+U/HGNHBTv+EqAqBzTAMTFoiXHyUzwY1w3OOmoiIiIjUdVaLmdGdG3puj+nSiB2O44T6W3l8xR7e3HCYhesOcUm7WIa2iyWroJSXVh9g8p/iubxLIy9WLvLH+HBQK/+pb0lERERE6p9gfwvnxdsAePmqrhSVuXhtzUEWrjvEZzsyPNs9tmwPoQFWLmjZgNwiJ/awAF0CQHyCzwc1vc9EREREJMjPwk19W3BV9yZ8l5JF8t5MbEF+fLc/iweW7PRs1zIqGFuQH/0Toriqe2MMwKwv/qUW8tmg5ubnNVD0xhIRERGRcrZgP4a1tzOsffl1f/OKy/g+JZsNh3KJDQ1g6a6jZBWW8vTX+5i36gAmE1zTM55W0cG0ig6hiS3Iy69ApJzPBjWNqImIiIjI6YQH+lW4BMD15zfF6XLz6tpU9hwtoLDUxQurUjzbm4CBbWPp3dTGhQlR2IL8vFO41Hs+HNTKk5qGqkVERETkTFgtZv7cuxlQ/pnyx8N5ZBaWsmhLOt+nZLNsZwbLdmZgWWaiSUQgPZrayDhewsiOcVyUGM37P6bRvEGw5xw5kZrgs0HNrZmPIiIiInKWTCYTXZuUL+mflBhNsdNN8oEcIv3MrDmQw8ZDuSzZ5sDfambV/iyGtbezeJsDgPev70nTSE2VlJrhs0Ht55ymqY8iIiIiJHykYgAAHlFJREFUUh1MJhNBfhau6BFPTk4hf2oW6XmssNTFzMXbWbrrKACBVjPjX1tHy6hgujeJ4Oa+LQj2t3irdKmDfDeo/Tz1UUNqIiIiIlLDgv0tzLm8E27DwDAg/XgxH21JZ4cjn/c2pfH+j0doFBFIO3soPxzMweU2uKJ7Y88US5Ez5bNBTVMfRURERORcM5tMYILGEUHc3LcFABsO5bB6fzarU7JZsfsYZa7yD6rzvzvAqn1ZxIT60z8hioISFw0jAgnyMxNgtdAoPIDo0ABvvhypxXw2qBn8vJiIlwsRERERkXqtexMb3ZvYuLlvc05kNHKLyvjf+kNsOpzH9vTjfL0ns8p9+7SI5PLODemfEF3psQVrU3n/xzQWTfmTFtCrh3w3qHmW59cvrYg3uFxOsrOP4nSWeruUauVwmDxTq6XcmbSJ1epPZGQMFovPdi8iIn+YyWTCeuKjaVSIP7dd2BIAp9tg79ECwgKtvL3xMNuOHKdX80jeXH+Y7/Zn893+bCb1aEKA1UzfVlE0DA+gQbA///l2PwBbjxync6Nwb70s8RKf7UndJz40KKeJeEd29lECA4MJCYnDVIfeiBaLGZfL7e0yapXf2yaGYVBQkEd29lGioxueg8pERHyD1WyijT0UgDsuauW5f8J5jTEMmPb+FhauOwTAS98fxAQM62D3bPevr/bSJjaUm/o213Xd6hEfDmrlP006SU3EK5zO0joX0uTsmEwmQkLCyc/P8XYpIiI+IcS//KP4i1d25WB2Ef5WEz9lFPDt3ky+2nOMYD8LTWyBbEs/zrb04yTvzaR/QhRNI4MoLnPTr1UDGoYHEhrgsx/p5Tf47v+qZ+qjd8sQqc8U0uTX9DshInLmLGYTLaKCgfJFSgYkRjOLNkD5uW7PrdxP18YRJ85ZO+LZ74VVKUD5yFywn4WujSPo1iQCt2EQ6Gchu7CUyGD/c/56pHr4bFBz8/PUR30oEKmPcnNzmD79ZgCysjIxm83YbOXXu3nxxQX4+Z16asjOndv5/PMl3H773b/5HP/3f9czd+4r1VbznDlP8dVXy/jggyWYzeZqO66IiNRdEUF+3D+4NQDD2ttJzysmt8iJPTyAdzelsXhrOv9bf7jCPgFWM+3toWw8nMfYLg1JP17CjX2a0dYe5o2XIH+Q7wY1z9RHEamPIiJsvPba/wB4+eV5BAUFM2HCJM/jTqcTq7XqP3Ft27anbdv2p32O6gxpbreb5OSviI21s2nTBrp371Ftx/6l33rdIiLi++LCA4k7sa7In3s344bzm7I9/Ti2ID9+PJzHkbxikvdmsvFwHgDvnRiB23golzFdGhEWYKFDwzB6No2sdGzDMDQIUov4bm+uqY8i8iuzZz+Ev78/P/20i86duzBw4BDmzHmK0tISAgICuf/+WTRt2pwNG9bx1ltv8Pjjz/Dyy/NwONJJSzuMw+HgyisnMGbMFQAMHtyPpUu/ZcOGdbzyynxsNhv79u2lTZt2zJr1d0wmE6tXr+Tf/36awMAgOnfuQlraYR5//JlKtW3cuJ4WLVoycOAQli79whPUsrIyeeKJx0hLK/829K677qNTpy589tli3nrrDcBEQkICDz74d2bPfog+ffoyYMCgSvW99NJcwsLCOHDgAG+99QEzZ87A4XBQWlrKuHFXMmrU5QB8//13zJ//HC6XG5vNxtNPP8eECWN44YVXiIyMxO12c9VVlzN37qtERlbuxEVEpHYxm0x0bFie3JrYggC49k/x7DlWQMPwQH5MyyMi0Mob6w7x+g+pQPlAR58WDYgIspKUGM0FLaN4e8Nhlmx38OKVXTznzol3+ez/wslVH5XURLxtyTYHH29Nr9ZjjuwYx/BfrHj1ex09msHcua9gsVgoKMjnuedexGq18sMPa5g37zlmz36i0j4HDx7g2WfnUlhYyIQJYxg1akylUandu3excOE7REfHcNNNN7B584+0bduOJ554jP/8Zz6NGjXmr3+9/5R1LVv2BYMGDaVfv/7Mm/ecZ+TrmWeepFu37jz22JO4XC6KiorYt28vCxa8wty5r2Cz2cjLyz3t6/7pp528/vrbNGrUGICZM2cRHh5BSUkxU6Zcw0UXJeF2Gzz++GxPvXl5uZjNZoYMuYSlSz9j/PgJrFu3loSERIW03yk5OZnZs2fjdrsZN24cU6dOrXK7L774gmnTpvHee+/RqVOnc1yliNQ3VovZM83xwlZRAHRpHEFOURkY8NL3B/jhYA47HGV8uj2jwr7/XLaH6BB/9mcVYgJu6N2MDnFh7M7IJ8DtIjxQq06eKz4c1Mp/KqeJyC8NGDAIi8UCQH5+Po888hCHDh3EZDLhdDqr3Kd37wvw9/fH39+fyMhIsrIyiY2tGBLbtevguS8xsTXp6WkEBwfRqFFjTzgaPHgoH3/8YaXjl5WVsXr1Km677Q6Cg0No374ja9as5oIL+rFhww/85S9/A8BisRAaGsrnny9mwICB2Gw2AMLDI077utu16+CpA+Ddd98iOflrADIyHKSmppKTk02XLt082/183OHDRzJz5gzGj5/AkiUfMWzYyNM+n4DL5eLhhx/m1VdfxW63M3bsWJKSkkhISKiwXX5+Pq+//jpdunTxUqUiIuV+Xtr/rqTyv1NOl5vPd2ZwIKuIUpebghIXH/3qi9dv92URaDVT7HTTKjqYvi2jaBwRyKhOcWxIzaVdXKhG4GqID7dqeVIz6yw1Ea8b3sH+h0a/akJgYKDn3y+9NJfu3Xvw2GNPcuRIGrfddmOV+/j5nVwRy2Kx4HK5Km3j739yG7PZXOU2p7JmzWry849zzTVXAlBcXExAQAAXXNDvdx/j59rcJ76lcrvdlJWVeR4LCgry/HvDhnWsW7eWefNeJTAwkFtvnUppackpj2u3xxEZGcX69T+wfft2Zs165Izqqq82b95Ms2bNiI+PB2D48OEsX768UlCbM2cOf/7zn3n55Ze9UaaIyClZLWYu7RBX4b4xXcuvg9miQTAFpS4eWLKDiEA/DuYUs+doPnuPFQLwbPI+8ktchPhbmPyneC7r3BATsOlwLp9uz+CupFbEhAac65dUp/hsUNOImoicTn5+PjExMQB8+ukn1X78pk2bkZZ2mCNH0mjYsBHLly+tcrtly77g3nv/wuDBFwNQVFTEuHEjKS4u5rzzerJo0XuMHz/BM/Wxe/ee3H//3Vx55UQiIsqnPoaHRxAX15Bdu3YwcOBgVq5MPuUIYUFBPmFh4QQGBnLgQArbt28FoEOHTvzrX/8kLe2wZ+rjz6NqI0aM4uGHH2To0GGeEUn5bQ6Hg7i4kx9w7HY7mzdvrrDNtm3bSE9P56KLLlJQExGf0O4XK0MG+lmYO758NkBERBArtpYvTLIlLY+0vGLScotZcyCH51em8PzKlArH2Z9VyAODE/G3mjEMaBoZpOu9nSGfbS3Dc46alwsRkVpr4sRreOSRh1iw4GV69+5b7ccPCAjkzjvvZcaM2wgMDKJdu8orSRYXF7NmzWruvnum576goCA6d+7KqlXJTJ9+F48/PpvFiz/CbLZw11330bFjZyZPvp5bb52K2Wyhdes2PPDAQ4wceRn33TeDyZOvolev3hVG0X6pV68+LFr0ARMnjqVp02a0b98RgMjISO6++34eeOBu3G6DyMhInnnmeQD69u3Po48+zPDhmvZYXdxuN//4xz947LHHznhfi8WEzRZ8Vs9vsZjP+hh1jdqkamqXytQmlVksZgZ2agTg+fmzb3cfZdXeTP63NpXGtiD+3K8F936whSlv/VhhO3+rmTsGJjKgTQxOl0Fre6hPrzdR078nJuPnxHOOlZW5yMkp/MP7L//pKPd9soM3J59HQnRINVbm+2y24LNq27pIbVLZ2bZJevoB4uKaVWNFtYPFYsblcv/u7QsLCwkODsYwDJ566p/Ex8dzxRUTa7DCmrFz53aeffZfPP/8S5UeO9M2qep3Iyam7l27Z+PGjfznP//xjJTNmzcPgBtvLJ9ie/z4cQYNGkRISHkfdfToUSIiInjhhRdOu6DI2faRoL97VVGbVE3tUpnapLLf0ybHi50E+pnxs5hZk5LNa2sPsi41l5hQf3KKyihzVY4dTSODGNHBToMQf7o2jqBpZNVfQtZG1fF78lv9o8+OqLm1PL+I1AKffPIhn322BKezjMTENowaNcbbJZ2xhQtfY9Gi93Ru2hnq1KkTKSkppKamYrfbWbJkCU899ZTn8bCwMNasWeO5PWnSJO655x6t+igidVZY4Mlo0at5JL2aR5KeV0xMaABH80uIDPbnQFYhGw/lkn68hDfWHeJgdhHP/WLaZFSIPw2C/YgO8afY6eaGXk3p0DAMq9lEoF/9mprvs0HNM/VRi4mIiBddccVEnxxB+6VJk65l0qRrvV2Gz7FarcyaNYspU6bgcrkYM2YMiYmJzJkzh44dOzJw4EBvlygi4nVx4YEVfraODaV1bCgAV3RrRGxYABnHSygodbHuYA6b0/LYlZHPoZwiSpxubn1/CwDhgVZ6N4/E32KmW5MIGoYH0tYeSpCfhc1peRSWuih1uRmQGO2dF1oDfDiolf/04WmtIiLi4/r370///v0r3Dd9+vQqt124cOG5KElExGf8OsS1ig7hiu4nLzVT4nTz9e5j7M0s4IeDOXyx8ygBVjOfbHMA5eEt0GomI7/Us8/Tl3XgghYNfPrct5/5bFBz/7w8fx34TxARERERkYoCrGaGtosFwG0YHMwqommDIPYeKyAjv5SPt6RT6nJzWecwvtmTyb7MAu74cBtRIf4Uljpp3iAYf4uZ0AAr0/u35Gh+CWaTibb2UHKKymhiq93nw/lsUDN0jpqIiIiISL1gNploHlW+wmJiTCiJMXBBiwaex6f0bkaJ082XOzNYcyAbl9vgUE4xP6blAbBqf9avjgd3JyUQHeLP/qxC/CxmxndthL/V7NmmoNRJkJ/FawNDPhvU3N5ZrFJERERERGqhAKuZER3jGNHx5DUuc4vKKHO5+WxHBiEBVpL3ZPLd/iysZhP/XL6nwv4fbj5C9yYRWMwm2saG8p9v99MmNpQbejeldUzoOb8OnM8GtZMjahpSE6mPbrvtRq6++lp69ertue+dd/7HwYMHuOuumVXuc+utU7n11ttp27Y9d901jb/+dTZhYRWXxX3ppbkEBAQxYcKkUz53cvLXxMc3pUWLlp59unTpRs+evarhlcGcOU/x1VfL+OCDJZjN5tPvICIiIlWKCPIDYFLPeAAu79wQwzAocbp5/8cjhAVYGdgmmvWpuby2JpWPt6bjZzHz/o/lF/deezCHtQdzaBQeQLd4G4WlLhqFB9I6NoRBnRriX4O1+3xQU04TqZ8GDRrK8uVfVghqy5Z9yc03T/td+z/55LN/+Lm//fZr+vTp6wlqU6b83x8+1q+53W6Sk78iNtbOpk0b6N69R7Ud+5ecTidWq892ASIiIn+YyVS+1P/EHk08913YKooLW0XhchsYwLqD2ZS6DOxhAaRmF/H48j0s2eYgMsiPr4qOARAQ6MfAlg1O8Sxnz2d76T81s3HDBc2xhwV4uxQR8YIBAwby4osvUFZWhp+fH0eOpHHs2FG6dOnGk08+xo4d2ykpKWHAgIHccMONlfYfO3YEL720EJvNxoIFL/PZZ0uIjIwkLi6OxMS2AHz88Yd8/PGHlJWV0aRJEx588O/s3r2LlSuT2bRpAwsWvMLs2Y/z2msv0adPXwYMGMS6dWt57rlncLlcJ0buZuLv78/YsSO45JJLWbUqGafTyd///k+aNWteqa6NG9fTokVLBg4cwtKlX3iCWlZWJk888RhpaYcBuOuu++jUqQuffbaYt956AzCRkJDAgw/+ndmzH/LUAzB4cD+WLv2WDRvW8dJLcwkLC+PAgQO89dYHzJw5A4fDQWlpKePGXcmoUZcD8P333zF//nO4XG5sNhtPP/0cEyaM4YUXXiEyMhK3281VV13O3LmvEhkZWQP/wyIiIuee5cQCGOc3PxnA2sSGclFCFAWlLiKC/PhiRwaHcou4rGtj8vKKaqwWnw1qceGB3HdxW101XqQWCNj5HoE73qrWYxa3u5KStmNP+Xh4eATt23fg++9X0a/fRSxb9iVJSYMxmUxMnXoz4eERuFwupk+/iT17dpOQkFjlcXbu3MHy5V/y2mv/w+Vycv31V3uCWv/+Axg58jIA5s9/nsWLFzF27JX07XthhSD0s5KSEh599G8888zzNG3ajL//fRaLFr3H+PETAIiIiOCVV/7LBx+8y5tvLuS++x6sVM+yZV8waNBQ+vXrz7x5z3lGvp555km6devOY489icvloqioiH379rJgwSvMnfsKNpuNvLzc07brTz/t5PXX36ZRo/Llj2fOnEV4eAQlJcVMmXINF12UhNtt8Pjjs/nPf+bTqFFj8vOPYzabGTLkEpYu/Yzx4yewbt1aEhISFdJERKResFrMRASVn47w80qU5hpe1VAnP4iIzxo0aCjLln0JwPLlXzJo0FAAVqxYyvXXT+T66yeSkrKPlJR9pzzG5s0bufDCAQQGBhISEkq/fievibVv315uvnkK11xzBUuXfs7+/ac+DsDBgwdo2LARTZs2A+CSSy5l06aNnsf7908CoE2bdhw5cqTS/mVlZaxevYoLL7yIkJBQ2rfvyJo1qwHYsOEHRo8uD64Wi4XQ0FA2bPiBAQMGYrPZgPLwejrt2nXwhDSAd999i8mTr2Lq1OvIyHCQmprKtm1b6NKlm2e7iIjy4w4fPpLPP18CwJIlHzFs2MjTPp+IiIj8MT47oiYitUdJ27G/OfpVU/r27c+zz/6LXbt2UlxcTNu27UhLO8ybb77Biy++Tnh4OLNnP0RpaenpD1aFRx/9G48++iSJia359NNP2Lhx/VnV6+dXfsqxxWLG5XJWenzNmtXk5x/nmmuuBKC4uJiAgAAuuKDfGT2PxWLB7S4/kdftdlNWVuZ5LCjo5DVjNmxYx7p1a5k371UCAwO59daplJaWnPK4dnsckZFRrF//A9u3b2fWrEfOqC4RERH5/TSiJiI+Kzg4mO7de/DYYw8zeHD5aFpBQQGBgUGEhoaSlZXJ999/95vH6NKlO99++zUlJcUUFhawcmWy57HCwgKio6NxOp18+eVnFZ63sLDytOumTZtx5Egahw6lAvDFF5/StWv33/16li37gnvv/QvvvfcJ7733Ce+++zE//LCG4uJizjuvJ4sWvQeAy+UiPz+f7t178tVXy8nNzQHwTH2Mi2vIrl07AFi5svycuKoUFOQTFhZOYGAgBw6ksH37VgA6dOjEjz9u9JwPl5t7ckrliBGjePjhBxkwYCAWi+V3vzYRERE5MwpqIuLTBg0ayp49P3mmPSYmtqZ16zZMmDCWv/3tL3Tq1OU392/Tpi1JSYOZPHkCM2ZMo127Dp7Hpky5ialTr+Wmm66vsPDHwIFDePPNhVx33QQOHz7kuT8gIID77/8rDz54L9dccwUmk4nRo8f8rtdRXFzMmjWr6dOnr+e+oKAgOnfuyqpVyUyffhcbNqzjmmuu4IYbJpGSso+WLVsxefL13HrrVCZPvop///tpAEaOvIxNmzYwefJVbN26ucIo2i/16tUHl8vFxIljmTv337Rv3xGAyMhI7r77fh544G4mT76KBx+8z7NP3779KSoqYvhwTXsUERGpSSbD8M6Vo8vKXGe9EIjNFqzFRKqgdqlMbVLZ2bZJevoB4uKaVWNFtUP5tES3t8uoVX7ZJjt3bufZZ//F88+/dMrtq/rdiIkJO8XWUhX1kTVDbVI1tUtlapPK1CaVVUeb/Fb/qHPURETkd1m48DUWLXpP56aJiIicAwpqIiLyu0yadC2TJl3r7TJERETqBZ2jJiIiIiIiUssoqInIH+alU1ylFtPvhIiISPVQUBORP8Rq9aegIE8fzMXDMAwKCvKwWv29XYqIiIjP0zlqIvKHREbGkJ19lPz8HG+XUq1MJpPC56+cSZtYrf5ERsbUcEUiIiJ1n4KaiPwhFouV6OiG3i6j2mn54crUJiIiIueepj6KiIiIiIjUMgpqIiIiIiIitYyCmoiIiIiISC1jMnTWvIiIiIiISK2iETUREREREZFaRkFNRERERESkllFQExERERERqWUU1ERERERERGoZBTUREREREZFaRkFNRERERESklvHZoJacnMzQoUMZPHgw8+fP93Y558zMmTPp3bs3l156qee+nJwcrrvuOoYMGcJ1111Hbm4uAIZh8MgjjzB48GBGjBjBtm3bvFV2jTpy5AiTJk1i2LBhDB8+nAULFgBql5KSEsaOHcvIkSMZPnw4zz77LACpqamMGzeOwYMHc/vtt1NaWgpAaWkpt99+O4MHD2bcuHEcOnTIm+XXKJfLxejRo7nxxhsBtUlSUhIjRoxg1KhRXH755YDeP76svvaPoD6yKuojK1P/eGrqHyvzah9p+CCn02kMHDjQOHjwoFFSUmKMGDHC2L17t7fLOifWrl1rbN261Rg+fLjnvn/+85/GvHnzDMMwjHnz5hmPP/64YRiG8fXXXxs33HCD4Xa7jY0bNxpjx471Ss01zeFwGFu3bjUMwzCOHz9uDBkyxNi9e3e9bxe3223k5+cbhmEYpaWlxtixY42NGzca06ZNMxYvXmwYhmE8+OCDxn//+1/DMAzjjTfeMB588EHDMAxj8eLFxvTp071T+DnwyiuvGHfeeacxdepUwzCMet8mAwYMMDIzMyvcV9/fP76qPvePhqE+sirqIytT/3hq6h8r82Yf6ZMjaps3b6ZZs2bEx8fj7+/P8OHDWb58ubfLOid69uxJREREhfuWL1/O6NGjARg9ejTLli2rcL/JZKJr167k5eWRkZFxzmuuabGxsXTo0AGA0NBQWrZsicPhqPftYjKZCAkJAcDpdOJ0OjGZTHz//fcMHToUgMsuu8zz3lmxYgWXXXYZAEOHDmX16tUYhuGd4mtQeno6X3/9NWPHjgXKv/2q721Slfr+/vFV9bl/BPWRVVEfWZn6x6qpf/z9ztX7xyeDmsPhIC4uznPbbrfjcDi8WJF3ZWZmEhsbC0BMTAyZmZlA5XaKi4ur8+106NAhduzYQZcuXdQulE9hGDVqFH369KFPnz7Ex8cTHh6O1WoFKr52h8NBw4YNAbBarYSFhZGdne212mvKo48+yt13343ZXP7nLzs7u963CcANN9zA5Zdfzttvvw3o74qvUv9YmX6XT1IfeZL6x8rUP56at/pI61nULLWQyWTCZDJ5uwyvKCgoYNq0adx///2EhoZWeKy+tovFYuGjjz4iLy+PW265hX379nm7JK/66quvaNCgAR07dmTNmjXeLqfWePPNN7Hb7WRmZnLdddfRsmXLCo/X1/eP1D31+XdZfWRF6h8rUv94at7sI30yqNntdtLT0z23HQ4HdrvdixV5V1RUFBkZGcTGxpKRkUGDBg2Ayu2Unp5eZ9uprKyMadOmMWLECIYMGQKoXX4pPDycXr16sWnTJvLy8nA6nVit1gqv3W63c+TIEeLi4nA6nRw/fpzIyEgvV169NmzYwIoVK0hOTqakpIT8/Hxmz55dr9sE8LzeqKgoBg8ezObNm/X+8VHqHyvT77L6yN+i/rGc+sdT82Yf6ZNTHzt16kRKSgqpqamUlpayZMkSkpKSvF2W1yQlJbFo0SIAFi1axMCBAyvcbxgGmzZtIiwszDNMW5cYhsEDDzxAy5Ytue666zz31/d2ycrKIi8vD4Di4mK+++47WrVqRa9evfjiiy8A+PDDDz3vnaSkJD788EMAvvjiC84///w69w3rjBkzSE5OZsWKFfzrX//i/PPP56mnnqrXbVJYWEh+fr7n36tWrSIxMbHev398lfrHyur777L6yMrUP1am/rFq3u4jTYaPnvn3zTff8Oijj+JyuRgzZgw33XSTt0s6J+68807Wrl1LdnY2UVFR3HbbbQwaNIjbb7+dI0eO0KhRI5555hlsNhuGYfDwww/z7bffEhQUxKOPPkqnTp28/RKq3bp165g4cSKtW7f2zKu+88476dy5c71ul507d3LffffhcrkwDIOLL76YW2+9ldTUVO644w5yc3Np164dTz75JP7+/pSUlHD33XezY8cOIiIiePrpp4mPj/f2y6gxa9as4ZVXXmHevHn1uk1SU1O55ZZbgPJzNi699FJuuukmsrOz6/X7x5fV1/4R1EdWRX1kZeoff5v6x5O83Uf6bFATERERERGpq3xy6qOIiIiIiEhdpqAmIiIiIiJSyyioiYiIiIiI1DIKaiIiIiIiIrWMgpqIiIiIiEgto6AmIiIiIiJSyyioiYiIiIiI1DIKaiIiIiIiIrXM/wMcom9MGcJ6HAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 1080x1080 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t0Yb4WeyTK9W",
        "outputId": "04742666-d172-4bf5-eed0-b710bd768891"
      },
      "source": [
        "predictions = model.predict_classes(x_val)\r\n",
        "predictions = predictions.reshape(1,-1)[0]\r\n",
        "print(classification_report(y_val, predictions, target_names = ['1.Cancer (Class 0)','2.Precancer (Class 1)','3.Inflammatory (Class 2)','4.Normal (Class 3)']))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                          precision    recall  f1-score   support\n",
            "\n",
            "      1.Cancer (Class 0)       0.63      0.65      0.64        82\n",
            "   2.Precancer (Class 1)       0.13      0.07      0.09        30\n",
            "3.Inflammatory (Class 2)       0.59      0.36      0.45        53\n",
            "      4.Normal (Class 3)       0.82      0.95      0.88       227\n",
            "\n",
            "                accuracy                           0.74       392\n",
            "               macro avg       0.55      0.50      0.51       392\n",
            "            weighted avg       0.70      0.74      0.71       392\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49jpStyaTB4U"
      },
      "source": [
        "ㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yD-54Wk7TKxq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o13OUa7HTKwJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWgpskUmTA5E"
      },
      "source": [
        "        \r\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1B8uuKoeAwb-",
        "outputId": "f1ea745b-b77f-401d-f553-4cc60581ebc4"
      },
      "source": [
        "model = Sequential()\r\n",
        "\r\n",
        "model.add(Conv2D(64,3,padding=\"same\", activation=\"relu\", input_shape=(224,224,3)))\r\n",
        "model.add(Conv2D(64,3,padding=\"same\", activation=\"relu\", input_shape=(224,224,3)))\r\n",
        "model.add(MaxPool2D())\r\n",
        "\r\n",
        "\r\n",
        "model.add(Conv2D(128,3,padding=\"same\", activation=\"relu\", input_shape=(224,224,3)))\r\n",
        "model.add(Conv2D(128,3,padding=\"same\", activation=\"relu\", input_shape=(224,224,3)))\r\n",
        "model.add(MaxPool2D())\r\n",
        "\r\n",
        "\r\n",
        "model.add(Conv2D(256,3,padding=\"same\", activation=\"relu\", input_shape=(224,224,3)))\r\n",
        "model.add(Conv2D(256,3,padding=\"same\", activation=\"relu\", input_shape=(224,224,3)))\r\n",
        "model.add(Conv2D(256,3,padding=\"same\", activation=\"relu\", input_shape=(224,224,3)))\r\n",
        "model.add(MaxPool2D())\r\n",
        "\r\n",
        "\r\n",
        "model.add(Conv2D(512,3,padding=\"same\", activation=\"relu\", input_shape=(224,224,3)))\r\n",
        "model.add(Conv2D(512,3,padding=\"same\", activation=\"relu\", input_shape=(224,224,3)))\r\n",
        "model.add(Conv2D(512,3,padding=\"same\", activation=\"relu\", input_shape=(224,224,3)))\r\n",
        "model.add(MaxPool2D())\r\n",
        "\r\n",
        "\r\n",
        "model.add(Conv2D(512,3,padding=\"same\", activation=\"relu\", input_shape=(224,224,3)))\r\n",
        "model.add(Conv2D(512,3,padding=\"same\", activation=\"relu\", input_shape=(224,224,3)))\r\n",
        "model.add(Conv2D(512,3,padding=\"same\", activation=\"relu\", input_shape=(224,224,3)))\r\n",
        "model.add(MaxPool2D())\r\n",
        "\r\n",
        "model.add(Flatten()) \r\n",
        "model.add(Dense(128,activation=\"relu\"))\r\n",
        "model.add(Dense(64,activation=\"relu\"))\r\n",
        "model.add(Dense(4,activation=\"softmax\"))\r\n",
        "\r\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_17 (Conv2D)           (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "conv2d_18 (Conv2D)           (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_19 (Conv2D)           (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "conv2d_20 (Conv2D)           (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_21 (Conv2D)           (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "conv2d_22 (Conv2D)           (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "conv2d_23 (Conv2D)           (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_24 (Conv2D)           (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "conv2d_25 (Conv2D)           (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "conv2d_26 (Conv2D)           (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_27 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "conv2d_28 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "conv2d_29 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               3211392   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 4)                 260       \n",
            "=================================================================\n",
            "Total params: 17,934,596\n",
            "Trainable params: 17,934,596\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ut2HqGjkCCak"
      },
      "source": [
        "opt = Adam(lr=0.001)\r\n",
        "model.compile(optimizer = opt , loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True) , metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "LT3JQiiZCFKZ",
        "outputId": "ff2bfcae-3181-4ed7-e59d-79560345585e"
      },
      "source": [
        "history = model.fit(x_train,y_train,epochs = 100 , validation_data = (x_val, y_val))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "74/74 [==============================] - 33s 438ms/step - loss: 1.2263 - accuracy: 0.5687 - val_loss: 1.1656 - val_accuracy: 0.5421\n",
            "Epoch 2/100\n",
            "74/74 [==============================] - 32s 428ms/step - loss: 1.1277 - accuracy: 0.5692 - val_loss: 1.1620 - val_accuracy: 0.5421\n",
            "Epoch 3/100\n",
            "74/74 [==============================] - 31s 422ms/step - loss: 1.0996 - accuracy: 0.5885 - val_loss: 1.1624 - val_accuracy: 0.5421\n",
            "Epoch 4/100\n",
            "74/74 [==============================] - 32s 438ms/step - loss: 1.1392 - accuracy: 0.5576 - val_loss: 1.1588 - val_accuracy: 0.5421\n",
            "Epoch 5/100\n",
            "74/74 [==============================] - 31s 425ms/step - loss: 1.1058 - accuracy: 0.5913 - val_loss: 1.1594 - val_accuracy: 0.5421\n",
            "Epoch 6/100\n",
            "74/74 [==============================] - 31s 424ms/step - loss: 1.1137 - accuracy: 0.5791 - val_loss: 1.1605 - val_accuracy: 0.5421\n",
            "Epoch 7/100\n",
            "74/74 [==============================] - 31s 424ms/step - loss: 1.1252 - accuracy: 0.5710 - val_loss: 1.1608 - val_accuracy: 0.5421\n",
            "Epoch 8/100\n",
            "74/74 [==============================] - 31s 425ms/step - loss: 1.1144 - accuracy: 0.5818 - val_loss: 1.1605 - val_accuracy: 0.5421\n",
            "Epoch 9/100\n",
            "74/74 [==============================] - 31s 425ms/step - loss: 1.1217 - accuracy: 0.5793 - val_loss: 1.1593 - val_accuracy: 0.5421\n",
            "Epoch 10/100\n",
            "74/74 [==============================] - 31s 426ms/step - loss: 1.0891 - accuracy: 0.5993 - val_loss: 1.1643 - val_accuracy: 0.5421\n",
            "Epoch 11/100\n",
            "74/74 [==============================] - 31s 425ms/step - loss: 1.1446 - accuracy: 0.5589 - val_loss: 1.1600 - val_accuracy: 0.5421\n",
            "Epoch 12/100\n",
            "74/74 [==============================] - 31s 423ms/step - loss: 1.1284 - accuracy: 0.5766 - val_loss: 1.1624 - val_accuracy: 0.5421\n",
            "Epoch 13/100\n",
            "74/74 [==============================] - 31s 424ms/step - loss: 1.1217 - accuracy: 0.5661 - val_loss: 1.1671 - val_accuracy: 0.5421\n",
            "Epoch 14/100\n",
            "74/74 [==============================] - 31s 423ms/step - loss: 1.1052 - accuracy: 0.5851 - val_loss: 1.1576 - val_accuracy: 0.5421\n",
            "Epoch 15/100\n",
            "74/74 [==============================] - 31s 424ms/step - loss: 1.1292 - accuracy: 0.5619 - val_loss: 1.1629 - val_accuracy: 0.5421\n",
            "Epoch 16/100\n",
            "74/74 [==============================] - 31s 423ms/step - loss: 1.1039 - accuracy: 0.5901 - val_loss: 1.1620 - val_accuracy: 0.5421\n",
            "Epoch 17/100\n",
            "74/74 [==============================] - 31s 423ms/step - loss: 1.0996 - accuracy: 0.5930 - val_loss: 1.1575 - val_accuracy: 0.5421\n",
            "Epoch 18/100\n",
            "74/74 [==============================] - 31s 424ms/step - loss: 1.1236 - accuracy: 0.5762 - val_loss: 1.1588 - val_accuracy: 0.5421\n",
            "Epoch 19/100\n",
            "74/74 [==============================] - 31s 424ms/step - loss: 1.1073 - accuracy: 0.5786 - val_loss: 1.1663 - val_accuracy: 0.5421\n",
            "Epoch 20/100\n",
            "74/74 [==============================] - 31s 424ms/step - loss: 1.1364 - accuracy: 0.5631 - val_loss: 1.1587 - val_accuracy: 0.5421\n",
            "Epoch 21/100\n",
            "36/74 [=============>................] - ETA: 14s - loss: 1.1404 - accuracy: 0.5626"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-b43bb60f745c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1103\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1105\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1106\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    452\u001b[0m     \"\"\"\n\u001b[1;32m    453\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    294\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unrecognized hook: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    314\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    354\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_supports_tf_logs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Only convert once.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1020\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1021\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1082\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1084\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1085\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1086\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    512\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 514\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    508\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    511\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1069\u001b[0m     \"\"\"\n\u001b[1;32m   1070\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1071\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1072\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1035\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHRJ8LZiCGh8"
      },
      "source": [
        "acc = history.history['accuracy']\r\n",
        "val_acc = history.history['val_accuracy']\r\n",
        "loss = history.history['loss']\r\n",
        "val_loss = history.history['val_loss']\r\n",
        "\r\n",
        "epochs_range = range(500)\r\n",
        "\r\n",
        "plt.figure(figsize=(15, 15))\r\n",
        "plt.subplot(2, 2, 1)\r\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\r\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\r\n",
        "plt.legend(loc='lower right')\r\n",
        "plt.title('Training and Validation Accuracy')\r\n",
        "\r\n",
        "plt.subplot(2, 2, 2)\r\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\r\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\r\n",
        "plt.legend(loc='upper right')\r\n",
        "plt.title('Training and Validation Loss')\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-d20SbICGuk"
      },
      "source": [
        "predictions = model.predict_classes(x_val)\r\n",
        "predictions = predictions.reshape(1,-1)[0]\r\n",
        "print(classification_report(y_val, predictions, target_names = ['Rugby (Class 0)','Soccer (Class 1)']))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}