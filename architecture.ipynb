{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "architecture.ipynb",
      "private_outputs": true,
      "provenance": [],
      "mount_file_id": "11tyBiw318XU8Y7xMZNVyoU4XNg5KVsrT",
      "authorship_tag": "ABX9TyPaf0fIJ8bbXg8Owhju+2l8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seunghyeon2776/98/blob/master/architecture.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euGUVKps67kU"
      },
      "source": [
        "pip install dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MrbDlS617AH8"
      },
      "source": [
        "import os\r\n",
        "import glob\r\n",
        "import numpy as np\r\n",
        "import cv2\r\n",
        "from sklearn.utils import shuffle\r\n",
        "\r\n",
        "def load_train(train_path, image_size, classes):\r\n",
        "    images = []\r\n",
        "    labels = []\r\n",
        "    ids = []\r\n",
        "    cls = []\r\n",
        "\r\n",
        "    print('Reading training images')\r\n",
        "    for fld in classes:\r\n",
        "        index = classes.index(fld)\r\n",
        "        print('Loading {} files (Index: {})'.format(fld, index))\r\n",
        "        path = os.path.join(train_path, fld, '*g')\r\n",
        "        files = glob.glob(path)\r\n",
        "        for fl in files:\r\n",
        "            image = cv2.imread(fl)\r\n",
        "            image = cv2.resize(image, (image_size, image_size), cv2.INTER_LINEAR)\r\n",
        "            images.append(image)\r\n",
        "            label = np.zeros(len(classes))\r\n",
        "            label[index] = 1.0\r\n",
        "            labels.append(label)\r\n",
        "            flbase = os.path.basename(fl)\r\n",
        "            ids.append(flbase)\r\n",
        "            cls.append(fld)\r\n",
        "    images = np.array(images)\r\n",
        "    labels = np.array(labels)\r\n",
        "    ids = np.array(ids)\r\n",
        "    cls = np.array(cls)\r\n",
        "  \r\n",
        "\r\n",
        "    return images, labels, ids, cls\r\n",
        "\r\n",
        "\r\n",
        "def load_test(test_path, image_size):\r\n",
        "    path = os.path.join(test_path, '*g')\r\n",
        "    files = sorted(glob.glob(path))\r\n",
        "\r\n",
        "    X_test = []\r\n",
        "    X_test_id = []\r\n",
        "    print(\"Reading test images\")\r\n",
        "    for fl in files:\r\n",
        "        \r\n",
        "        img = cv2.imread(fl)\r\n",
        "        img = cv2.resize(img, (image_size, image_size), cv2.INTER_LINEAR)\r\n",
        "        X_test.append(img)\r\n",
        "        X_test_id.append(flbase)\r\n",
        "        flbase = os.path.basename(fl)\r\n",
        "\r\n",
        "    X_test = np.array(X_test, dtype=np.uint8)\r\n",
        "    X_test = X_test.astype('float32')\r\n",
        "    X_test = X_test / 255\r\n",
        "    X_test_id = np.array(X_test_id)\r\n",
        "\r\n",
        "    return X_test, X_test_id\r\n",
        "\r\n",
        "\r\n",
        "class DataSet(object):\r\n",
        "\r\n",
        "    def __init__(self, images, labels, ids, cls):\r\n",
        "        \"\"\"Construct a DataSet. one_hot arg is used only if fake_data is true.\"\"\"\r\n",
        "\r\n",
        "        self._num_examples = images.shape[0]\r\n",
        "\r\n",
        "        # Convert shape from [num examples, rows, columns, depth]\r\n",
        "        # to [num examples, rows*columns] (assuming depth == 1)\r\n",
        "        # Convert from [0, 255] -> [0.0, 1.0].\r\n",
        "\r\n",
        "        images = images.astype(np.float32)\r\n",
        "        images = np.multiply(images, 1.0 / 255.0)\r\n",
        "\r\n",
        "        self._images = images\r\n",
        "        self._labels = labels\r\n",
        "        self._ids = ids\r\n",
        "        self._cls = cls\r\n",
        "        self._epochs_completed = 0\r\n",
        "        self._index_in_epoch = 0\r\n",
        "\r\n",
        "    @property\r\n",
        "    def images(self):\r\n",
        "        return self._images\r\n",
        "\r\n",
        "    @property\r\n",
        "    def labels(self):\r\n",
        "        return self._labels\r\n",
        "\r\n",
        "    @property\r\n",
        "    def ids(self):\r\n",
        "        return self._ids\r\n",
        "\r\n",
        "    @property\r\n",
        "    def cls(self):\r\n",
        "        return self._cls\r\n",
        "\r\n",
        "    @property\r\n",
        "    def num_examples(self):\r\n",
        "        return self._num_examples\r\n",
        "\r\n",
        "    @property\r\n",
        "    def epochs_completed(self):\r\n",
        "        return self._epochs_completed\r\n",
        "\r\n",
        "    def next_batch(self, batch_size):\r\n",
        "        \"\"\"Return the next `batch_size` examples from this data set.\"\"\"\r\n",
        "        start = self._index_in_epoch\r\n",
        "        self._index_in_epoch += batch_size\r\n",
        "\r\n",
        "        if self._index_in_epoch > self._num_examples:\r\n",
        "            # Finished epoch\r\n",
        "            self._epochs_completed += 1\r\n",
        "\r\n",
        "            # # Shuffle the data (maybe)\r\n",
        "            # perm = np.arange(self._num_examples)\r\n",
        "            # np.random.shuffle(perm)\r\n",
        "            # self._images = self._images[perm]\r\n",
        "            # self._labels = self._labels[perm]\r\n",
        "            # Start next epoch\r\n",
        "\r\n",
        "            start = 0\r\n",
        "            self._index_in_epoch = batch_size\r\n",
        "            assert batch_size <= self._num_examples\r\n",
        "        end = self._index_in_epoch\r\n",
        "\r\n",
        "        return self._images[start:end], self._labels[start:end], self._ids[start:end], self._cls[start:end]\r\n",
        "\r\n",
        "\r\n",
        "def read_train_sets(train_path, image_size, classes, validation_size=0):\r\n",
        "    class DataSets(object):\r\n",
        "        pass\r\n",
        "\r\n",
        "    data_sets = DataSets()\r\n",
        "\r\n",
        "    images, labels, ids, cls = load_train(train_path, image_size, classes)\r\n",
        "    images, labels, ids, cls = shuffle(images, labels, ids, cls)  # shuffle the data\r\n",
        "\r\n",
        "    if isinstance(validation_size, float):\r\n",
        "        validation_size = int(validation_size * images.shape[0])\r\n",
        "\r\n",
        "    train_images = images\r\n",
        "    train_labels = labels\r\n",
        "    train_ids = ids\r\n",
        "    train_cls = cls\r\n",
        "\r\n",
        "    data_sets.train = DataSet(train_images, train_labels, train_ids, train_cls)\r\n",
        "\r\n",
        "    return data_sets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekCkn1vC7ATm"
      },
      "source": [
        "def load_validation(validation_path, image_size, classes):\r\n",
        "    images2 = []\r\n",
        "    labels2 = []\r\n",
        "    ids2 = []\r\n",
        "    cls2 = []\r\n",
        "\r\n",
        "    print('Reading validation images')\r\n",
        "    for fld in classes:\r\n",
        "        index = classes.index(fld)\r\n",
        "        print('Loading {} files (Index: {})'.format(fld, index))\r\n",
        "        path = os.path.join(validation_path, fld, '*g')\r\n",
        "        files = glob.glob(path)\r\n",
        "        for fl in files:\r\n",
        "            image = cv2.imread(fl)\r\n",
        "            image = cv2.resize(image, (image_size, image_size), cv2.INTER_LINEAR)\r\n",
        "            images2.append(image)\r\n",
        "            label = np.zeros(len(classes))\r\n",
        "            label[index] = 1.0\r\n",
        "            labels2.append(label)\r\n",
        "            flbase = os.path.basename(fl)\r\n",
        "            ids2.append(flbase)\r\n",
        "            cls2.append(fld)\r\n",
        "    images2 = np.array(images2)\r\n",
        "    labels2 = np.array(labels2)\r\n",
        "    ids2 = np.array(ids2)\r\n",
        "    cls2 = np.array(cls2)\r\n",
        "  \r\n",
        "\r\n",
        "    return images2, labels2, ids2, cls2\r\n",
        "\r\n",
        "\r\n",
        "def read_validation_sets(validation_path, image_size, classes, validation_size=0):\r\n",
        "    class DataSets(object):\r\n",
        "        pass\r\n",
        "\r\n",
        "    data_sets = DataSets()\r\n",
        "\r\n",
        "    images2, labels2, ids2, cls2 = load_validation(validation_path, image_size, classes)\r\n",
        "    images2, labels2, ids2, cls2 = shuffle(images2, labels2, ids2, cls2)  # shuffle the data\r\n",
        "\r\n",
        "    if isinstance(validation_size, float):\r\n",
        "        validation_size = int(validation_size * images2.shape[0])\r\n",
        "\r\n",
        "    validation_images = images2\r\n",
        "    validation_labels = labels2\r\n",
        "    validation_ids = ids2\r\n",
        "    validation_cls = cls2\r\n",
        "\r\n",
        "    data_sets.valid = DataSet(validation_images, validation_labels, validation_ids, validation_cls)\r\n",
        "\r\n",
        "    return data_sets\r\n",
        "\r\n",
        "def load_test(test_path, image_size, classes):\r\n",
        "    images3 = []\r\n",
        "    labels3 = []\r\n",
        "    ids3 = []\r\n",
        "    cls3 = []\r\n",
        "\r\n",
        "    print('Reading validation images')\r\n",
        "    for fld in classes:\r\n",
        "        index = classes.index(fld)\r\n",
        "        print('Loading {} files (Index: {})'.format(fld, index))\r\n",
        "        path = os.path.join(test_path, fld, '*g')\r\n",
        "        files = glob.glob(path)\r\n",
        "        for fl in files:\r\n",
        "            image = cv2.imread(fl)\r\n",
        "            image = cv2.resize(image, (image_size, image_size), cv2.INTER_LINEAR)\r\n",
        "            images3.append(image)\r\n",
        "            label = np.zeros(len(classes))\r\n",
        "            label[index] = 1.0\r\n",
        "            labels3.append(label)\r\n",
        "            flbase = os.path.basename(fl)\r\n",
        "            ids3.append(flbase)\r\n",
        "            cls3.append(fld)\r\n",
        "    images3 = np.array(images3)\r\n",
        "    labels3 = np.array(labels3)\r\n",
        "    ids3 = np.array(ids3)\r\n",
        "    cls3 = np.array(cls3)\r\n",
        "  \r\n",
        "\r\n",
        "    return images3, labels3, ids3, cls3\r\n",
        "\r\n",
        "\r\n",
        "def read_test_sets(test_path, image_size, classes, validation_size=0):\r\n",
        "    class DataSets(object):\r\n",
        "        pass\r\n",
        "\r\n",
        "    data_sets = DataSets()\r\n",
        "\r\n",
        "    images3, labels3, ids3, cls3 = load_test(test_path, image_size, classes)\r\n",
        "    images3, labels3, ids3, cls3 = shuffle(images3, labels3, ids3, cls3)  # shuffle the data\r\n",
        "\r\n",
        "    if isinstance(validation_size, float):\r\n",
        "        validation_size = int(validation_size * images3.shape[0])\r\n",
        "\r\n",
        "    test_images = images3\r\n",
        "    test_labels = labels3\r\n",
        "    test_ids = ids3\r\n",
        "    test_cls = cls3\r\n",
        "\r\n",
        "    data_sets.test = DataSet(test_images, test_labels, test_ids, test_cls)\r\n",
        "\r\n",
        "    return data_sets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ljS-nbe7Ag2"
      },
      "source": [
        "import time\r\n",
        "import math\r\n",
        "import random\r\n",
        "\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import tensorflow.compat.v1 as tf\r\n",
        "import cv2\r\n",
        "import dataset\r\n",
        "import os\r\n",
        "import keras\r\n",
        "\r\n",
        "from sklearn.metrics import confusion_matrix\r\n",
        "from datetime import timedelta\r\n",
        "import seaborn as sn\r\n",
        "\r\n",
        "%matplotlib inline\r\n",
        "\r\n",
        "tf.disable_v2_behavior()\r\n",
        "\r\n",
        "filter_size0 = 3\r\n",
        "num_filters0 = 3\r\n",
        "\r\n",
        "filter_size1 = 3\r\n",
        "num_filters1 = 64\r\n",
        "\r\n",
        "filter_size2 = 3\r\n",
        "num_filters2 = 128\r\n",
        "\r\n",
        "filter_size3 = 3\r\n",
        "num_filters3 = 256\r\n",
        "\r\n",
        "filter_size4 = 3\r\n",
        "num_filters4 = 512\r\n",
        "\r\n",
        "filter_size5 = 3\r\n",
        "num_filters5 = 512\r\n",
        "\r\n",
        "filter_size6 = 7\r\n",
        "num_filters6 = 512\r\n",
        "\r\n",
        "# Fully-connected layer.\r\n",
        "fc_size = 4096\r\n",
        "fc_size2 = 1000           \r\n",
        "\r\n",
        "# Number of color channels for the images: 1 channel for gray-scale.\r\n",
        "num_channels = 3\r\n",
        "\r\n",
        "# image dimensions (only squares for now)\r\n",
        "img_size = 224\r\n",
        "\r\n",
        "# Size of image when flattened to a single dimension\r\n",
        "img_size_flat = img_size * img_size * num_channels\r\n",
        "\r\n",
        "# Tuple with height and width of images used to reshape arrays.\r\n",
        "img_shape = (img_size, img_size)\r\n",
        "\r\n",
        "# class info\r\n",
        "classes = ['1.Cancer', '2.Precancer', '3.Inflammatory', '4.Normal']\r\n",
        "num_classes = len(classes)\r\n",
        "\r\n",
        "# batch size\r\n",
        "batch_size = 32\r\n",
        "\r\n",
        "# validation split\r\n",
        "validation_size = 0\r\n",
        "\r\n",
        "# how long to wait after validation loss stops improving before terminating training\r\n",
        "early_stopping = None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSxeNiNE7ArC"
      },
      "source": [
        "train_path = '/content/drive/Shareddrives/CTRC/HM_Color/train'\r\n",
        "validation_path = '/content/drive/Shareddrives/CTRC/HM_Color/validation'\r\n",
        "test_path = '/content/drive/Shareddrives/CTRC/HM_Color/test'\r\n",
        "checkpoint_dir = '/content/drive/MyDrive/model2/'\r\n",
        "\r\n",
        "data = read_train_sets(train_path, img_size, classes, validation_size=validation_size)\r\n",
        "data2 = read_validation_sets(validation_path, img_size, classes, validation_size=validation_size)\r\n",
        "data3 = read_test_sets(test_path, img_size, classes, validation_size=validation_size)\r\n",
        "\r\n",
        "\r\n",
        "print(\"Size of:\")\r\n",
        "print(\"- Training-set:\\t\\t{}\".format(len(data.train.labels)))\r\n",
        "print(\"- Validation-set:\\t{}\".format(len(data2.valid.labels)))\r\n",
        "print(\"- Test-set:\\t\\t{}\".format(len(data3.test.labels)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWufurb77A1_"
      },
      "source": [
        "model = tf.keras.Sequential([\r\n",
        "    tf.keras.layers.Conv2D(num_filters1, filter_size1, activation='relu',\r\n",
        "                           kernel_regularizer=tf.keras.regularizers.l2(0.001),\r\n",
        "                           input_shape=(img_size, img_size, num_channels)),\r\n",
        "    tf.keras.layers.Conv2D(num_filters1, filter_size1, activation='relu',\r\n",
        "                           kernel_regularizer=tf.keras.regularizers.l2(0.001)),\r\n",
        "    tf.keras.layers.Dropout(rate=0.25),\r\n",
        "    tf.keras.layers.MaxPooling2D(),\r\n",
        "    tf.keras.layers.Conv2D(num_filters2, filter_size2, activation='relu',\r\n",
        "                           kernel_regularizer=tf.keras.regularizers.l2(0.001)),\r\n",
        "    tf.keras.layers.Conv2D(num_filters2, filter_size2, activation='relu',\r\n",
        "                           kernel_regularizer=tf.keras.regularizers.l2(0.001)),\r\n",
        "    tf.keras.layers.Dropout(rate=0.25),\r\n",
        "    tf.keras.layers.MaxPooling2D(),\r\n",
        "    tf.keras.layers.Conv2D(num_filters3, filter_size3, activation='relu',\r\n",
        "                           kernel_regularizer=tf.keras.regularizers.l2(0.001)),\r\n",
        "    tf.keras.layers.Conv2D(num_filters3, filter_size3, activation='relu',\r\n",
        "                           kernel_regularizer=tf.keras.regularizers.l2(0.001)),\r\n",
        "    tf.keras.layers.Conv2D(num_filters3, filter_size3, activation='relu',\r\n",
        "                           kernel_regularizer=tf.keras.regularizers.l2(0.001)),\r\n",
        "    tf.keras.layers.Dropout(rate=0.25),\r\n",
        "    tf.keras.layers.MaxPooling2D(),\r\n",
        "    tf.keras.layers.Conv2D(num_filters4, filter_size4, activation='relu',\r\n",
        "                           kernel_regularizer=tf.keras.regularizers.l2(0.001)),\r\n",
        "    tf.keras.layers.Conv2D(num_filters4, filter_size4, activation='relu',\r\n",
        "                           kernel_regularizer=tf.keras.regularizers.l2(0.001)),\r\n",
        "    tf.keras.layers.Conv2D(num_filters4, filter_size4, activation='relu',\r\n",
        "                           kernel_regularizer=tf.keras.regularizers.l2(0.001)),\r\n",
        "    tf.keras.layers.Dropout(rate=0.25),\r\n",
        "    tf.keras.layers.MaxPooling2D(),\r\n",
        "    tf.keras.layers.Conv2D(num_filters5, filter_size5, activation='relu',\r\n",
        "                           kernel_regularizer=tf.keras.regularizers.l2(0.001)),\r\n",
        "    tf.keras.layers.Conv2D(num_filters5, filter_size5, activation='relu',\r\n",
        "                           kernel_regularizer=tf.keras.regularizers.l2(0.001)),\r\n",
        "    tf.keras.layers.Conv2D(num_filters5, filter_size5, activation='relu',\r\n",
        "                           kernel_regularizer=tf.keras.regularizers.l2(0.001)),\r\n",
        "    tf.keras.layers.Dropout(rate=0.25),\r\n",
        "    tf.keras.layers.MaxPooling2D(),\r\n",
        "    tf.keras.layers.Flatten(),\r\n",
        "    tf.keras.layers.Dense(fc_size, activation='relu'),\r\n",
        "    tf.keras.layers.Dense(fc_size2, activation='relu'),\r\n",
        "    tf.keras.layers.Dense(num_classes)\r\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3X12amYP7BBP"
      },
      "source": [
        "from keras.utils import plot_model\r\n",
        "plot_model(model, to_file='model.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AONfSDG-7BOZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TR92DycT7BYx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2SGw-lN7Bji"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}